{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Model Distillation\n",
    "\n",
    "This notebook demonstrates the knowledge distillation process from Perplexity-AI/r1-1776 (guru) to our VishwamAI model (shishya)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from vishwamai.distillation import VishwamaiGuruKnowledge, VishwamaiShaalaTrainer\n",
    "from vishwamai.model import VishwamAIModel, ModelConfig\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Perplexity-R1 distillation configuration\n",
    "config = OmegaConf.load('vishwamai/configs/training/perplexity_r1_distillation.yaml')\n",
    "\n",
    "# Display configuration\n",
    "print(\"Teacher Model:\", config.teacher_model.path)\n",
    "print(\"Student Model:\", config.student_model.path)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(f\"Hidden Size: {config.student_model.hidden_size}\")\n",
    "print(f\"Num Layers: {config.student_model.num_layers}\")\n",
    "print(f\"Attention Heads: {config.student_model.num_heads}\")\n",
    "print(f\"KV Heads: {config.student_model.num_kv_heads}\")\n",
    "\n",
    "print(\"\\nDistillation Parameters:\")\n",
    "print(f\"Temperature: {config.teacher_model.temperature}\")\n",
    "print(f\"Alpha: {config.teacher_model.alpha}\")\n",
    "print(f\"Feature Layers: {config.distillation.feature_distillation.layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Teacher Model (Guru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the teacher model (Perplexity r1-1776)\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(config.teacher_model.path)\n",
    "teacher_config = AutoConfig.from_pretrained(config.teacher_model.path)\n",
    "teacher_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.teacher_model.path,\n",
    "    device_map='auto',\n",
    "    torch_dtype='auto'\n",
    ")\n",
    "\n",
    "print(f\"Teacher model loaded: {teacher_config.model_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Student Model (Shishya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize student model (smaller version)\n",
    "student_config = ModelConfig(\n",
    "    vocab_size=teacher_config.vocab_size,\n",
    "    hidden_size=config.student_model.hidden_size,\n",
    "    num_layers=config.student_model.num_layers,\n",
    "    num_attention_heads=config.student_model.num_heads,\n",
    "    intermediate_size=config.student_model.intermediate_size,\n",
    "    max_position_embeddings=config.student_model.max_seq_len,\n",
    "    use_flash_attention=True,\n",
    "    use_gqa=True,\n",
    "    num_key_value_heads=config.student_model.num_kv_heads\n",
    ")\n",
    "\n",
    "student_model = VishwamAIModel(student_config)\n",
    "print(f\"Student model initialized with {student_config.num_layers} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load and prepare training data\n",
    "train_dataset = load_dataset(\n",
    "    config.data.path,\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize inputs\n",
    "    model_inputs = teacher_tokenizer(\n",
    "        examples['text'],\n",
    "        max_length=config.model.max_seq_len,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(tokenized_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the guru-shishya training process\n",
    "trainer = VishwamaiShaalaTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    cfg=config\n",
    ")\n",
    "\n",
    "# Initialize training state\n",
    "rng = jax.random.PRNGKey(config.training.seed)\n",
    "state = trainer.create_train_state(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training loop with progress tracking\n",
    "num_epochs = config.training.num_epochs\n",
    "steps_per_epoch = len(tokenized_dataset) // config.training.batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(total=steps_per_epoch, desc=f\"Epoch {epoch+1}\") as pbar:\n",
    "        for step, batch in enumerate(trainer.get_train_dataloader(tokenized_dataset)):\n",
    "            state, loss_dict, rng = trainer.train_step(state, batch, step, rng)\n",
    "            \n",
    "            if step % config.training.log_every == 0:\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f\"{loss_dict['total_loss']:.4f}\",\n",
    "                    'kd_loss': f\"{loss_dict['kd_loss']:.4f}\"\n",
    "                })\n",
    "            pbar.update(1)\n",
    "            \n",
    "        # Save checkpoint at end of epoch\n",
    "        if (epoch + 1) % config.training.save_every == 0:\n",
    "            trainer.save_checkpoint(\n",
    "                state,\n",
    "                f\"{config.student_model.path}/checkpoint-{epoch+1}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the final distilled model with metadata\n",
    "model_card = {\n",
    "    \"base_model\": \"perplexity-ai/r1-1776\",\n",
    "    \"model_type\": \"distilled-language-model\",\n",
    "    \"distillation_method\": \"VishwamAI guru-shishya knowledge transfer\",\n",
    "    \"architecture\": {\n",
    "        \"hidden_size\": config.student_model.hidden_size,\n",
    "        \"num_layers\": config.student_model.num_layers,\n",
    "        \"num_heads\": config.student_model.num_heads,\n",
    "        \"num_kv_heads\": config.student_model.num_kv_heads\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"distillation_temperature\": config.teacher_model.temperature,\n",
    "        \"alpha\": config.teacher_model.alpha,\n",
    "        \"epochs\": config.training.num_epochs\n",
    "    }\n",
    "}\n",
    "\n",
    "trainer.save_model(\n",
    "    state,\n",
    "    config.student_model.path,\n",
    "    push_to_hub=True,\n",
    "    model_card=model_card\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Distillation complete!\")\n",
    "print(f\"ðŸ’¡ Model saved to: {config.student_model.path}\")\n",
    "print(\"ðŸ“Š Model card and weights pushed to Hugging Face Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quick validation test\n",
    "test_input = \"What is the capital of France?\"\n",
    "\n",
    "# Get teacher output\n",
    "teacher_output = trainer.generate_text(teacher_model, test_input)\n",
    "print(\"Teacher output:\", teacher_output)\n",
    "\n",
    "# Get student output\n",
    "student_output = trainer.generate_text(student_model, test_input)\n",
    "print(\"Student output:\", student_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
