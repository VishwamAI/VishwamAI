{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI TPU Development - Experiment 2\n",
    "\n",
    "This notebook implements TPU-optimized transformer training with monitoring and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vishwamai import (\n",
    "    create_vishwamai_transformer,\n",
    "    create_train_state,\n",
    "    EnhancedTransformerModel,\n",
    "    VishwamAITrainer,\n",
    "    DuckDBLogger,\n",
    "    DEFAULT_CONFIG\n",
    ")\n",
    "\n",
    "# Check TPU configuration\n",
    "print(\"JAX devices:\", jax.devices())\n",
    "print(\"Number of devices:\", jax.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and update configuration for TPU\n",
    "config = DEFAULT_CONFIG.copy()\n",
    "\n",
    "# Update model configuration\n",
    "config['model_config'].update({\n",
    "    'vocab_size': 32000,\n",
    "    'num_layers': 12,\n",
    "    'num_heads': 12,\n",
    "    'head_dim': 64,\n",
    "    'hidden_dim': 768,\n",
    "    'mlp_dim': 3072,\n",
    "    'max_seq_len': 2048,\n",
    "    'use_flash_attn': True,\n",
    "    'use_rotary': True,\n",
    "    'use_rms_norm': True,\n",
    "    'dtype': 'bfloat16',\n",
    "    'compute_dtype': 'float32'\n",
    "})\n",
    "\n",
    "# Update training configuration\n",
    "config['training'].update({\n",
    "    'batch_size': 32 * jax.device_count(),  # Scale batch size by number of devices\n",
    "    'learning_rate': 1e-4,\n",
    "    'warmup_steps': 2000,\n",
    "    'decay_steps': 50000,\n",
    "    'weight_decay': 0.01,\n",
    "    'gradient_checkpointing': True,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'mixed_precision': True,\n",
    "    'tpu_iterations_per_loop': 100\n",
    "})\n",
    "\n",
    "print(\"Model configuration:\", config['model_config'])\n",
    "print(\"\\nTraining configuration:\", config['training'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_data(num_samples, batch_size, seq_length, vocab_size):\n",
    "    \"\"\"Create dummy data optimized for TPU training\"\"\"\n",
    "    # Ensure total samples is divisible by global batch size\n",
    "    samples_per_device = num_samples // jax.device_count()\n",
    "    total_samples = samples_per_device * jax.device_count()\n",
    "    \n",
    "    # Generate random data\n",
    "    rng = np.random.default_rng(42)\n",
    "    \n",
    "    input_shape = (total_samples, seq_length)\n",
    "    input_ids = rng.integers(0, vocab_size, size=input_shape)\n",
    "    labels = rng.integers(0, vocab_size, size=input_shape)\n",
    "    attention_mask = np.ones(input_shape)\n",
    "    \n",
    "    # Convert to device arrays\n",
    "    return {\n",
    "        'input_ids': jnp.array(input_ids),\n",
    "        'labels': jnp.array(labels),\n",
    "        'attention_mask': jnp.array(attention_mask)\n",
    "    }\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_data = create_dummy_data(\n",
    "    num_samples=1000,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    seq_length=config['model_config']['max_seq_len'],\n",
    "    vocab_size=config['model_config']['vocab_size']\n",
    ")\n",
    "\n",
    "val_data = create_dummy_data(\n",
    "    num_samples=100,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    seq_length=config['model_config']['max_seq_len'],\n",
    "    vocab_size=config['model_config']['vocab_size']\n",
    ")\n",
    "\n",
    "print(\"Training data shape:\", train_data['input_ids'].shape)\n",
    "print(\"Validation data shape:\", val_data['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training state\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "\n",
    "# Create model\n",
    "model = create_vishwamai_transformer(config['model_config'])\n",
    "\n",
    "# Create trainer\n",
    "trainer = VishwamAITrainer(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    experiment_name='experiment2_tpu',\n",
    "    db_path='experiment2.db'\n",
    ")\n",
    "\n",
    "# Initialize training state\n",
    "trainer.setup_training()\n",
    "\n",
    "print(f\"Model initialized with {sum(p.size for p in jax.tree_leaves(model.params)):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(trainer, train_data, config):\n",
    "    \"\"\"Run one epoch of training\"\"\"\n",
    "    batch_size = config['training']['batch_size']\n",
    "    steps_per_epoch = len(train_data['input_ids']) // batch_size\n",
    "    \n",
    "    metrics_list = []\n",
    "    \n",
    "    for step in tqdm(range(steps_per_epoch)):\n",
    "        # Get batch\n",
    "        start_idx = step * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids': train_data['input_ids'][start_idx:end_idx],\n",
    "            'labels': train_data['labels'][start_idx:end_idx],\n",
    "            'attention_mask': train_data['attention_mask'][start_idx:end_idx]\n",
    "        }\n",
    "        \n",
    "        # Training step\n",
    "        metrics = trainer.train_step(\n",
    "            batch,\n",
    "            dropout_rng=jax.random.PRNGKey(step)\n",
    "        )\n",
    "        metrics_list.append(metrics)\n",
    "        \n",
    "        # Log every N steps\n",
    "        if step % 10 == 0:\n",
    "            avg_loss = np.mean([m['loss'] for m in metrics_list[-10:]])\n",
    "            print(f\"\\nStep {step}/{steps_per_epoch}\")\n",
    "            print(f\"Loss: {avg_loss:.4f}\")\n",
    "            print(f\"Learning rate: {metrics['learning_rate']:.6f}\")\n",
    "    \n",
    "    return metrics_list\n",
    "\n",
    "def evaluate(trainer, val_data, config):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    batch_size = config['training']['batch_size']\n",
    "    steps_per_eval = len(val_data['input_ids']) // batch_size\n",
    "    \n",
    "    metrics_list = []\n",
    "    \n",
    "    for step in range(steps_per_eval):\n",
    "        start_idx = step * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids': val_data['input_ids'][start_idx:end_idx],\n",
    "            'labels': val_data['labels'][start_idx:end_idx],\n",
    "            'attention_mask': val_data['attention_mask'][start_idx:end_idx]\n",
    "        }\n",
    "        \n",
    "        metrics = trainer.evaluate(batch)\n",
    "        metrics_list.append(metrics)\n",
    "    \n",
    "    # Compute average metrics\n",
    "    avg_metrics = {}\n",
    "    for key in metrics_list[0].keys():\n",
    "        avg_metrics[key] = np.mean([m[key] for m in metrics_list])\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    epoch_metrics = train_epoch(trainer, train_data, config)\n",
    "    train_metrics.extend(epoch_metrics)\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_metrics = evaluate(trainer, val_data, config)\n",
    "    val_metrics.append(eval_metrics)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} evaluation:\")\n",
    "    print(f\"Validation loss: {eval_metrics['loss']:.4f}\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    trainer.save_checkpoint(f\"experiment2_checkpoint_epoch_{epoch + 1}\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "train_losses = [m['loss'] for m in train_metrics]\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "val_losses = [m['loss'] for m in val_metrics]\n",
    "plt.plot(val_losses, 'r-')\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"Final training loss:\", train_losses[-1])\n",
    "print(\"Final validation loss:\", val_losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Profiling and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.profiler import start_trace, stop_trace, trace\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class TPUMonitor:\n",
    "    \"\"\"Monitor TPU performance and memory usage\"\"\"\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def capture_metrics(self):\n",
    "        try:\n",
    "            # Get host memory usage\n",
    "            memory = psutil.Process().memory_info()\n",
    "            \n",
    "            # Get TPU metrics if available\n",
    "            devices = jax.devices()\n",
    "            device_memory = [device.memory_stats() for device in devices]\n",
    "            \n",
    "            metrics = {\n",
    "                'timestamp': time.time() - self.start_time,\n",
    "                'host_memory_mb': memory.rss / (1024 * 1024),\n",
    "                'device_metrics': device_memory\n",
    "            }\n",
    "            \n",
    "            self.metrics.append(metrics)\n",
    "            return metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error capturing metrics: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        timestamps = [m['timestamp'] for m in self.metrics]\n",
    "        host_memory = [m['host_memory_mb'] for m in self.metrics]\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(timestamps, host_memory)\n",
    "        plt.title('Host Memory Usage')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Memory (MB)')\n",
    "        \n",
    "        if self.metrics[0]['device_metrics']:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            for i, device in enumerate(jax.devices()):\n",
    "                device_mem = [m['device_metrics'][i].get('peak_bytes_in_use', 0) / (1024**3)\n",
    "                             for m in self.metrics]\n",
    "                plt.plot(timestamps, device_mem, label=f'TPU {i}')\n",
    "            \n",
    "            plt.title('TPU Memory Usage')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Memory (GB)')\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create monitor\n",
    "tpu_monitor = TPUMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update training loop with profiling\n",
    "@trace(\"train_epoch_profile\")\n",
    "def train_epoch_with_profile(trainer, train_data, config):\n",
    "    metrics = train_epoch(trainer, train_data, config)\n",
    "    tpu_monitor.capture_metrics()\n",
    "    return metrics\n",
    "\n",
    "# Start profiling\n",
    "start_trace('./tpu_profile')\n",
    "\n",
    "# Run one epoch with profiling\n",
    "print(\"Running profiled training epoch...\")\n",
    "profile_metrics = train_epoch_with_profile(trainer, train_data, config)\n",
    "\n",
    "# Stop profiling\n",
    "stop_trace()\n",
    "\n",
    "# Plot monitoring results\n",
    "tpu_monitor.plot_metrics()\n",
    "\n",
    "print(\"\\nProfile data saved to ./tpu_profile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tpu_performance(monitor, profile_metrics):\n",
    "    \"\"\"Analyze TPU performance metrics\"\"\"\n",
    "    print(\"TPU Performance Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Memory utilization\n",
    "    if monitor.metrics:\n",
    "        latest = monitor.metrics[-1]\n",
    "        print(\"\\nMemory Utilization:\")\n",
    "        print(f\"Host Memory: {latest['host_memory_mb']:.2f} MB\")\n",
    "        \n",
    "        for i, device_metrics in enumerate(latest['device_metrics']):\n",
    "            mem_gb = device_metrics.get('peak_bytes_in_use', 0) / (1024**3)\n",
    "            print(f\"TPU {i} Peak Memory: {mem_gb:.2f} GB\")\n",
    "    \n",
    "    # Training metrics\n",
    "    if profile_metrics:\n",
    "        print(\"\\nTraining Performance:\")\n",
    "        losses = [m['loss'] for m in profile_metrics]\n",
    "        print(f\"Average Loss: {np.mean(losses):.4f}\")\n",
    "        print(f\"Loss Std Dev: {np.std(losses):.4f}\")\n",
    "        \n",
    "        # Compute throughput\n",
    "        batch_size = config['training']['batch_size']\n",
    "        total_samples = len(profile_metrics) * batch_size\n",
    "        duration = monitor.metrics[-1]['timestamp'] - monitor.metrics[0]['timestamp']\n",
    "        throughput = total_samples / duration\n",
    "        \n",
    "        print(f\"\\nThroughput: {throughput:.2f} samples/second\")\n",
    "        print(f\"Batch Processing Time: {duration/len(profile_metrics)*1000:.2f} ms/batch\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_tpu_performance(tpu_monitor, profile_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model and configuration\n",
    "import json\n",
    "\n",
    "save_dir = 'experiment2_final'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "trainer.save_checkpoint(f\"{save_dir}/model\")\n",
    "\n",
    "# Save configuration\n",
    "with open(f\"{save_dir}/config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Model and configuration saved to {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
