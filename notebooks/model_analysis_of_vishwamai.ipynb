{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyO6Mo6nRVcL6M4xfOOJMAe1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishwamAI/VishwamAI/blob/main/notebooks/model_analysis_of_vishwamai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# Task\n",
        "model analyisis of vishwamai and devlopments integrating with advancements of ai and devlopment https://github.com/VishwamAI/VishwamAI"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBPBPa8Rj1f"
      }
    },
    {
      "source": [
        "## Data loading\n",
        "\n",
        "### Subtask:\n",
        "Load the data from \"train-00000-of-00001-1.csv\" into a pandas DataFrame.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "pZK7lS-PRkFM"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Load the data from \"train-00000-of-00001-1.csv\" into a pandas DataFrame.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "M8prrz6MRkU7"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train-00000-of-00001-1.csv')\n",
        "display(df.head())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "_AagNJKgRkkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data exploration\n",
        "\n",
        "### Subtask:\n",
        "Explore the loaded data to understand its structure, features, and potential issues.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "oXO4g1syRoVK"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Explore the data's structure, features, and potential issues by examining the shape, data types, descriptive statistics, and missing values.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "EBhM75wXRpL2"
      }
    },
    {
      "source": [
        "# Examine the shape of the data\n",
        "print(\"Shape of the DataFrame:\", df.shape)\n",
        "\n",
        "# Check data types\n",
        "print(\"\\nData Types:\\n\", df.dtypes)\n",
        "\n",
        "# Explore descriptive statistics\n",
        "print(\"\\nDescriptive Statistics:\\n\", df.describe(include='all'))\n",
        "\n",
        "# Identify missing values\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
        "\n",
        "# Examine unique values for 'question' and 'answer'\n",
        "print(\"\\nUnique Questions:\", df['question'].nunique())\n",
        "print(\"Unique Answers:\", df['answer'].nunique())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6fUDka2ARpbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "**Reasoning**:\n",
        "Analyze the distribution of variables (question and answer lengths) using histograms to understand the data's characteristics and potential issues.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "TWNfpAexRrEO"
      }
    },
    {
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Analyze the distribution of question length\n",
        "df['question_length'] = df['question'].str.len()\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(df['question_length'], bins=50)\n",
        "plt.xlabel('Question Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Question Lengths')\n",
        "plt.show()\n",
        "\n",
        "# Analyze the distribution of answer length\n",
        "df['answer_length'] = df['answer'].str.len()\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(df['answer_length'], bins=50)\n",
        "plt.xlabel('Answer Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Answer Lengths')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CxwoldH-RrT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Data preparation\n",
        "\n",
        "### Subtask:\n",
        "Prepare the data for model training by handling missing values (if any), converting categorical variables (if any), splitting the data into training and testing sets, and potentially performing feature scaling if necessary.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "rY99OfhcRutp"
      }
    },
    {
      "source": [
        "**Reasoning**:\n",
        "The next step is to prepare the data for model training by handling missing values, checking for categorical variables, splitting the data into training and testing sets, and potentially performing feature scaling.\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "9YQow2lYRvlL"
      }
    },
    {
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Handle Missing Values (No missing values found during exploration)\n",
        "# Since no missing values were found during the data exploration step, we can skip this step.\n",
        "\n",
        "# 2. Check for Categorical Variables\n",
        "# Both 'question' and 'answer' are text columns, which can be treated as categorical features.\n",
        "# However, we don't need to convert them to numerical representations in this stage.\n",
        "# We will likely use a language model to process the textual data, so we can keep them as they are.\n",
        "\n",
        "# 3. Split the Data\n",
        "X = df[['question', 'question_length', 'answer_length']]  # Features\n",
        "y = df['answer']  # Target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Feature Scaling (Optional)\n",
        "# Since the 'question' and 'answer' are text columns, feature scaling for them is unnecessary.\n",
        "# We only need to scale 'question_length' and 'answer_length'.\n",
        "scaler = StandardScaler()\n",
        "X_train[['question_length', 'answer_length']] = scaler.fit_transform(X_train[['question_length', 'answer_length']])\n",
        "X_test[['question_length', 'answer_length']] = scaler.transform(X_test[['question_length', 'answer_length']])\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "77ZlTF1tRv02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Model training\n",
        "\n",
        "### Subtask:\n",
        "Train a VishwamAI model using the prepared data.\n"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "ikEbffYpSb25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/VishwamAI/VishwamAI\n",
        "%cd VishwamAI"
      ],
      "metadata": {
        "id": "bBMTjIbjTDlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt kauldron albumentations kornia timm openai-whisper torch torchaudio torchvision -f https://download.pytorch.org/whl/cu118/torch_stable.html\n"
      ],
      "metadata": {
        "id": "Qt3H8COoTHmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python importtest.py"
      ],
      "metadata": {
        "id": "Ssg4XFVJUzBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from vishwamai.layers.layers import TPUMoELayer\n",
        "from vishwamai.thoughts.tot import TreeOfThoughts, ThoughtNode\n",
        "from vishwamai.thoughts.cot import ChainOfThoughtPrompting\n",
        "from vishwamai.transformer import create_vishwamai_transformer"
      ],
      "metadata": {
        "id": "bdErK93CnauD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_moe_config(num_experts: int, expert_dim: int, capacity_factor: float = 1.0):\n",
        "    \"\"\"Analyze MoE configuration and compute resource requirements\"\"\"\n",
        "    config = {\n",
        "        'num_experts': num_experts,\n",
        "        'expert_dim': expert_dim,\n",
        "        'capacity_factor': capacity_factor,\n",
        "        'router_dim': 256,\n",
        "        'router_capacity': int(capacity_factor * (expert_dim / num_experts))\n",
        "    }\n",
        "\n",
        "    # Calculate parameter counts\n",
        "    router_params = config['router_dim'] * num_experts\n",
        "    expert_params = num_experts * (expert_dim * expert_dim * 4)  # FFN params per expert\n",
        "\n",
        "    return {\n",
        "        'config': config,\n",
        "        'router_params': router_params,\n",
        "        'expert_params': expert_params,\n",
        "        'total_params': router_params + expert_params\n",
        "    }"
      ],
      "metadata": {
        "id": "CaYMNwzNq5zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_tree():\n",
        "    \"\"\"Create a sample thought tree for visualization\"\"\"\n",
        "    root = ThoughtNode(thought=\"Initial problem\", value=0.0)\n",
        "\n",
        "    # Create child thoughts\n",
        "    thought1 = ThoughtNode(\n",
        "        thought=\"Approach 1: Direct solution\",\n",
        "        value=0.7,\n",
        "        parent=root,\n",
        "        depth=1\n",
        "    )\n",
        "    thought2 = ThoughtNode(\n",
        "        thought=\"Approach 2: Break down problem\",\n",
        "        value=0.8,\n",
        "        parent=root,\n",
        "        depth=1\n",
        "    )\n",
        "\n",
        "    # Add sub-thoughts to thought2\n",
        "    sub1 = ThoughtNode(\n",
        "        thought=\"Sub-problem 1: Analyze components\",\n",
        "        value=0.85,\n",
        "        parent=thought2,\n",
        "        depth=2\n",
        "    )\n",
        "    sub2 = ThoughtNode(\n",
        "        thought=\"Sub-problem 2: Synthesize solution\",\n",
        "        value=0.9,\n",
        "        parent=thought2,\n",
        "        depth=2\n",
        "    )\n",
        "\n",
        "    # Set up the tree structure\n",
        "    root.children = [thought1, thought2]\n",
        "    thought2.children = [sub1, sub2]\n",
        "\n",
        "    return root"
      ],
      "metadata": {
        "id": "RYRnHXw6q8dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_thought_tree(node: ThoughtNode, level: int = 0):\n",
        "    \"\"\"Visualize a thought tree with values\"\"\"\n",
        "    prefix = \"  \" * level\n",
        "    print(f\"{prefix}└─ {node.thought} (value: {node.value:.2f})\")\n",
        "\n",
        "    for child in node.children:\n",
        "        visualize_thought_tree(child, level + 1)"
      ],
      "metadata": {
        "id": "jlSwrXmzrI8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_advanced_config():\n",
        "    \"\"\"Create model configuration with advanced features\"\"\"\n",
        "    return {\n",
        "        'vocab_size': 32000,\n",
        "        'num_layers': 12,\n",
        "        'num_heads': 12,\n",
        "        'head_dim': 64,\n",
        "        'hidden_dim': 768,\n",
        "        'mlp_dim': 3072,\n",
        "        'max_seq_len': 2048,\n",
        "        'num_experts': 8,\n",
        "        'expert_dim': 3072,\n",
        "        'tot_max_steps': 10,\n",
        "        'tot_beam_width': 3,\n",
        "        'dropout_rate': 0.1\n",
        "    }\n",
        "\n",
        "config = create_advanced_config()\n",
        "moe_analysis = analyze_moe_config(config['num_experts'], config['expert_dim'])\n",
        "\n",
        "print(\"MoE Configuration:\")\n",
        "print(f\"Number of Experts: {config['num_experts']}\")\n",
        "print(f\"Expert Dimension: {config['expert_dim']}\")\n",
        "print(f\"Total MoE Parameters: {moe_analysis['total_params']:,}\")\n",
        "\n",
        "print(\"\\nSample Thought Tree:\")\n",
        "root = create_sample_tree()\n",
        "visualize_thought_tree(root)"
      ],
      "metadata": {
        "id": "6mgQbhE3rK4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from vishwamai.model import VishwamAI\n",
        "from vishwamai.kernels.kernel import fp8_gemm_optimized\n",
        "from vishwamai.layers.attention import FlashAttention\n",
        "from vishwamai.transformer import (\n",
        "    TransformerModel,\n",
        "    EnhancedTransformerModel,\n",
        "    create_vishwamai_transformer\n",
        ")"
      ],
      "metadata": {
        "id": "CQrYNzC2rNIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_config():\n",
        "    return {\n",
        "        'vocab_size': 32000,\n",
        "        'num_layers': 12,\n",
        "        'num_heads': 12,\n",
        "        'head_dim': 64,\n",
        "        'hidden_dim': 768,\n",
        "        'mlp_dim': 3072,\n",
        "        'max_seq_len': 2048,\n",
        "        'dropout_rate': 0.1,\n",
        "        'use_enhanced': True,\n",
        "        'use_rotary': True,\n",
        "        'use_flash_attn': True,\n",
        "        'use_rms_norm': False\n",
        "    }"
      ],
      "metadata": {
        "id": "QUezh1iksKbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_model_size(config):\n",
        "    \"\"\"Calculate model size and component breakdown\"\"\"\n",
        "    vocab_size = config['vocab_size']\n",
        "    hidden_dim = config['hidden_dim']\n",
        "    num_layers = config['num_layers']\n",
        "    mlp_dim = config['mlp_dim']\n",
        "\n",
        "    embedding_params = vocab_size * hidden_dim\n",
        "    attention_params = num_layers * (4 * hidden_dim * hidden_dim)\n",
        "    ffn_params = num_layers * (2 * hidden_dim * mlp_dim)\n",
        "    layer_norm_params = num_layers * 2 * hidden_dim\n",
        "\n",
        "    total_params = embedding_params + attention_params + ffn_params + layer_norm_params\n",
        "\n",
        "    return {\n",
        "        'total': total_params,\n",
        "        'embedding': embedding_params,\n",
        "        'attention': attention_params,\n",
        "        'ffn': ffn_params,\n",
        "        'layer_norm': layer_norm_params\n",
        "    }"
      ],
      "metadata": {
        "id": "3v3mLE0RsMFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze model architecture\n",
        "config = create_sample_config()\n",
        "model_stats = analyze_model_size(config)\n",
        "\n",
        "# Plot parameter distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie([v/model_stats['total'] for v in model_stats.values()][1:],\n",
        "        labels=[k for k in model_stats.keys()][1:],\n",
        "        autopct='%1.1f%%')\n",
        "plt.title('Parameter Distribution Across Model Components')\n",
        "plt.axis('equal')"
      ],
      "metadata": {
        "id": "KN0Mf5EHsNzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = create_vishwamai_transformer(config)\n",
        "\n",
        "# Print model summary\n",
        "print(f\"Total Parameters: {model_stats['total']:,}\")\n",
        "print(f\"Hidden Dimension: {config['hidden_dim']}\")\n",
        "print(f\"Number of Layers: {config['num_layers']}\")\n",
        "print(f\"Number of Attention Heads: {config['num_heads']}\")\n",
        "print(f\"Maximum Sequence Length: {config['max_seq_len']}\")"
      ],
      "metadata": {
        "id": "fpLrtmDQsRV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from vishwamai.kernels.kernel import fp8_gemm_optimized\n",
        "from vishwamai.layers.attention import FlashAttention\n",
        "from vishwamai.layers.layers import TPUGEMMLinear, TPULayerNorm\n",
        "from vishwamai.transformer import create_vishwamai_transformer"
      ],
      "metadata": {
        "id": "G-ueO01YsT3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_gemm(batch_size: int, seq_len: int, hidden_dim: int):\n",
        "    \"\"\"Benchmark GEMM operations with and without optimizations\"\"\"\n",
        "    x = jnp.ones((batch_size, seq_len, hidden_dim))\n",
        "    w = jnp.ones((hidden_dim, hidden_dim))\n",
        "\n",
        "    # Standard GEMM\n",
        "    start = time.time()\n",
        "    for _ in range(10):\n",
        "        _ = jnp.dot(x, w)\n",
        "    std_time = (time.time() - start) / 10\n",
        "\n",
        "    # Optimized GEMM\n",
        "    start = time.time()\n",
        "    for _ in range(10):\n",
        "        _ = fp8_gemm_optimized(x, w)\n",
        "    opt_time = (time.time() - start) / 10\n",
        "\n",
        "    return std_time, opt_time"
      ],
      "metadata": {
        "id": "jR0ZoGT6s-yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_attention(batch_size: int, seq_len: int, hidden_dim: int, num_heads: int):\n",
        "    \"\"\"Benchmark attention implementations\"\"\"\n",
        "    head_dim = hidden_dim // num_heads\n",
        "\n",
        "    # Initialize inputs\n",
        "    q = jnp.ones((batch_size, seq_len, num_heads, head_dim))\n",
        "    k = jnp.ones((batch_size, seq_len, num_heads, head_dim))\n",
        "    v = jnp.ones((batch_size, seq_len, num_heads, head_dim))\n",
        "\n",
        "    # Standard attention\n",
        "    start = time.time()\n",
        "    for _ in range(10):\n",
        "        scores = jnp.einsum('bthd,bshd->btsh', q, k)\n",
        "        scores = scores / jnp.sqrt(head_dim)\n",
        "        attn = jax.nn.softmax(scores)\n",
        "        output = jnp.einsum('btsh,bshd->bthd', attn, v)\n",
        "    std_time = (time.time() - start) / 10\n",
        "\n",
        "    # Flash attention\n",
        "    flash_attn = FlashAttention(num_heads=num_heads, head_dim=head_dim)\n",
        "    start = time.time()\n",
        "    for _ in range(10):\n",
        "        _ = flash_attn(q, k, v)\n",
        "    flash_time = (time.time() - start) / 10\n",
        "\n",
        "    return std_time, flash_time"
      ],
      "metadata": {
        "id": "WwGFaQVCtBV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_memory_usage(config: Dict):\n",
        "    \"\"\"Analyze memory usage of different components\"\"\"\n",
        "    batch_size = 32\n",
        "    seq_len = config['max_seq_len']\n",
        "    hidden_dim = config['hidden_dim']\n",
        "\n",
        "    # Calculate memory requirements\n",
        "    activations = batch_size * seq_len * hidden_dim * 2  # BF16\n",
        "    attention = batch_size * seq_len * seq_len * config['num_heads'] * 2  # BF16\n",
        "    kv_cache = 2 * batch_size * seq_len * hidden_dim * 2  # BF16\n",
        "\n",
        "    # Convert to MB\n",
        "    mb = 1024 * 1024\n",
        "    return {\n",
        "        'activations': activations / mb,\n",
        "        'attention': attention / mb,\n",
        "        'kv_cache': kv_cache / mb\n",
        "    }"
      ],
      "metadata": {
        "id": "zOjTlfHbtDKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run benchmarks\n",
        "config = {\n",
        "    'max_seq_len': 2048,\n",
        "    'hidden_dim': 768,\n",
        "    'num_heads': 12\n",
        "}\n",
        "\n",
        "# Memory analysis\n",
        "memory_usage = analyze_memory_usage(config)\n",
        "\n",
        "# Plot memory usage\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(memory_usage.keys(), memory_usage.values())\n",
        "plt.title('Memory Usage by Component (MB)')\n",
        "plt.ylabel('Memory (MB)')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Print summary\n",
        "print(\"Memory Usage Summary (MB):\")\n",
        "for k, v in memory_usage.items():\n",
        "    print(f\"{k}: {v:.2f}\")"
      ],
      "metadata": {
        "id": "NDiwmIf0tEwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}