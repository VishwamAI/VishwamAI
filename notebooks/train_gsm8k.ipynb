{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSM8K Math Problem Training\n",
    "\n",
    "This notebook implements training on the GSM8K dataset using TPU acceleration and optimized configurations for mathematical reasoning.\n",
    "\n",
    "## Repository Setup\n",
    "\n",
    "First, let's clone the repository and prepare the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Helper function to determine environment\n",
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Setup repository and paths\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if is_colab():\n",
    "    # Clone repository in Colab\n",
    "    !git clone https://github.com/organization/vishwamai.git\n",
    "    repo_path = Path('vishwamai')\n",
    "else:\n",
    "    # Local development setup\n",
    "    notebook_dir = Path().absolute()\n",
    "    if notebook_dir.name == 'notebooks':\n",
    "        repo_path = notebook_dir.parent\n",
    "    else:\n",
    "        repo_path = notebook_dir\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(repo_path / 'checkpoints' / 'gsm8k', exist_ok=True)\n",
    "os.makedirs(repo_path / 'logs', exist_ok=True)\n",
    "\n",
    "print(f\"Repository path: {repo_path}\")\n",
    "print(\"Directory structure:\")\n",
    "!ls -R {repo_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up Python environment\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir(repo_path)\n",
    "\n",
    "# Install package in development mode\n",
    "print(\"Installing VishwamAI package...\")\n",
    "!pip install --quiet --no-cache-dir -e .\n",
    "\n",
    "# Add repository to Python path if needed\n",
    "if str(repo_path) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_path))\n",
    "    print(f\"Added {repo_path} to Python path\")\n",
    "\n",
    "# Clear and reload imports\n",
    "if 'vishwamai' in sys.modules:\n",
    "    importlib.reload(sys.modules['vishwamai'])\n",
    "\n",
    "# Verify installation\n",
    "try:\n",
    "    import vishwamai\n",
    "    print(f\"✓ Successfully imported vishwamai v{vishwamai.__version__}\")\n",
    "    print(f\"✓ Package location: {vishwamai.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Failed to import vishwamai: {e}\")\n",
    "    print(\"Debug information:\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Install required packages and set up TPU environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup TPU runtime and install required packages\n",
    "!pip install --upgrade pip\n",
    "!pip install \"jax[tpu]>=0.4.13\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n",
    "!pip install flax>=0.7.0 optax>=0.1.7 chex>=0.1.7 tensorboardX>=2.6.1\n",
    "!pip install datasets omegaconf safetensors matplotlib seaborn\n",
    "\n",
    "# Install VishwamAI package in development mode with extras\n",
    "!pip install -e \".[dev,profiling]\" --no-cache-dir\n",
    "\n",
    "# Verify installations\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"Available devices: {jax.devices()}\")\n",
    "\n",
    "import vishwamai\n",
    "print(f\"VishwamAI version: {vishwamai.__version__}\")\n",
    "print(\"✓ Successfully imported all required packages\")\n",
    "\n",
    "# Ensure TPU is available\n",
    "assert len(jax.devices('tpu')) > 0, \"No TPU devices found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import jax\n",
    "from jax.sharding import Mesh, NamedSharding, PartitionSpec as P\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from vishwamai.training import train, create_train_state\n",
    "from vishwamai.model import VishwamAIModel, ModelConfig\n",
    "from vishwamai.tokenizer import VishwamAITokenizer\n",
    "from omegaconf import OmegaConf\n",
    "import logging\n",
    "from safetensors.flax import save_file\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configure logging and plotting\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Setup\n",
    "\n",
    "Configure TPU environment and create device mesh for training using modern JAX sharding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# TPU environment setup\n",
    "os.environ['TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD'] = '10000000000'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ['JAX_PLATFORMS'] = 'tpu'\n",
    "os.environ['JAX_ENABLE_X64'] = 'False'\n",
    "\n",
    "def setup_tpu_cluster():\n",
    "    \"\"\"Set up JAX TPU cluster configuration using modern sharding API.\"\"\"\n",
    "    # Get available devices\n",
    "    devices = jax.devices()\n",
    "    print(f\"Available devices: {devices}\")\n",
    "    \n",
    "    # Create device mesh for data parallel training\n",
    "    device_count = len(devices)\n",
    "    device_mesh = np.array(devices).reshape(device_count)\n",
    "    \n",
    "    # Create mesh with data parallel sharding\n",
    "    mesh = Mesh(device_mesh, ('data',))\n",
    "    \n",
    "    # Create sharding rules\n",
    "    data_sharding = NamedSharding(mesh, P('data'))\n",
    "    \n",
    "    return mesh, data_sharding\n",
    "\n",
    "# Set up TPU mesh and sharding\n",
    "mesh, sharding = setup_tpu_cluster()\n",
    "print(\"\\nMesh specification:\", mesh)\n",
    "print(\"Sharding specification:\", sharding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configurations\n",
    "\n",
    "Load model and training configurations optimized for GSM8K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load configurations\n",
    "configs_dir = repo_path / 'vishwamai' / 'configs'\n",
    "model_config = OmegaConf.load(configs_dir / 'model' / '10B.yaml')\n",
    "training_config = OmegaConf.load(configs_dir / 'training' / 'gsm8k.yaml')\n",
    "\n",
    "# Update paths in configs to use absolute paths\n",
    "if 'output_dir' in training_config:\n",
    "    training_config.output_dir = str(repo_path / 'checkpoints' / 'gsm8k')\n",
    "\n",
    "print(\"Config directory:\", configs_dir)\n",
    "print(\"\\nModel config:\", model_config)\n",
    "print(\"\\nTraining config:\", training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Implement GSM8K dataset processing with step-by-step solution formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class GSM8KProcessor:\n",
    "    \"\"\"Processor for GSM8K dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, config):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        self.max_length = config.dataset.max_length\n",
    "    \n",
    "    def format_example(self, example):\n",
    "        \"\"\"Format a GSM8K example for training.\"\"\"\n",
    "        question = example['question']\n",
    "        answer = example['answer']\n",
    "        # Extract final answer\n",
    "        final_answer = answer.split('####')[-1].strip()\n",
    "        # Format as instruction and response\n",
    "        formatted_text = f\"Question: {question}\\nLet's solve this step by step:\\n{answer}\\nFinal Answer: {final_answer}\"\n",
    "        return formatted_text\n",
    "    \n",
    "    def tokenize_function(self, examples):\n",
    "        \"\"\"Tokenize a batch of formatted examples.\"\"\"\n",
    "        formatted_texts = [self.format_example(ex) for ex in examples]\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            formatted_texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "        return tokenized\n",
    "    \n",
    "    def prepare_dataset(self, dataset):\n",
    "        \"\"\"Prepare GSM8K dataset.\"\"\"\n",
    "        tokenized_dataset = dataset.map(\n",
    "            self.tokenize_function,\n",
    "            batched=True,\n",
    "            num_proc=self.config.dataset.num_workers,\n",
    "            remove_columns=dataset.column_names,\n",
    "        )\n",
    "        return tokenized_dataset\n",
    "\n",
    "def create_gsm8k_dataloader(config, split=\"train\"):\n",
    "    \"\"\"Create data loader for GSM8K dataset.\"\"\"\n",
    "    dataset = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "    \n",
    "    tokenizer = VishwamAITokenizer(\n",
    "        vocab_size=config.model.vocab_size,\n",
    "        model_prefix=config.model.name\n",
    "    )\n",
    "    \n",
    "    data_processor = GSM8KProcessor(tokenizer, config)\n",
    "    processed_dataset = data_processor.prepare_dataset(dataset)\n",
    "    \n",
    "    print(f\"Processed {len(processed_dataset)} examples for {split} split\")\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "model = VishwamAIModel(ModelConfig(**model_config))\n",
    "print(\"Model initialized with config:\", model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create dataloaders\n",
    "train_dataset = create_gsm8k_dataloader(training_config, split=\"train\")\n",
    "val_dataset = create_gsm8k_dataloader(training_config, split=\"validation\")\n",
    "\n",
    "# Set up checkpoint directory using repository path\n",
    "checkpoint_dir = repo_path / 'checkpoints' / 'gsm8k'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_checkpoint_hook(state, path):\n",
    "    \"\"\"Save checkpoint in safetensors format.\"\"\"\n",
    "    numpy_params = jax.tree_map(lambda x: np.array(x), state.params)\n",
    "    save_file(numpy_params, f\"{path}.safetensors\")\n",
    "    print(f\"Saved checkpoint to {path}.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run training with TPU mesh and sharding\n",
    "with mesh:\n",
    "    final_state = train(\n",
    "        model,\n",
    "        training_config,\n",
    "        train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_steps=training_config.max_steps,\n",
    "        log_every=training_config.logging_steps,\n",
    "        eval_every=training_config.eval_steps,\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        save_checkpoint_fn=save_checkpoint_hook,\n",
    "        sharding=sharding\n",
    "    )\n",
    "\n",
    "# Save final model\n",
    "final_path = checkpoint_dir / \"gsm8k_final.safetensors\"\n",
    "numpy_params = jax.tree_map(lambda x: np.array(x), final_state.params)\n",
    "save_file(numpy_params, str(final_path))\n",
    "print(f\"\\nTraining completed! Final model saved to {final_path}\")\n",
    "print(f\"Best metrics: {final_state.best_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
