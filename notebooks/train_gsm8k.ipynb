{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSM8K Math Problem Training\n",
    "\n",
    "This notebook implements training on the GSM8K dataset using TPU acceleration and optimized configurations for mathematical reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import jax\n",
    "from jax.experimental import mesh_utils\n",
    "from jax.experimental.maps import Mesh\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from vishwamai.training import train, create_train_state\n",
    "from vishwamai.model import VishwamAIModel, ModelConfig\n",
    "from vishwamai.tokenizer import VishwamAITokenizer\n",
    "from omegaconf import OmegaConf\n",
    "import logging\n",
    "from safetensors.flax import save_file\n",
    "import random\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Setup\n",
    "\n",
    "Configure TPU environment and create device mesh for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# TPU environment setup\n",
    "os.environ['TCMALLOC_LARGE_ALLOC_REPORT_THRESHOLD'] = '10000000000'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ['JAX_PLATFORMS'] = 'tpu'\n",
    "os.environ['JAX_ENABLE_X64'] = 'False'\n",
    "\n",
    "def setup_tpu_cluster():\n",
    "    \"\"\"Set up JAX TPU cluster configuration.\"\"\"\n",
    "    devices = jax.devices()\n",
    "    print(f\"Available devices: {devices}\")\n",
    "    \n",
    "    # Create mesh for data parallelism\n",
    "    mesh_shape = (8,)  # 8-core TPU\n",
    "    device_mesh = mesh_utils.create_device_mesh(mesh_shape)\n",
    "    mesh = Mesh(device_mesh, ('dp',))\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "mesh = setup_tpu_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configurations\n",
    "\n",
    "Load model and training configurations optimized for GSM8K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load configurations\n",
    "model_config = OmegaConf.load('../vishwamai/configs/model/10B.yaml')\n",
    "training_config = OmegaConf.load('../vishwamai/configs/training/gsm8k.yaml')\n",
    "\n",
    "print(\"Model config:\", model_config)\n",
    "print(\"\\nTraining config:\", training_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Implement GSM8K dataset processing with step-by-step solution formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class GSM8KProcessor:\n",
    "    \"\"\"Processor for GSM8K dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, config):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "        self.max_length = config.dataset.max_length\n",
    "    \n",
    "    def format_example(self, example):\n",
    "        \"\"\"Format a GSM8K example for training.\"\"\"\n",
    "        question = example['question']\n",
    "        answer = example['answer']\n",
    "        # Extract final answer\n",
    "        final_answer = answer.split('####')[-1].strip()\n",
    "        # Format as instruction and response\n",
    "        formatted_text = f\"Question: {question}\\nLet's solve this step by step:\\n{answer}\\nFinal Answer: {final_answer}\"\n",
    "        return formatted_text\n",
    "    \n",
    "    def tokenize_function(self, examples):\n",
    "        \"\"\"Tokenize a batch of formatted examples.\"\"\"\n",
    "        formatted_texts = [self.format_example(ex) for ex in examples]\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            formatted_texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        \n",
    "        tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "        return tokenized\n",
    "    \n",
    "    def prepare_dataset(self, dataset):\n",
    "        \"\"\"Prepare GSM8K dataset.\"\"\"\n",
    "        tokenized_dataset = dataset.map(\n",
    "            self.tokenize_function,\n",
    "            batched=True,\n",
    "            num_proc=self.config.dataset.num_workers,\n",
    "            remove_columns=dataset.column_names,\n",
    "        )\n",
    "        return tokenized_dataset\n",
    "\n",
    "def create_gsm8k_dataloader(config, split=\"train\"):\n",
    "    \"\"\"Create data loader for GSM8K dataset.\"\"\"\n",
    "    dataset = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "    \n",
    "    tokenizer = VishwamAITokenizer(\n",
    "        vocab_size=config.model.vocab_size,\n",
    "        model_prefix=config.model.name\n",
    "    )\n",
    "    \n",
    "    data_processor = GSM8KProcessor(tokenizer, config)\n",
    "    processed_dataset = data_processor.prepare_dataset(dataset)\n",
    "    \n",
    "    print(f\"Processed {len(processed_dataset)} examples for {split} split\")\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "model = VishwamAIModel(ModelConfig(**model_config))\n",
    "print(\"Model initialized with config:\", model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create dataloaders\n",
    "train_dataset = create_gsm8k_dataloader(training_config, split=\"train\")\n",
    "val_dataset = create_gsm8k_dataloader(training_config, split=\"validation\")\n",
    "\n",
    "# Create checkpoint directory\n",
    "checkpoint_dir = os.path.join(os.getcwd(), 'checkpoints', 'gsm8k')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "def save_checkpoint_hook(state, path):\n",
    "    \"\"\"Save checkpoint in safetensors format.\"\"\"\n",
    "    numpy_params = jax.tree_map(lambda x: np.array(x), state.params)\n",
    "    save_file(numpy_params, f\"{path}.safetensors\")\n",
    "    print(f\"Saved checkpoint to {path}.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run training with TPU mesh\n",
    "with mesh:\n",
    "    final_state = train(\n",
    "        model,\n",
    "        training_config,\n",
    "        train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        num_steps=training_config.max_steps,\n",
    "        log_every=training_config.logging_steps,\n",
    "        eval_every=training_config.eval_steps,\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        save_checkpoint_fn=save_checkpoint_hook\n",
    "    )\n",
    "\n",
    "# Save final model\n",
    "final_path = os.path.join(checkpoint_dir, \"gsm8k_final.safetensors\")\n",
    "numpy_params = jax.tree_map(lambda x: np.array(x), final_state.params)\n",
    "save_file(numpy_params, final_path)\n",
    "print(f\"\\nTraining completed! Final model saved to {final_path}\")\n",
    "print(f\"Best metrics: {final_state.best_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
