{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Distillation Training\n",
    "\n",
    "This notebook implements knowledge distillation from DeepSeek to a smaller VishwamAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/VishwamAI/VishwamAI.git\n",
    "%cd VishwamAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q transformers datasets accelerate bitsandbytes wandb safetensors sentencepiece flax optax omegaconf safetensors huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax.training import train_state\n",
    "\n",
    "from vishwamai.model import VishwamAIModel, ModelConfig\n",
    "from vishwamai.tokenizer import VishwamAITokenizer\n",
    "from vishwamai.distillation import VishwamaiGuruKnowledge, VishwamaiShaalaTrainer\n",
    "from vishwamai.data_utils import create_train_dataloader, create_val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher model config (DeepSeek)\n",
    "teacher_config = {\n",
    "    \"hidden_size\": 7168,\n",
    "    \"intermediate_size\": 18432,\n",
    "    \"num_attention_heads\": 128,\n",
    "    \"num_layers\": 61,\n",
    "    \"num_key_value_heads\": 128,\n",
    "    \"vocab_size\": 129280,\n",
    "    \"max_position_embeddings\": 163840\n",
    "}\n",
    "\n",
    "# Student model config (smaller VishwamAI)\n",
    "student_config = {\n",
    "    \"hidden_size\": 2048,  # Smaller hidden size\n",
    "    \"intermediate_size\": 8192,\n",
    "    \"num_attention_heads\": 32,\n",
    "    \"num_layers\": 24,  # Fewer layers\n",
    "    \"num_key_value_heads\": 32,\n",
    "    \"vocab_size\": 129280,\n",
    "    \"max_position_embeddings\": 163840\n",
    "}\n",
    "\n",
    "# Distillation configuration\n",
    "distillation_config = {\n",
    "    \"training\": {\n",
    "        \"max_steps\": 50000,\n",
    "        \"eval_steps\": 500,\n",
    "        \"save_steps\": 1000,\n",
    "        \"logging_steps\": 100,\n",
    "        \"warmup_steps\": 2000\n",
    "    },\n",
    "    \"distillation\": {\n",
    "        \"teacher_model\": {\n",
    "            \"path\": \"perplexity-ai/r1-1776\",\n",
    "            \"temperature\": 2.0,\n",
    "            \"alpha\": 0.5  # Weight between distillation and task loss\n",
    "        },\n",
    "        \"feature_distillation\": {\n",
    "            \"layers\": [0, 8, 16],  # Layer indices to match\n",
    "            \"loss_weight\": 0.1\n",
    "        },\n",
    "        \"attention_distillation\": {\n",
    "            \"loss_weight\": 0.1\n",
    "        },\n",
    "        \"hidden_distillation\": {\n",
    "            \"loss_weight\": 0.1\n",
    "        },\n",
    "        \"pruning\": {\n",
    "            \"enabled\": True,\n",
    "            \"target_sparsity\": 0.3,\n",
    "            \"begin_step\": 1000,\n",
    "            \"end_step\": 40000,\n",
    "            \"pruning_schedule\": \"cubic\"\n",
    "        },\n",
    "        \"quantization\": {\n",
    "            \"enabled\": True,\n",
    "            \"precision\": \"int8\"\n",
    "        }\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"beta1\": 0.9,\n",
    "        \"beta2\": 0.95,\n",
    "        \"clip_grad_norm\": 1.0\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train_batch_size\": 32,\n",
    "        \"eval_batch_size\": 32,\n",
    "        \"max_length\": 2048\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configurations\n",
    "Path(\"configs\").mkdir(exist_ok=True)\n",
    "config_path = Path(\"configs\")\n",
    "\n",
    "with open(config_path / \"teacher_config.json\", \"w\") as f:\n",
    "    json.dump(teacher_config, f, indent=2)\n",
    "\n",
    "with open(config_path / \"student_config.json\", \"w\") as f:\n",
    "    json.dump(student_config, f, indent=2)\n",
    "\n",
    "with open(config_path / \"distillation_config.yaml\", \"w\") as f:\n",
    "    OmegaConf.save(OmegaConf.create(distillation_config), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize teacher model\n",
    "teacher_model = VishwamAIModel(ModelConfig(**teacher_config))\n",
    "teacher_model.load_weights(distillation_config['distillation']['teacher_model']['path'])\n",
    "\n",
    "# Initialize student model\n",
    "student_model = VishwamAIModel(ModelConfig(**student_config))\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = VishwamAITokenizer(\n",
    "    vocab_size=teacher_config[\"vocab_size\"],\n",
    "    model_prefix=\"vishwamai\"\n",
    ")\n",
    "\n",
    "# Initialize distillation trainer\n",
    "trainer = VishwamaiShaalaTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    cfg=OmegaConf.create(distillation_config)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"VishwamAI\",\n",
    "    name=\"vishwamai-distillation\",\n",
    "    config=distillation_config\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = create_train_dataloader(OmegaConf.create(distillation_config))\n",
    "val_loader = create_val_dataloader(OmegaConf.create(distillation_config))\n",
    "\n",
    "# Initialize training state\n",
    "rng = jax.random.PRNGKey(42)\n",
    "state = trainer.create_train_state(rng)\n",
    "\n",
    "# Initialize guru knowledge with feature matching\n",
    "guru = VishwamaiGuruKnowledge(OmegaConf.create(distillation_config))\n",
    "\n",
    "# Training loop with guru knowledge\n",
    "try:\n",
    "    for step in range(distillation_config['training']['max_steps']):\n",
    "        batch = next(train_loader)\n",
    "        \n",
    "        # Get teacher predictions and features\n",
    "        teacher_outputs = teacher_model(\n",
    "            batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            output_hidden_states=True,\n",
    "            output_attentions=True\n",
    "        )\n",
    "        \n",
    "        # Training step with knowledge distillation\n",
    "        state, metrics, rng = trainer.train_step(\n",
    "            state=state,\n",
    "            batch=batch,\n",
    "            teacher_outputs=teacher_outputs,\n",
    "            guru=guru,\n",
    "            step=step,\n",
    "            rng=rng\n",
    "        )\n",
    "        \n",
    "        # Enhanced logging with distillation metrics\n",
    "        if step % distillation_config['training']['logging_steps'] == 0:\n",
    "            distill_metrics = {\n",
    "                'kd_loss': metrics['kd_loss'],\n",
    "                'feature_loss': metrics.get('feature_loss', 0.0),\n",
    "                'attention_loss': metrics.get('attention_loss', 0.0),\n",
    "                'hidden_loss': metrics.get('hidden_loss', 0.0),\n",
    "                'total_loss': metrics['total_loss'],\n",
    "                'temperature': guru.temperature\n",
    "            }\n",
    "            wandb.log({**metrics, **distill_metrics}, step=step)\n",
    "            \n",
    "            # Print current distillation progress\n",
    "            print(f\"\\nStep {step}:\")\n",
    "            print(f\"KD Loss: {distill_metrics['kd_loss']:.4f}\")\n",
    "            print(f\"Feature Loss: {distill_metrics['feature_loss']:.4f}\")\n",
    "            print(f\"Total Loss: {distill_metrics['total_loss']:.4f}\")\n",
    "        \n",
    "        # Evaluation with feature matching\n",
    "        if step % distillation_config['training']['eval_steps'] == 0:\n",
    "            eval_metrics = trainer.evaluate(\n",
    "                state=state,\n",
    "                val_loader=val_loader,\n",
    "                teacher_model=teacher_model,\n",
    "                guru=guru\n",
    "            )\n",
    "            wandb.log({f\"eval_{k}\": v for k, v in eval_metrics.items()}, step=step)\n",
    "        \n",
    "        # Dynamic temperature adjustment based on training progress\n",
    "        if step % 1000 == 0:\n",
    "            guru.temperature = max(\n",
    "                1.0,  # Minimum temperature\n",
    "                guru.temperature * 0.95  # Gradual temperature decay\n",
    "            )\n",
    "        \n",
    "        # Save checkpoint with distillation state\n",
    "        if step % distillation_config['training']['save_steps'] == 0:\n",
    "            ckpt_path = f\"checkpoints/step_{step}\"\n",
    "            trainer.save_checkpoint(\n",
    "                state=state,\n",
    "                path=ckpt_path,\n",
    "                guru=guru,  # Save guru state\n",
    "                metadata={\n",
    "                    'temperature': guru.temperature,\n",
    "                    'step': step,\n",
    "                    'metrics': metrics\n",
    "                }\n",
    "            )\n",
    "            \n",
    "    # Final quantization with teacher guidance\n",
    "    if distillation_config['distillation']['quantization']['enabled']:\n",
    "        state = trainer.quantize_model(\n",
    "            state=state,\n",
    "            val_loader=val_loader,\n",
    "            teacher_model=teacher_model,\n",
    "            guru=guru,\n",
    "            num_calibration_steps=100\n",
    "        )\n",
    "        trainer.save_checkpoint(state, \"checkpoints/quantized\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {str(e)}\")\n",
    "finally:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Push distilled model to HuggingFace Hub\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"VishwamAI/VishwamAI-small\"\n",
    "api.create_repo(repo_id, exist_ok=True)\n",
    "\n",
    "# Upload model files\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"configs/student_config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=repo_id\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"checkpoints/quantized/model.safetensors\",\n",
    "    path_in_repo=\"model.safetensors\",\n",
    "    repo_id=repo_id\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"tokenizer/vishwamai.model\",\n",
    "    path_in_repo=\"tokenizer.model\",\n",
    "    repo_id=repo_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare teacher and student model performance\n",
    "def evaluate_models(teacher, student, val_loader, num_batches=10):\n",
    "    teacher_metrics = []\n",
    "    student_metrics = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        batch = next(val_loader)\n",
    "        \n",
    "        # Teacher predictions\n",
    "        teacher_output = teacher(batch['input_ids'], deterministic=True)\n",
    "        teacher_metrics.append({\n",
    "            'loss': float(teacher_output['loss']),\n",
    "            'accuracy': float(teacher_output.get('accuracy', 0))\n",
    "        })\n",
    "        \n",
    "        # Student predictions\n",
    "        student_output = student(batch['input_ids'], deterministic=True)\n",
    "        student_metrics.append({\n",
    "            'loss': float(student_output['loss']),\n",
    "            'accuracy': float(student_output.get('accuracy', 0))\n",
    "        })\n",
    "    \n",
    "    # Calculate averages\n",
    "    teacher_avg = {k: sum(m[k] for m in teacher_metrics) / len(teacher_metrics)\n",
    "                  for k in teacher_metrics[0]}\n",
    "    student_avg = {k: sum(m[k] for m in student_metrics) / len(student_metrics)\n",
    "                   for k in student_metrics[0]}\n",
    "    \n",
    "    return {\n",
    "        'teacher': teacher_avg,\n",
    "        'student': student_avg,\n",
    "        'compression_ratio': f\"{teacher.param_count / student.param_count:.2f}x\"\n",
    "    }\n",
    "\n",
    "results = evaluate_models(teacher_model, student_model, val_loader)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Compression Ratio: {results['compression_ratio']}\")\n",
    "print(\"\\nTeacher Model:\")\n",
    "print(f\"Loss: {results['teacher']['loss']:.4f}\")\n",
    "print(f\"Accuracy: {results['teacher']['accuracy']:.4f}\")\n",
    "print(\"\\nStudent Model:\")\n",
    "print(f\"Loss: {results['student']['loss']:.4f}\")\n",
    "print(f\"Accuracy: {results['student']['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model paths\n",
    "TEACHER_MODEL_PATH = \"perplexity-ai/r1-1776\"\n",
    "OUTPUT_MODEL_PATH = \"VishwamAI/Perplexity_r1_disttled_experiment\"\n",
    "\n",
    "# Verify teacher model files exist\n",
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Download teacher model files\n",
    "teacher_path = snapshot_download(\n",
    "    repo_id=TEACHER_MODEL_PATH,\n",
    "    allow_patterns=[\"*.safetensors\", \"config.json\", \"tokenizer.model\"]\n",
    ")\n",
    "print(f\"Downloaded teacher model to {teacher_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified model saving logic\n",
    "def save_sharded_model(state, save_dir, num_shards=252):\n",
    "    \"\"\"Save model weights in sharded safetensor format.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Get model parameters\n",
    "    params = state.params\n",
    "    \n",
    "    # Calculate parameters per shard\n",
    "    total_params = sum(p.size for p in jax.tree_leaves(params))\n",
    "    params_per_shard = total_params // num_shards\n",
    "    \n",
    "    # Save in sharded format\n",
    "    current_shard = 0\n",
    "    current_size = 0\n",
    "    shard_dict = {}\n",
    "    \n",
    "    for name, param in params.items():\n",
    "        param_size = param.size\n",
    "        \n",
    "        if current_size + param_size > params_per_shard:\n",
    "            # Save current shard\n",
    "            shard_path = os.path.join(\n",
    "                save_dir, \n",
    "                f\"model-{current_shard+1:05d}-of-{num_shards:05d}.safetensors\"\n",
    "            )\n",
    "            safetensors.save_file(shard_dict, shard_path)\n",
    "            \n",
    "            # Start new shard\n",
    "            current_shard += 1\n",
    "            current_size = 0\n",
    "            shard_dict = {}\n",
    "        \n",
    "        shard_dict[name] = param\n",
    "        current_size += param_size\n",
    "    \n",
    "    # Save final shard\n",
    "    if shard_dict:\n",
    "        shard_path = os.path.join(\n",
    "            save_dir,\n",
    "            f\"model-{current_shard+1:05d}-of-{num_shards:05d}.safetensors\"\n",
    "        )\n",
    "        safetensors.save_file(shard_dict, shard_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified model export cell\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Push distilled model to HuggingFace Hub\n",
    "api = HfApi()\n",
    "\n",
    "# Save model in sharded format\n",
    "save_dir = \"checkpoints/final\"\n",
    "save_sharded_model(state, save_dir)\n",
    "\n",
    "# Upload to HF Hub\n",
    "api.create_repo(OUTPUT_MODEL_PATH, exist_ok=True)\n",
    "\n",
    "# Upload configuration\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"configs/student_config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=OUTPUT_MODEL_PATH\n",
    ")\n",
    "\n",
    "# Upload all model shards\n",
    "for shard_file in sorted(os.listdir(save_dir)):\n",
    "    if shard_file.endswith(\".safetensors\"):\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=os.path.join(save_dir, shard_file),\n",
    "            path_in_repo=shard_file,\n",
    "            repo_id=OUTPUT_MODEL_PATH\n",
    "        )\n",
    "\n",
    "# Upload tokenizer\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"tokenizer/vishwamai.model\", \n",
    "    path_in_repo=\"tokenizer.model\",\n",
    "    repo_id=OUTPUT_MODEL_PATH\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
