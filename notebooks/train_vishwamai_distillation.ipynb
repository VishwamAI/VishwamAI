{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Enhanced Distillation with ToT and Error Correction\n",
    "\n",
    "This notebook implements knowledge distillation from larger models to a smaller VishwamAI model with Tree of Thoughts (ToT) integration and error correction components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/VishwamAI/VishwamAI.git\n",
    "%cd VishwamAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q transformers datasets accelerate bitsandbytes wandb safetensors sentencepiece flax optax omegaconf safetensors huggingface-hub einops mlflow aim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import aim\n",
    "from omegaconf import OmegaConf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from flax.training import train_state\n",
    "from huggingface_hub import snapshot_download, HfApi\n",
    "import safetensors.flax as stf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"vishwamai_distillation\")\n",
    "\n",
    "# Import VishwamAI components\n",
    "from vishwamai.model import VishwamAIModel, ModelConfig\n",
    "from vishwamai.tokenizer import VishwamAITokenizer\n",
    "from vishwamai.tot import TreeOfThoughts\n",
    "from vishwamai.integration import ToTIntegrationLayer, MixtureDensityNetwork, MultiLevelToTAttention\n",
    "from vishwamai.error_correction_trainer import ErrorCorrectionTrainer\n",
    "from vishwamai.training import train, create_train_dataloader, create_val_dataloader\n",
    "from vishwamai.transformer import VishwamAIModel as VisionTransformer10B\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Configuration Setup\n",
    "\n",
    "Setting up configuration for distillation with Tree of Thoughts and Error Correction components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced configuration with ToT and Error Correction components\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"vocab_size\": 129280,\n",
    "        \"hidden_size\": 2048,  # Smaller hidden size for student model\n",
    "        \"num_layers\": 24,  # Fewer layers\n",
    "        \"num_attention_heads\": 32,\n",
    "        \"intermediate_size\": 8192,\n",
    "        \"hidden_dropout_prob\": 0.1,\n",
    "        \"attention_dropout_prob\": 0.1,\n",
    "        \"max_position_embeddings\": 4096,  # Reduced context length for better training efficiency\n",
    "        \"initializer_range\": 0.02,\n",
    "        \"layer_norm_eps\": 1e-5,\n",
    "        \"use_cache\": True,\n",
    "        \"pad_token_id\": 0,\n",
    "        \"bos_token_id\": 1,\n",
    "        \"eos_token_id\": 2,\n",
    "        \"tie_word_embeddings\": True,\n",
    "        \"use_flash_attention\": True,\n",
    "        \"use_rope\": True,\n",
    "        \"use_alibi\": False,\n",
    "        \"use_gqa\": True,\n",
    "        \"num_key_value_heads\": 32,\n",
    "        \"dtype\": \"bfloat16\",\n",
    "        \n",
    "        # MoE configuration\n",
    "        \"moe_enabled\": True,\n",
    "        \"num_experts\": 8,\n",
    "        \"expert_capacity\": 0.25,\n",
    "        \"expert_dropout\": 0.1,\n",
    "        \"moe_layers\": [5, 11, 17, 23],  # Specific layers to use MoE\n",
    "        \n",
    "        # MoD configuration\n",
    "        \"use_mod\": True,\n",
    "        \"mod_num_mixtures\": 5,\n",
    "        \"mod_balance_weight\": 0.01,\n",
    "        \n",
    "        # ToT configuration\n",
    "        \"use_tot\": True\n",
    "    },\n",
    "    \n",
    "    \"training\": {\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"warmup_steps\": 1000,\n",
    "        \"max_steps\": 100000,\n",
    "        \"batch_size\": 16,\n",
    "        \"eval_batch_size\": 8,\n",
    "        \"adam_beta1\": 0.9,\n",
    "        \"adam_beta2\": 0.999,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"z_loss\": 0.01,\n",
    "        \"log_every\": 100,\n",
    "        \"eval_every\": 1000,\n",
    "        \"save_every\": 5000,\n",
    "        \"checkpoint_dir\": \"checkpoints/tot_distillation\",\n",
    "        \"seed\": 42,\n",
    "        \"logging_steps\": 100,\n",
    "        \"eval_steps\": 1000,\n",
    "        \"save_steps\": 5000,\n",
    "        \n",
    "        # ToT specific training config\n",
    "        \"use_tot\": True,\n",
    "        \"tot_search_strategy\": \"beam\",\n",
    "        \"tot_max_thoughts\": 5,\n",
    "        \"tot_max_depth\": 3,\n",
    "        \"tot_beam_width\": 8,\n",
    "        \"tot_pruning_threshold\": 0.3,\n",
    "        \"tot_exploration_factor\": 1.0,\n",
    "        \"tot_guidance_alpha\": 0.2,\n",
    "        \n",
    "        # Error correction config\n",
    "        \"use_error_correction\": True,\n",
    "        \"error_history_size\": 100,\n",
    "        \"error_threshold_percentile\": 85.0,\n",
    "        \"ec_loss_weight\": 0.2\n",
    "    },\n",
    "    \n",
    "    \"data\": {\n",
    "        \"dataset_name\": \"c4\",\n",
    "        \"train_split\": \"train\",\n",
    "        \"val_split\": \"validation\",\n",
    "        \"text_column\": \"text\",\n",
    "        \"max_seq_length\": 1024,\n",
    "        \"preprocessing_num_workers\": 4,\n",
    "        \"max_train_samples\": 100000,\n",
    "        \"max_val_samples\": 5000\n",
    "    },\n",
    "    \n",
    "    \"distillation\": {\n",
    "        \"teacher_model\": {\n",
    "            \"path\": \"perplexity-ai/r1-1776\",\n",
    "            \"config\": {\n",
    "                \"hidden_size\": 7168,\n",
    "                \"intermediate_size\": 18432,\n",
    "                \"num_attention_heads\": 128,\n",
    "                \"num_layers\": 61,\n",
    "                \"num_key_value_heads\": 128,\n",
    "                \"vocab_size\": 129280,\n",
    "                \"max_position_embeddings\": 163840\n",
    "            }\n",
    "        },\n",
    "        \"kd_temperature\": 2.0,\n",
    "        \"alpha_kd\": 0.5,  # Weight for KL divergence loss\n",
    "        \"alpha_ce\": 0.5,  # Weight for cross-entropy loss\n",
    "        \"alpha_tot\": 0.2,  # Weight for ToT guidance\n",
    "        \"feature_matching\": True,  # Whether to match intermediate features\n",
    "        \"feature_layers\": [5, 11, 17, 23],  # Layers to match features\n",
    "        \"quantization\": {\n",
    "            \"enabled\": False\n",
    "        },\n",
    "        \"output_path\": \"VishwamAI/tot-enhanced-distilled-model\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to OmegaConf format\n",
    "config = OmegaConf.create(config)\n",
    "\n",
    "# Create directories for checkpoint saving\n",
    "os.makedirs(config.training.checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Initialize Teacher Model\n",
    "\n",
    "Downloading the teacher model with reduced shards to manage memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_partial_model(model_path: str, num_shards: int = 5):\n",
    "    \"\"\"Download only specified number of model shards\"\"\"\n",
    "    patterns = [f\"model-{i+1:05d}-of-00252.safetensors\" for i in range(num_shards)]\n",
    "    patterns.extend([\"config.json\", \"tokenizer.model\"])  # Add other required files\n",
    "\n",
    "    try:\n",
    "        local_path = snapshot_download(\n",
    "            repo_id=model_path,\n",
    "            allow_patterns=patterns,\n",
    "            local_files_only=False,\n",
    "            resume_download=True\n",
    "        )\n",
    "        print(f\"Successfully downloaded {num_shards} model shards to {local_path}\")\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error downloading model shards: {str(e)}\")\n",
    "\n",
    "# Download partial teacher model\n",
    "teacher_path = download_partial_model(\n",
    "    config.distillation.teacher_model.path,\n",
    "    num_shards=5  # Reduced for memory efficiency\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models and Components\n",
    "\n",
    "Setting up teacher model, student model, and associated components for ToT integration and error correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize error correction trainer\n",
    "error_trainer = ErrorCorrectionTrainer(\n",
    "    config=config,\n",
    "    use_tot=config.training.use_tot,\n",
    "    use_mod=config.model.use_mod,\n",
    "    history_size=config.training.error_history_size,\n",
    "    threshold_percentile=config.training.error_threshold_percentile\n",
    ")\n",
    "\n",
    "# Initialize teacher model (with reduced size for memory efficiency)\n",
    "teacher_config = ModelConfig(**config.distillation.teacher_model.config)\n",
    "teacher_model = VishwamAIModel(teacher_config)\n",
    "teacher_model.load_weights(teacher_path, reduced_size=True)\n",
    "print(\"Teacher model loaded successfully\")\n",
    "\n",
    "# Initialize student model\n",
    "student_config = ModelConfig(**config.model)\n",
    "student_model = VishwamAIModel(student_config)\n",
    "print(\"Student model initialized\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = VishwamAITokenizer(\n",
    "    vocab_size=config.model.vocab_size,\n",
    "    model_prefix=\"vishwamai\",\n",
    "    error_tokens=True  # Enable error tokens for integration with error correction\n",
    ")\n",
    "print(\"Tokenizer initialized with error correction tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tree of Thoughts components for student model\n",
    "vision_transformer = VisionTransformer10B(student_config)\n",
    "tot_model = TreeOfThoughts(\n",
    "    transformer=vision_transformer,\n",
    "    max_thoughts=config.training.tot_max_thoughts,\n",
    "    max_depth=config.training.tot_max_depth,\n",
    "    beam_width=config.training.tot_beam_width,\n",
    "    pruning_threshold=config.training.tot_pruning_threshold,\n",
    "    exploration_factor=config.training.tot_exploration_factor\n",
    ")\n",
    "\n",
    "# Create integration components\n",
    "tot_integration = ToTIntegrationLayer(config.model)\n",
    "mla = MultiLevelToTAttention(\n",
    "    hidden_size=config.model.hidden_size,\n",
    "    num_heads=min(8, config.model.num_attention_heads)\n",
    ")\n",
    "print(\"ToT components initialized\")\n",
    "\n",
    "# Create MoD component if enabled\n",
    "if config.model.use_mod:\n",
    "    mod_layer = MixtureDensityNetwork(\n",
    "        hidden_size=config.model.hidden_size,\n",
    "        num_mixtures=config.model.mod_num_mixtures\n",
    "    )\n",
    "    student_model.mod_layer = mod_layer\n",
    "    print(\"MoD components initialized\")\n",
    "\n",
    "# Add components to student model\n",
    "student_model.tot_model = tot_model\n",
    "student_model.tot_integration = tot_integration\n",
    "student_model.tot_mla = mla\n",
    "student_model.use_tot = config.model.use_tot\n",
    "student_model.use_mod = config.model.use_mod\n",
    "\n",
    "print(\"All advanced components integrated into student model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Enhanced Knowledge Distillation Loss\n",
    "\n",
    "Creating a specialized loss function that combines standard KD loss with ToT guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.nn as nn\n",
    "\n",
    "def tot_guided_distillation_loss(\n",
    "    student_logits, \n",
    "    teacher_logits, \n",
    "    labels, \n",
    "    tot_outputs=None, \n",
    "    temperature=1.0,\n",
    "    alpha_kd=0.5, \n",
    "    alpha_ce=0.5, \n",
    "    alpha_tot=0.2\n",
    "):\n",
    "    \"\"\"Enhanced KD loss with ToT guidance.\"\"\"\n",
    "    \n",
    "    # KL divergence loss between student and teacher\n",
    "    teacher_probs = nn.softmax(teacher_logits / temperature)\n",
    "    kd_loss = -jnp.sum(teacher_probs * nn.log_softmax(student_logits / temperature)) * (temperature ** 2)\n",
    "    \n",
    "    # Standard cross entropy with ground truth\n",
    "    ce_loss = -jnp.sum(nn.one_hot(labels, student_logits.shape[-1]) * nn.log_softmax(student_logits))\n",
    "    \n",
    "    # Add ToT guidance if available\n",
    "    tot_loss = 0.0\n",
    "    if tot_outputs is not None and alpha_tot > 0.0:\n",
    "        attention_weights = tot_outputs.get('attention_weights', None)\n",
    "        if attention_weights is not None:\n",
    "            # Use ToT attention weights to guide where to focus learning\n",
    "            attention_weights_flat = jnp.mean(attention_weights, axis=(0, 1))\n",
    "            teacher_probs_weighted = teacher_probs * attention_weights_flat\n",
    "            tot_loss = -jnp.sum(teacher_probs_weighted * nn.log_softmax(student_logits / temperature))\n",
    "    \n",
    "    # Add feature matching loss if available\n",
    "    feature_loss = 0.0\n",
    "    if 'feature_loss' in tot_outputs:\n",
    "        feature_loss = tot_outputs['feature_loss']\n",
    "    \n",
    "    # Combine losses with weights\n",
    "    combined_loss = alpha_kd * kd_loss + alpha_ce * ce_loss\n",
    "    if tot_outputs is not None and alpha_tot > 0.0:\n",
    "        combined_loss += alpha_tot * (tot_loss + feature_loss)\n",
    "        \n",
    "    return combined_loss, {\n",
    "        \"kd_loss\": kd_loss, \n",
    "        \"ce_loss\": ce_loss, \n",
    "        \"tot_loss\": tot_loss,\n",
    "        \"feature_loss\": feature_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Loaders\n",
    "\n",
    "Setting up data loaders for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "logger.info(\"Creating data loaders...\")\n",
    "train_loader = create_train_dataloader(config)\n",
    "val_loader = create_val_dataloader(config)\n",
    "logger.info(\"Data loaders created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Training with ToT and Error Correction\n",
    "\n",
    "Running the training process with tracking and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize experiment tracking\n",
    "mlflow.set_experiment(\"VishwamAI-ToT-Distillation\")\n",
    "aim_run = aim.Run(experiment=\"VishwamAI-ToT-Distillation\")\n",
    "logger.info(\"Starting advanced training with ToT and error correction\")\n",
    "\n",
    "# Get JAX PRNGKey for reproducibility\n",
    "rng_key = jax.random.PRNGKey(config.training.seed)\n",
    "\n",
    "# Track configurations in experiment tools\n",
    "config_dict = OmegaConf.to_container(config)\n",
    "aim_run.set_params(config_dict)\n",
    "\n",
    "# Run training with ToT and error correction integration\n",
    "with mlflow.start_run() as run:\n",
    "    # Log important configuration parameters\n",
    "    mlflow.log_params({\n",
    "        \"model.hidden_size\": config.model.hidden_size,\n",
    "        \"model.num_layers\": config.model.num_layers,\n",
    "        \"model.num_attention_heads\": config.model.num_attention_heads,\n",
    "        \"training.learning_rate\": config.training.learning_rate,\n",
    "        \"training.batch_size\": config.training.batch_size,\n",
    "        \"training.use_tot\": config.training.use_tot,\n",
    "        \"training.use_error_correction\": config.training.use_error_correction,\n",
    "        \"model.use_mod\": config.model.use_mod,\n",
    "        \"distillation.kd_temperature\": config.distillation.kd_temperature,\n",
    "        \"distillation.alpha_tot\": config.distillation.alpha_tot\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        # Start the training\n",
    "        final_state = train(\n",
    "            model=student_model,\n",
    "            config=config,\n",
    "            train_dataloader=train_loader,\n",
    "            val_dataloader=val_loader,\n",
    "            num_steps=config.training.max_steps,\n",
    "            log_every=config.training.log_every,\n",
    "            eval_every=config.training.eval_every,\n",
    "            checkpoint_dir=config.training.checkpoint_dir\n",
    "        )\n",
    "        \n",
    "        # Log final metrics\n",
    "        final_metrics = {\n",
    "            \"final_loss\": float(final_state.best_metrics['loss']),\n",
    "            \"final_accuracy\": float(final_state.best_metrics['accuracy']),\n",
    "            \"ec_improvement\": float(final_state.best_metrics.get('ec_improvement', 0.0))\n",
    "        }\n",
    "        \n",
    "        # Log to both tracking systems\n",
    "        mlflow.log_metrics(final_metrics)\n",
    "        for k, v in final_metrics.items():\n",
    "            aim_run.track(v, name=k)\n",
    "        \n",
    "        # Log model artifacts\n",
    "        mlflow.log_artifacts(config.training.checkpoint_dir)\n",
    "        \n",
    "        logger.info(\"Training completed successfully!\")\n",
    "        logger.info(f\"Best loss: {final_state.best_metrics['loss']:.4f}\")\n",
    "        logger.info(f\"Best accuracy: {final_state.best_metrics['accuracy']:.4f}\")\n",
    "        logger.info(f\"Error correction improvement: {final_state.best_metrics.get('ec_improvement', 0.0):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {str(e)}\")\n",
    "        mlflow.log_param(\"error\", str(e))\n",
    "        aim_run.set_params({\"error\": str(e)})\n",
    "    finally:\n",
    "        aim_run.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Results\n",
    "\n",
    "Creating visualizations of the training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics from the training run\n",
    "def get_training_metrics_from_mlflow(run_id=None):\n",
    "    \"\"\"Get metrics from MLflow tracking.\"\"\"\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    if run_id is None:\n",
    "        runs = client.search_runs(experiment_ids=[mlflow.get_experiment_by_name(\"VishwamAI-ToT-Distillation\").experiment_id])\n",
    "        if not runs:\n",
    "            return {}\n",
    "        run = runs[0]  # Get the latest run\n",
    "        run_id = run.info.run_id\n",
    "    \n",
    "    run = client.get_run(run_id)\n",
    "    metrics_data = run.data.metrics\n",
    "    \n",
    "    # Get metrics history for certain key metrics\n",
    "    metric_keys = [\"loss\", \"accuracy\", \"ec_improvement\", \"tot_score\", \"kd_loss\"]\n",
    "    metrics_history = {}\n",
    "    \n",
    "    for key in metric_keys:\n",
    "        if key in metrics_data:\n",
    "            metrics_history[key] = [\n",
    "                (m.step, m.value) for m in client.get_metric_history(run_id, key)\n",
    "            ]\n",
    "    \n",
    "    return metrics_history\n",
    "\n",
    "# Create visualizations\n",
    "metrics = get_training_metrics_from_mlflow()\n",
    "\n",
    "if metrics:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    if 'loss' in metrics:\n",
    "        steps, values = zip(*metrics['loss'])\n",
    "        plt.plot(steps, values, label='Training Loss')\n",
    "    if 'kd_loss' in metrics:\n",
    "        steps, values = zip(*metrics['kd_loss'])\n",
    "        plt.plot(steps, values, label='KD Loss')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and KD Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    if 'accuracy' in metrics:\n",
    "        steps, values = zip(*metrics['accuracy'])\n",
    "        plt.plot(steps, values)\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot error correction improvement\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if 'ec_improvement' in metrics:\n",
    "        steps, values = zip(*metrics['ec_improvement'])\n",
    "        plt.plot(steps, values)\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Error Correction Improvement (%)')\n",
    "    plt.title('Error Correction Impact')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot ToT score\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'tot_score' in metrics:\n",
    "        steps, values = zip(*metrics['tot_score'])\n",
    "        plt.plot(steps, values)\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('ToT Score')\n",
    "    plt.title('Tree of Thoughts Quality Score')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No metrics available to visualize.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
