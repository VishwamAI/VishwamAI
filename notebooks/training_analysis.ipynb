{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b069c32b",
   "metadata": {},
   "source": [
    "# VishwamAI Training Performance Analysis\n",
    "\n",
    "This notebook analyzes the training performance of VishwamAI model using the provided train/test parquet datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80475a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Any\n",
    "\n",
    "from vishwamai.training import TPUTrainingConfig, create_train_state_tpu, create_train_step_tpu\n",
    "from vishwamai.profiler import TPUProfiler\n",
    "from vishwamai.transformer import create_vishwamai_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train_data = pd.read_parquet('train-00000-of-00001.parquet')\n",
    "test_data = pd.read_parquet('test-00000-of-00001.parquet')\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_config():\n",
    "    \"\"\"Create TPU-optimized training configuration\"\"\"\n",
    "    model_config = {\n",
    "        'vocab_size': 32000,\n",
    "        'num_layers': 12,\n",
    "        'num_heads': 12,\n",
    "        'head_dim': 64,\n",
    "        'hidden_dim': 768,\n",
    "        'mlp_dim': 3072,\n",
    "        'max_seq_len': 2048,\n",
    "        'dropout_rate': 0.1,\n",
    "        'use_flash_attn': True,\n",
    "        'use_rms_norm': False\n",
    "    }\n",
    "    \n",
    "    return TPUTrainingConfig(\n",
    "        model_config=model_config,\n",
    "        batch_size=32,\n",
    "        grad_accum_steps=4,\n",
    "        learning_rate=1e-4,\n",
    "        warmup_steps=2000,\n",
    "        max_steps=100000,\n",
    "        dtype='bfloat16',\n",
    "        enable_pjit=True,\n",
    "        block_size=128,\n",
    "        use_flash_attn=True,\n",
    "        mixed_precision=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training components\n",
    "config = create_training_config()\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "# Create training state and step function\n",
    "state = create_train_state_tpu(config, rng)\n",
    "train_step = create_train_step_tpu(config, state)\n",
    "\n",
    "# Initialize profiler\n",
    "profiler = TPUProfiler(config=config.model_config, log_dir='training_profiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_training_metrics(profiler: TPUProfiler, num_steps: int = 100):\n",
    "    \"\"\"Analyze training metrics over multiple steps\"\"\"\n",
    "    metrics = {\n",
    "        'step_time': [],\n",
    "        'throughput': [],\n",
    "        'memory_used': [],\n",
    "        'tpu_utilization': []\n",
    "    }\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        profiler.start_step()\n",
    "        \n",
    "        # Simulate training step\n",
    "        batch_size = config.batch_size * config.grad_accum_steps\n",
    "        profiler.record_batch_time(batch_size, 0.1)  # Example duration\n",
    "        profiler.measure_tpu_utilization()\n",
    "        \n",
    "        profiler.end_step()\n",
    "        \n",
    "        # Collect metrics\n",
    "        summary = profiler.get_metrics_summary()\n",
    "        metrics['step_time'].append(summary['step_time_mean'])\n",
    "        metrics['throughput'].append(summary.get('steps_per_second', 0))\n",
    "        metrics['memory_used'].append(summary.get('memory_accessed_mean', 0))\n",
    "        metrics['tpu_utilization'].append(summary.get('tpu_utilization_mean', 0))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run analysis\n",
    "training_metrics = analyze_training_metrics(profiler)\n",
    "\n",
    "# Plot metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Performance Metrics')\n",
    "\n",
    "axes[0, 0].plot(training_metrics['step_time'])\n",
    "axes[0, 0].set_title('Step Time')\n",
    "axes[0, 0].set_xlabel('Step')\n",
    "axes[0, 0].set_ylabel('Time (s)')\n",
    "\n",
    "axes[0, 1].plot(training_metrics['throughput'])\n",
    "axes[0, 1].set_title('Throughput')\n",
    "axes[0, 1].set_xlabel('Step')\n",
    "axes[0, 1].set_ylabel('Steps/second')\n",
    "\n",
    "axes[1, 0].plot(training_metrics['memory_used'])\n",
    "axes[1, 0].set_title('Memory Usage')\n",
    "axes[1, 0].set_xlabel('Step')\n",
    "axes[1, 0].set_ylabel('Bytes')\n",
    "\n",
    "axes[1, 1].plot(training_metrics['tpu_utilization'])\n",
    "axes[1, 1].set_title('TPU Utilization')\n",
    "axes[1, 1].set_xlabel('Step')\n",
    "axes[1, 1].set_ylabel('Utilization %')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52722ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance recommendations\n",
    "recommendations = profiler.get_performance_recommendations()\n",
    "print(\"\\nPerformance Recommendations:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb875b",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Current metrics from previous analysis:\n",
    "- Total Parameters: 109,529,088\n",
    "- MoE Parameters: 301,991,936\n",
    "- Memory Usage:\n",
    "  - Activations: 96.00 MB\n",
    "  - Attention: 3072.00 MB\n",
    "  - KV Cache: 192.00 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_model_performance(config: Dict[str, Any]):\n",
    "    \"\"\"Profile model inference performance\"\"\"\n",
    "    model = create_vishwamai_transformer(config)\n",
    "    batch_size = 1\n",
    "    seq_length = config['max_seq_len']\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = jnp.ones((batch_size, seq_length), dtype=jnp.int32)\n",
    "    \n",
    "    # Profile memory\n",
    "    memory_profile = profiler.profile_memory_usage(\n",
    "        lambda x: model.apply({'params': state.params}, x),\n",
    "        {'input': dummy_input.shape}\n",
    "    )\n",
    "    \n",
    "    return memory_profile\n",
    "\n",
    "# Run performance profiling\n",
    "perf_metrics = profile_model_performance(config.model_config)\n",
    "print(\"\\nModel Performance Profile:\")\n",
    "for k, v in perf_metrics.items():\n",
    "    print(f\"{k}: {v/1e9:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
