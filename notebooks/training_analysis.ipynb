{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b069c32b",
   "metadata": {},
   "source": [
    "# VishwamAI Training Performance Analysis\n",
    "\n",
    "This notebook analyzes the training performance with TPU optimizations and fixed FlashAttention implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80475a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 13:13:32.746850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742370212.772737   14809 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742370212.781544   14809 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Any\n",
    "\n",
    "from vishwamai.training import create_train_state_tpu, create_train_step_tpu\n",
    "from vishwamai.profiler import TPUProfiler\n",
    "from vishwamai.transformer import create_vishwamai_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9511c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train-00000-of-00001.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load training and test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain-00000-of-00001.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest-00000-of-00001.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-00000-of-00001.parquet'"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "train_data = pd.read_parquet('/home/kasinadhsarma/VishwamAI/train-00000-of-00001.parquet')\n",
    "test_data = pd.read_parquet('test-00000-of-00001.parquet')\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_config():\n",
    "    \"\"\"Create TPU-optimized training configuration\"\"\"\n",
    "    model_config = {\n",
    "        'vocab_size': 32000,\n",
    "        'num_layers': 12,\n",
    "        'num_heads': 12,\n",
    "        'head_dim': 64,\n",
    "        'hidden_dim': 768,\n",
    "        'mlp_dim': 3072,\n",
    "        'max_seq_len': 2048,\n",
    "        'dropout_rate': 0.1,\n",
    "        'use_flash_attn': True,\n",
    "        'use_rotary': True,\n",
    "        'use_rms_norm': False\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'model_config': model_config,\n",
    "        'batch_size': 32,\n",
    "        'grad_accum_steps': 4,\n",
    "        'learning_rate': 1e-4,\n",
    "        'warmup_steps': 2000,\n",
    "        'max_steps': 100000,\n",
    "        'dtype': jnp.bfloat16,\n",
    "        'enable_pjit': True,\n",
    "        'block_size': 128,\n",
    "        'mixed_precision': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training components\n",
    "config = create_training_config()\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "# Create model and initialize training state\n",
    "print(\"Initializing model and training state...\")\n",
    "state = create_train_state_tpu(config, rng)\n",
    "train_step = create_train_step_tpu(config, state)\n",
    "\n",
    "# Initialize profiler\n",
    "profiler = TPUProfiler(config=config['model_config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_training_metrics(profiler: TPUProfiler, num_steps: int = 100):\n",
    "    \"\"\"Analyze training metrics over multiple steps\"\"\"\n",
    "    metrics = {\n",
    "        'step_time': [],\n",
    "        'throughput': [],\n",
    "        'memory_used': [],\n",
    "        'tpu_utilization': []\n",
    "    }\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        profiler.start_step()\n",
    "        \n",
    "        # Simulate training step\n",
    "        batch_size = config['batch_size'] * config['grad_accum_steps']\n",
    "        profiler.record_batch_time(batch_size, 0.1)  # Example duration\n",
    "        profiler.measure_tpu_utilization()\n",
    "        \n",
    "        profiler.end_step()\n",
    "        \n",
    "        # Collect metrics\n",
    "        summary = profiler.get_metrics_summary()\n",
    "        metrics['step_time'].append(summary['step_time_mean'])\n",
    "        metrics['throughput'].append(summary.get('steps_per_second', 0))\n",
    "        metrics['memory_used'].append(summary.get('memory_accessed_mean', 0))\n",
    "        metrics['tpu_utilization'].append(summary.get('tpu_utilization_mean', 0))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run analysis\n",
    "training_metrics = analyze_training_metrics(profiler)\n",
    "\n",
    "# Plot metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Performance Metrics')\n",
    "\n",
    "axes[0, 0].plot(training_metrics['step_time'])\n",
    "axes[0, 0].set_title('Step Time')\n",
    "axes[0, 0].set_xlabel('Step')\n",
    "axes[0, 0].set_ylabel('Time (s)')\n",
    "\n",
    "axes[0, 1].plot(training_metrics['throughput'])\n",
    "axes[0, 1].set_title('Throughput')\n",
    "axes[0, 1].set_xlabel('Step')\n",
    "axes[0, 1].set_ylabel('Steps/second')\n",
    "\n",
    "axes[1, 0].plot(training_metrics['memory_used'])\n",
    "axes[1, 0].set_title('Memory Usage')\n",
    "axes[1, 0].set_xlabel('Step')\n",
    "axes[1, 0].set_ylabel('Bytes')\n",
    "\n",
    "axes[1, 1].plot(training_metrics['tpu_utilization'])\n",
    "axes[1, 1].set_title('TPU Utilization')\n",
    "axes[1, 1].set_xlabel('Step')\n",
    "axes[1, 1].set_ylabel('Utilization %')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a84f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration with proper dtype settings\n",
    "config = create_training_config()\n",
    "\n",
    "# Initialize model and check params\n",
    "print(\"Creating model...\")\n",
    "model = create_vishwamai_transformer(config)\n",
    "\n",
    "# Initialize training components\n",
    "print(\"\\nInitializing training state...\")\n",
    "rng = jax.random.PRNGKey(42)\n",
    "state = create_train_state_tpu(config, rng)\n",
    "train_step = create_train_step_tpu(config, state)\n",
    "\n",
    "# Initialize profiler with proper config\n",
    "print(\"\\nSetting up profiler...\")\n",
    "profiler = TPUProfiler(config=config['model_config'])\n",
    "\n",
    "# Run analysis\n",
    "print(\"\\nAnalyzing training metrics...\")\n",
    "training_metrics = analyze_training_metrics(profiler)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Performance Analysis')\n",
    "\n",
    "steps = range(len(training_metrics['step_time']))\n",
    "\n",
    "axes[0,0].plot(steps, training_metrics['step_time'])\n",
    "axes[0,0].set_title('Step Time')\n",
    "axes[0,0].set_xlabel('Step')\n",
    "axes[0,0].set_ylabel('Time (s)')\n",
    "\n",
    "axes[0,1].plot(steps, training_metrics['throughput'])\n",
    "axes[0,1].set_title('Training Throughput')\n",
    "axes[0,1].set_xlabel('Step')\n",
    "axes[0,1].set_ylabel('Steps/Second')\n",
    "\n",
    "axes[1,0].plot(steps, training_metrics['memory_used'])\n",
    "axes[1,0].set_title('Memory Usage')\n",
    "axes[1,0].set_xlabel('Step')\n",
    "axes[1,0].set_ylabel('Bytes')\n",
    "\n",
    "axes[1,1].plot(steps, training_metrics['tpu_utilization'])\n",
    "axes[1,1].set_title('TPU Utilization')\n",
    "axes[1,1].set_xlabel('Step')\n",
    "axes[1,1].set_ylabel('Utilization %')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52722ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance recommendations\n",
    "recommendations = profiler.get_performance_recommendations()\n",
    "print(\"\\nPerformance Recommendations:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb875b",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Current metrics from previous analysis:\n",
    "- Total Parameters: 109,529,088\n",
    "- MoE Parameters: 301,991,936\n",
    "- Memory Usage:\n",
    "  - Activations: 96.00 MB\n",
    "  - Attention: 3072.00 MB\n",
    "  - KV Cache: 192.00 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_model_performance(config: Dict[str, Any]):\n",
    "    \"\"\"Profile model inference performance\"\"\"\n",
    "    model = create_vishwamai_transformer(config)\n",
    "    batch_size = 1\n",
    "    seq_length = config['max_seq_len']\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = jnp.ones((batch_size, seq_length), dtype=jnp.int32)\n",
    "    \n",
    "    # Profile memory\n",
    "    memory_profile = profiler.profile_memory_usage(\n",
    "        lambda x: model.apply({'params': state.params}, x),\n",
    "        {'input': dummy_input.shape}\n",
    "    )\n",
    "    \n",
    "    return memory_profile\n",
    "\n",
    "# Run performance profiling\n",
    "perf_metrics = profile_model_performance(config['model_config'])\n",
    "print(\"\\nModel Performance Profile:\")\n",
    "for k, v in perf_metrics.items():\n",
    "    print(f\"{k}: {v/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_attention(batch_size: int = 32, seq_len: int = 512):\n",
    "    \"\"\"Benchmark different attention implementations\"\"\"\n",
    "    # Generate dummy inputs\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jax.random.normal(rng, (batch_size, seq_len, config['model_config']['hidden_dim']))\n",
    "    \n",
    "    # Standard attention\n",
    "    def run_std_attention():\n",
    "        q = k = v = x\n",
    "        scores = jnp.einsum('bqd,bkd->bqk', q, k)\n",
    "        scores = scores / jnp.sqrt(config['model_config']['head_dim'])\n",
    "        attn = jax.nn.softmax(scores)\n",
    "        return jnp.einsum('bqk,bkd->bqd', attn, v)\n",
    "    \n",
    "    # Flash attention\n",
    "    def run_flash_attention():\n",
    "        q = k = v = x.reshape(batch_size, seq_len, \n",
    "                             config['model_config']['num_heads'], \n",
    "                             config['model_config']['head_dim'])\n",
    "        return FlashAttention(\n",
    "            num_heads=config['model_config']['num_heads'],\n",
    "            head_dim=config['model_config']['head_dim']\n",
    "        )(q, k, v)\n",
    "    \n",
    "    # Benchmark\n",
    "    std_time = %timeit -o -n 10 -r 3 -q run_std_attention()\n",
    "    flash_time = %timeit -o -n 10 -r 3 -q run_flash_attention()\n",
    "    \n",
    "    return {\n",
    "        'standard_attention_ms': std_time.best * 1000,\n",
    "        'flash_attention_ms': flash_time.best * 1000,\n",
    "        'speedup': std_time.best / flash_time.best\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks\n",
    "print(\"Running attention benchmarks...\")\n",
    "results_512 = benchmark_attention(seq_len=512)\n",
    "results_1024 = benchmark_attention(seq_len=1024)\n",
    "results_2048 = benchmark_attention(seq_len=2048)\n",
    "\n",
    "# Plot results\n",
    "seq_lens = [512, 1024, 2048]\n",
    "std_times = [results_512['standard_attention_ms'],\n",
    "            results_1024['standard_attention_ms'],\n",
    "            results_2048['standard_attention_ms']]\n",
    "flash_times = [results_512['flash_attention_ms'],\n",
    "              results_1024['flash_attention_ms'],\n",
    "              results_2048['flash_attention_ms']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(seq_lens, std_times, 'b-', label='Standard Attention')\n",
    "plt.plot(seq_lens, flash_times, 'r-', label='Flash Attention')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Attention Performance Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSpeedup at different sequence lengths:\")\n",
    "print(f\"512: {results_512['speedup']:.2f}x\")\n",
    "print(f\"1024: {results_1024['speedup']:.2f}x\")\n",
    "print(f\"2048: {results_2048['speedup']:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
