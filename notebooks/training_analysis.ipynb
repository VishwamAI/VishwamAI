{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b069c32b",
   "metadata": {},
   "source": [
    "# VishwamAI Training Performance Analysis\n",
    "\n",
    "This notebook analyzes the training performance with TPU optimizations and fixed FlashAttention implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80475a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from vishwamai.training import TPUTrainingConfig, create_train_state_tpu, create_train_step_tpu\n",
    "from vishwamai.profiler import TPUProfiler\n",
    "from vishwamai.transformer import create_vishwamai_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "train_data = pd.read_parquet('/home/kasinadhsarma/VishwamAI/train-00000-of-00001.parquet')\n",
    "test_data = pd.read_parquet('/home/kasinadhsarma/VishwamAI/test-00000-of-00001.parquet')\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration with proper typing\"\"\"\n",
    "    model_config: Dict[str, Any]\n",
    "    batch_size: int\n",
    "    grad_accum_steps: int\n",
    "    learning_rate: float\n",
    "    warmup_steps: int\n",
    "    max_steps: int\n",
    "    weight_decay: float\n",
    "    max_grad_norm: float\n",
    "    dtype: str\n",
    "    enable_pjit: bool\n",
    "    block_size: int\n",
    "    use_flash_attn: bool\n",
    "    mixed_precision: bool\n",
    "\n",
    "def create_training_config() -> TrainingConfig:\n",
    "    \"\"\"Create TPU-optimized training configuration\"\"\"\n",
    "    model_config = {\n",
    "        'vocab_size': 32000,\n",
    "        'num_layers': 12,\n",
    "        'num_heads': 12,\n",
    "        'head_dim': 64,\n",
    "        'hidden_dim': 768,\n",
    "        'mlp_dim': 3072,\n",
    "        'max_seq_len': 2048,\n",
    "        'dropout_rate': 0.1,\n",
    "        'use_flash_attn': True,\n",
    "        'use_rotary': True,\n",
    "        'use_rms_norm': False\n",
    "    }\n",
    "    \n",
    "    return TrainingConfig(\n",
    "        model_config=model_config,\n",
    "        batch_size=32,\n",
    "        grad_accum_steps=4,\n",
    "        learning_rate=1e-4,\n",
    "        warmup_steps=2000,\n",
    "        max_steps=100000,\n",
    "        weight_decay=0.01,\n",
    "        max_grad_norm=1.0,\n",
    "        dtype='bfloat16',\n",
    "        enable_pjit=True,\n",
    "        block_size=128,\n",
    "        use_flash_attn=True,\n",
    "        mixed_precision=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training components\n",
    "print(\"Creating training configuration...\")\n",
    "config = create_training_config()\n",
    "\n",
    "print(\"\\nInitializing model and training state...\")\n",
    "rng = jax.random.PRNGKey(42)\n",
    "state = create_train_state_tpu(TPUTrainingConfig(**vars(config)), rng)\n",
    "train_step = create_train_step_tpu(TPUTrainingConfig(**vars(config)), state)\n",
    "\n",
    "print(\"\\nSetting up profiler...\")\n",
    "profiler = TPUProfiler(config=config.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_training_performance(\n",
    "    profiler: TPUProfiler,\n",
    "    num_steps: int = 100,\n",
    "    log_interval: int = 10\n",
    ") -> Dict[str, list]:\n",
    "    \"\"\"Analyze training performance metrics with enhanced monitoring\"\"\"\n",
    "    metrics = {\n",
    "        'step_time': [],\n",
    "        'throughput': [],\n",
    "        'memory_used': [],\n",
    "        'tpu_utilization': [],\n",
    "        'compute_efficiency': [],\n",
    "        'memory_efficiency': []\n",
    "    }\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        profiler.start_step()\n",
    "        \n",
    "        # Simulate training step\n",
    "        batch_size = config.batch_size * config.grad_accum_steps\n",
    "        profiler.record_batch_time(batch_size, 0.1)  # Example duration\n",
    "        profiler.measure_tpu_utilization()\n",
    "        \n",
    "        profiler.end_step()\n",
    "        \n",
    "        # Collect detailed metrics\n",
    "        summary = profiler.get_metrics_summary()\n",
    "        metrics['step_time'].append(summary['step_time_mean'])\n",
    "        metrics['throughput'].append(summary.get('steps_per_second', 0))\n",
    "        metrics['memory_used'].append(summary.get('memory_accessed_mean', 0))\n",
    "        metrics['tpu_utilization'].append(summary.get('tpu_utilization_mean', 0))\n",
    "        \n",
    "        # Calculate efficiency metrics\n",
    "        compute_efficiency = summary.get('compute_time_mean', 0) / summary['step_time_mean']\n",
    "        memory_efficiency = 1 - (summary.get('memory_stall_mean', 0) / summary['step_time_mean'])\n",
    "        \n",
    "        metrics['compute_efficiency'].append(compute_efficiency)\n",
    "        metrics['memory_efficiency'].append(memory_efficiency)\n",
    "        \n",
    "        if step % log_interval == 0:\n",
    "            print(f\"\\nStep {step}/{num_steps}\")\n",
    "            print(f\"TPU Utilization: {metrics['tpu_utilization'][-1]:.2%}\")\n",
    "            print(f\"Throughput: {metrics['throughput'][-1]:.2f} steps/sec\")\n",
    "            print(f\"Memory Usage: {metrics['memory_used'][-1]/1e9:.2f} GB\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run analysis\n",
    "print(\"\\nAnalyzing training performance...\")\n",
    "training_metrics = analyze_training_performance(profiler)\n",
    "\n",
    "# Create enhanced visualization\n",
    "plt.style.use('seaborn')\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "fig.suptitle('VishwamAI Training Performance Analysis', fontsize=16)\n",
    "\n",
    "# Plot metrics with enhanced styling\n",
    "def plot_metric(ax, data, title, ylabel, color='#2196F3'):\n",
    "    ax.plot(data, color=color, linewidth=2)\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.set_xlabel('Step', fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plot_metric(axes[0,0], training_metrics['step_time'], 'Step Time', 'Time (s)')\n",
    "plot_metric(axes[0,1], training_metrics['throughput'], 'Training Throughput', 'Steps/Second', '#4CAF50')\n",
    "plot_metric(axes[1,0], [m/1e9 for m in training_metrics['memory_used']], 'Memory Usage', 'GB', '#FF9800')\n",
    "plot_metric(axes[1,1], training_metrics['tpu_utilization'], 'TPU Utilization', 'Utilization %', '#E91E63')\n",
    "plot_metric(axes[2,0], training_metrics['compute_efficiency'], 'Compute Efficiency', 'Ratio', '#9C27B0')\n",
    "plot_metric(axes[2,1], training_metrics['memory_efficiency'], 'Memory Efficiency', 'Ratio', '#795548')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Generate performance insights\n",
    "print(\"\\nPerformance Analysis Summary:\")\n",
    "print(f\"Average TPU Utilization: {np.mean(training_metrics['tpu_utilization']):.2%}\")\n",
    "print(f\"Average Throughput: {np.mean(training_metrics['throughput']):.2f} steps/sec\")\n",
    "print(f\"Peak Memory Usage: {max(training_metrics['memory_used'])/1e9:.2f} GB\")\n",
    "print(f\"Average Compute Efficiency: {np.mean(training_metrics['compute_efficiency']):.2%}\")\n",
    "print(f\"Average Memory Efficiency: {np.mean(training_metrics['memory_efficiency']):.2%}\")\n",
    "\n",
    "# Get and display optimization recommendations\n",
    "recommendations = profiler.get_performance_recommendations()\n",
    "print(\"\\nPerformance Optimization Recommendations:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a84f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration with proper dtype settings\n",
    "config = create_training_config()\n",
    "\n",
    "# Initialize model and check params\n",
    "print(\"Creating model...\")\n",
    "model = create_vishwamai_transformer(config)\n",
    "\n",
    "# Initialize training components\n",
    "print(\"\\nInitializing training state...\")\n",
    "rng = jax.random.PRNGKey(42)\n",
    "state = create_train_state_tpu(config, rng)\n",
    "train_step = create_train_step_tpu(config, state)\n",
    "\n",
    "# Initialize profiler with proper config\n",
    "print(\"\\nSetting up profiler...\")\n",
    "profiler = TPUProfiler(config=config['model_config'])\n",
    "\n",
    "# Run analysis\n",
    "print(\"\\nAnalyzing training metrics...\")\n",
    "training_metrics = analyze_training_metrics(profiler)\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Training Performance Analysis')\n",
    "\n",
    "steps = range(len(training_metrics['step_time']))\n",
    "\n",
    "axes[0,0].plot(steps, training_metrics['step_time'])\n",
    "axes[0,0].set_title('Step Time')\n",
    "axes[0,0].set_xlabel('Step')\n",
    "axes[0,0].set_ylabel('Time (s)')\n",
    "\n",
    "axes[0,1].plot(steps, training_metrics['throughput'])\n",
    "axes[0,1].set_title('Training Throughput')\n",
    "axes[0,1].set_xlabel('Step')\n",
    "axes[0,1].set_ylabel('Steps/Second')\n",
    "\n",
    "axes[1,0].plot(steps, training_metrics['memory_used'])\n",
    "axes[1,0].set_title('Memory Usage')\n",
    "axes[1,0].set_xlabel('Step')\n",
    "axes[1,0].set_ylabel('Bytes')\n",
    "\n",
    "axes[1,1].plot(steps, training_metrics['tpu_utilization'])\n",
    "axes[1,1].set_title('TPU Utilization')\n",
    "axes[1,1].set_xlabel('Step')\n",
    "axes[1,1].set_ylabel('Utilization %')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52722ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get performance recommendations\n",
    "recommendations = profiler.get_performance_recommendations()\n",
    "print(\"\\nPerformance Recommendations:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb875b",
   "metadata": {},
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "Current metrics from previous analysis:\n",
    "- Total Parameters: 109,529,088\n",
    "- MoE Parameters: 301,991,936\n",
    "- Memory Usage:\n",
    "  - Activations: 96.00 MB\n",
    "  - Attention: 3072.00 MB\n",
    "  - KV Cache: 192.00 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_model_performance(config: Dict[str, Any]):\n",
    "    \"\"\"Profile model inference performance\"\"\"\n",
    "    model = create_vishwamai_transformer(config)\n",
    "    batch_size = 1\n",
    "    seq_length = config['max_seq_len']\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = jnp.ones((batch_size, seq_length), dtype=jnp.int32)\n",
    "    \n",
    "    # Profile memory\n",
    "    memory_profile = profiler.profile_memory_usage(\n",
    "        lambda x: model.apply({'params': state.params}, x),\n",
    "        {'input': dummy_input.shape}\n",
    "    )\n",
    "    \n",
    "    return memory_profile\n",
    "\n",
    "# Run performance profiling\n",
    "perf_metrics = profile_model_performance(config['model_config'])\n",
    "print(\"\\nModel Performance Profile:\")\n",
    "for k, v in perf_metrics.items():\n",
    "    print(f\"{k}: {v/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_attention(batch_size: int = 32, seq_len: int = 512):\n",
    "    \"\"\"Benchmark different attention implementations\"\"\"\n",
    "    # Generate dummy inputs\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jax.random.normal(rng, (batch_size, seq_len, config['model_config']['hidden_dim']))\n",
    "    \n",
    "    # Standard attention\n",
    "    def run_std_attention():\n",
    "        q = k = v = x\n",
    "        scores = jnp.einsum('bqd,bkd->bqk', q, k)\n",
    "        scores = scores / jnp.sqrt(config['model_config']['head_dim'])\n",
    "        attn = jax.nn.softmax(scores)\n",
    "        return jnp.einsum('bqk,bkd->bqd', attn, v)\n",
    "    \n",
    "    # Flash attention\n",
    "    def run_flash_attention():\n",
    "        q = k = v = x.reshape(batch_size, seq_len, \n",
    "                             config['model_config']['num_heads'], \n",
    "                             config['model_config']['head_dim'])\n",
    "        return FlashAttention(\n",
    "            num_heads=config['model_config']['num_heads'],\n",
    "            head_dim=config['model_config']['head_dim']\n",
    "        )(q, k, v)\n",
    "    \n",
    "    # Benchmark\n",
    "    std_time = %timeit -o -n 10 -r 3 -q run_std_attention()\n",
    "    flash_time = %timeit -o -n 10 -r 3 -q run_flash_attention()\n",
    "    \n",
    "    return {\n",
    "        'standard_attention_ms': std_time.best * 1000,\n",
    "        'flash_attention_ms': flash_time.best * 1000,\n",
    "        'speedup': std_time.best / flash_time.best\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks\n",
    "print(\"Running attention benchmarks...\")\n",
    "results_512 = benchmark_attention(seq_len=512)\n",
    "results_1024 = benchmark_attention(seq_len=1024)\n",
    "results_2048 = benchmark_attention(seq_len=2048)\n",
    "\n",
    "# Plot results\n",
    "seq_lens = [512, 1024, 2048]\n",
    "std_times = [results_512['standard_attention_ms'],\n",
    "            results_1024['standard_attention_ms'],\n",
    "            results_2048['standard_attention_ms']]\n",
    "flash_times = [results_512['flash_attention_ms'],\n",
    "              results_1024['flash_attention_ms'],\n",
    "              results_2048['flash_attention_ms']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(seq_lens, std_times, 'b-', label='Standard Attention')\n",
    "plt.plot(seq_lens, flash_times, 'r-', label='Flash Attention')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Attention Performance Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSpeedup at different sequence lengths:\")\n",
    "print(f\"512: {results_512['speedup']:.2f}x\")\n",
    "print(f\"1024: {results_1024['speedup']:.2f}x\")\n",
    "print(f\"2048: {results_2048['speedup']:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06284e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_tpu_performance(config: Dict[str, Any]) -> Dict[str, float]:\n",
    "    \"\"\"Benchmark TPU performance characteristics\"\"\"\n",
    "    # Initialize model\n",
    "    model = create_vishwamai_transformer(config)\n",
    "    \n",
    "    # Setup profiler\n",
    "    profiler = TPUProfiler(config)\n",
    "    \n",
    "    # Generate sample batch\n",
    "    batch_size = 32\n",
    "    seq_len = 512\n",
    "    x = jnp.ones((batch_size, seq_len), dtype=jnp.int32)\n",
    "    \n",
    "    # Initialize model parameters\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    variables = model.init(rng, x)\n",
    "    \n",
    "    # Warmup\n",
    "    with profiler.profile_region('warmup'):\n",
    "        _ = model.apply(variables, x, deterministic=True)  # Fixed: Using deterministic instead of train\n",
    "    \n",
    "    # Benchmark forward pass\n",
    "    times = []\n",
    "    for _ in range(10):\n",
    "        start = time.time()\n",
    "        _ = model.apply(variables, x, deterministic=True)  # Fixed: Using deterministic instead of train\n",
    "        jax.tree_util.tree_map(lambda x: x.block_until_ready(), _)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    forward_latency = np.mean(times)\n",
    "    tokens_per_second = (batch_size * seq_len) / forward_latency\n",
    "    \n",
    "    # Get TPU utilization from profiler\n",
    "    metrics = profiler.get_metrics_summary()\n",
    "    tpu_utilization = metrics.get('tpu_utilization_mean', 0.0)\n",
    "    memory_efficiency = metrics.get('memory_efficiency_mean', 0.0)\n",
    "    \n",
    "    return {\n",
    "        'forward_latency': forward_latency,\n",
    "        'tokens_per_second': tokens_per_second,\n",
    "        'tpu_utilization': tpu_utilization,\n",
    "        'memory_efficiency': memory_efficiency\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
