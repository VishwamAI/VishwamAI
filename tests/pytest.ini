[pytest]
# Test discovery and collection
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Logging configuration
log_cli = True
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Test execution
addopts =
    --verbose
    --strict-markers
    --cov=vishwamai
    --cov-report=term-missing
    --cov-report=html
    -n auto
    --dist loadscope
    --benchmark-only
    --benchmark-autosave

# Custom markers
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    gpu: requires GPU
    cpu: CPU only tests
    precision: precision-related tests
    distributed: distributed training tests
    benchmark: performance benchmark tests

# Timeout settings
timeout = 300

# Environment variables
env =
    CUDA_VISIBLE_DEVICES=0
    TORCH_CUDA_ARCH_LIST=7.0+PTX
    PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Skip patterns
norecursedirs = .* build dist *.egg-info venv env

# Fail on warnings
filterwarnings =
    error
    ignore::DeprecationWarning
    ignore::UserWarning
    ignore::FutureWarning

# Disable coverage for some paths
[coverage:run]
omit =
    tests/*
    setup.py
    examples/*
    docs/*

# Coverage report settings
[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise NotImplementedError
    if __name__ == .__main__.:
    pass

# Benchmark settings
[benchmark]
min_rounds = 5
max_time = 1.0
timer = time.perf_counter
disable_gc = False
warmup = True
warmup_iterations = 3

# Tool-specific settings
[tool:pytest]
console_output_style = classic
