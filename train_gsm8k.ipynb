{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VishwamAI on GSM8K Dataset\n",
    "\n",
    "This notebook demonstrates how to train the VishwamAI model on the GSM8K (Grade School Math 8K) dataset.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install transformers datasets torch accelerate wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import wandb\n",
    "\n",
    "from vishwamai.model.transformer import create_transformer_model, get_pretrained_config\n",
    "from vishwamai.data.dataset.implementations.gsm8k import GSM8KDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load GSM8K dataset\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "print(f\"Train size: {len(dataset['train'])}\")\n",
    "print(f\"Test size: {len(dataset['test'])}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample question:\")\n",
    "print(dataset['train'][0]['question'])\n",
    "print(\"\\nSample answer:\")\n",
    "print(dataset['train'][0]['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get model configuration\n",
    "config = get_pretrained_config(\n",
    "    model_size=\"base\",\n",
    "    model_type=\"moe_mla_transformer\"\n",
    ")\n",
    "\n",
    "# Create model\n",
    "model = create_transformer_model(config)\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"gpt2\",  # Starting with GPT-2 tokenizer\n",
    "    pad_token=\"<pad>\"\n",
    ")\n",
    "tokenizer.add_special_tokens({\n",
    "    'sep_token': '<sep>',\n",
    "    'cls_token': '<cls>'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def format_example(example):\n",
    "    \"\"\"Format GSM8K example for training.\"\"\"\n",
    "    return {\n",
    "        \"input_text\": f\"Question: {example['question']}\\nLet's solve this step by step:\\n\",\n",
    "        \"target_text\": example['answer']\n",
    "    }\n",
    "\n",
    "# Process datasets\n",
    "train_dataset = GSM8KDataset(\n",
    "    dataset[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    format_func=format_example\n",
    ")\n",
    "\n",
    "eval_dataset = GSM8KDataset(\n",
    "    dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    format_func=format_example\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=\"vishwamai-gsm8k\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_sample(question):\n",
    "    \"\"\"Generate answer for a sample question.\"\"\"\n",
    "    input_text = f\"Question: {question}\\nLet's solve this step by step:\\n\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=200,\n",
    "        num_beams=4,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test with sample questions\n",
    "test_questions = [\n",
    "    dataset['test'][0]['question'],\n",
    "    dataset['test'][1]['question']\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"Question:\", question)\n",
    "    print(\"\\nGenerated Answer:\")\n",
    "    print(evaluate_sample(question))\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Upload to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save model\n",
    "model_path = \"gsm8k_trained_model\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n",
    "# Upload to HuggingFace Hub\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=model_path,\n",
    "    repo_id=\"VishwamAI/VishwamAI\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
