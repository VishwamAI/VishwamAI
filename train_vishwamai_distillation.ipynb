{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishwamAI/VishwamAI/blob/main/train_vishwamai_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAbg5csLN9-x"
      },
      "source": [
        "# VishwamAI Distillation Training\n",
        "\n",
        "This notebook implements knowledge distillation from DeepSeek to a smaller VishwamAI model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0DJ8BItN9-z",
        "outputId": "e7542f88-2773-4a65-b4ad-060adaffa25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'VishwamAI' already exists and is not an empty directory.\n",
            "/content/VishwamAI\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository and change directory\n",
        "!git clone https://github.com/VishwamAI/VishwamAI\n",
        "%cd VishwamAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "McG6UzJpN9-0"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q --upgrade transformers datasets accelerate bitsandbytes wandb  sentencepiece \\\n",
        "    flax optax omegaconf huggingface-hub einops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cmuE9ixWN9-0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax.training import train_state\n",
        "\n",
        "from vishwamai.model import VishwamAIModel, ModelConfig\n",
        "from vishwamai.tokenizer import VishwamAITokenizer\n",
        "from vishwamai.distillation import VishwamaiGuruKnowledge, VishwamaiShaalaTrainer\n",
        "from vishwamai.data_utils import create_train_dataloader, create_val_dataloader\n",
        "from huggingface_hub import snapshot_download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXqn3fOmN9-0"
      },
      "source": [
        "## Configuration Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_dRmGenmN9-1"
      },
      "outputs": [],
      "source": [
        "# Teacher model config (DeepSeek)\n",
        "teacher_config = {\n",
        "    \"vocab_size\": 129280,\n",
        "    \"hidden_size\": 7168,\n",
        "    \"num_layers\": 61,\n",
        "    \"num_attention_heads\": 128,\n",
        "    \"intermediate_size\": 18432,\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"attention_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 163840,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_eps\": 1e-5,\n",
        "    \"use_cache\": True, # Changed from true to True\n",
        "    \"pad_token_id\": 0,\n",
        "    \"bos_token_id\": 1,\n",
        "    \"eos_token_id\": 2,\n",
        "    \"tie_word_embeddings\": True,\n",
        "    \"use_flash_attention\": True,\n",
        "    \"use_rope\": True,\n",
        "    \"use_alibi\": False, # Changed from false to False\n",
        "    \"use_gqa\": True,\n",
        "    \"num_key_value_heads\": 128,\n",
        "    \"dtype\": \"bfloat16\"\n",
        "}\n",
        "\n",
        "# Student model config (smaller VishwamAI)\n",
        "student_config = {\n",
        "    \"vocab_size\": 129280,\n",
        "    \"hidden_size\": 2048,  # Smaller hidden size\n",
        "    \"num_layers\": 24,  # Fewer layers\n",
        "    \"num_attention_heads\": 32,\n",
        "    \"intermediate_size\": 8192,\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"attention_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 163840,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_eps\": 1e-5,\n",
        "    \"use_cache\": True, # Changed from true to True\n",
        "    \"pad_token_id\": 0,\n",
        "    \"bos_token_id\": 1,\n",
        "    \"eos_token_id\": 2,\n",
        "    \"tie_word_embeddings\": True,\n",
        "    \"use_flash_attention\": True,\n",
        "    \"use_rope\": True,\n",
        "    \"use_alibi\": False, # Changed from false to False\n",
        "    \"use_gqa\": True,\n",
        "    \"num_key_value_heads\": 32,\n",
        "    \"dtype\": \"bfloat16\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIFwM6B3N9-1"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a8d3129297c3445d980aa92c94dc7ced",
            "13c2b0942d3441adaa4b829cc03e805c",
            "5d47737946a84df79f21a7b9d746eaec",
            "a0633756612f4b4a9228a72e716973eb",
            "0ade2e254cf2491eb556d9d21295408d",
            "b00bc245e3df4fb9808e9f1db0b84833",
            "218c354ca59346fea20414e36a0a58ca",
            "03eb60a70fd54772b84891ac6dfe6a83",
            "1dcae057b013400b903561438261900b",
            "52b160024fac438ea2c6fcbd23456655",
            "f0666df24a274f9b900a553d40a82938"
          ]
        },
        "id": "dl2tVuXzN9-2",
        "outputId": "7478a0be-c3b2-48e2-df2f-63014e9dd691"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8d3129297c3445d980aa92c94dc7ced"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded 15 model shards to /root/.cache/huggingface/hub/models--perplexity-ai--r1-1776/snapshots/1ae3222e162fe7dd8511b1f74f27e100e7b82d6a\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error loading weights from /root/.cache/huggingface/hub/models--perplexity-ai--r1-1776/snapshots/1ae3222e162fe7dd8511b1f74f27e100e7b82d6a/model-00001-of-00252.safetensors: RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 1.73G. That was not possible. There are 143.53M free.; (0x0x0_HBM0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/content/VishwamAI/vishwamai/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                 \u001b[0mshard_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/safetensors/flax.py\u001b[0m in \u001b[0;36mload_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[1;32m   4085\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected input type for array: {type(object)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4086\u001b[0;31m   out_array: Array = lax_internal._convert_element_type(\n\u001b[0m\u001b[1;32m   4087\u001b[0m       out, dtype, weak_type=weak_type, sharding=sharding)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type, sharding)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     return convert_element_type_p.bind(\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type_bind\u001b[0;34m(operand, new_dtype, weak_type, sharding)\u001b[0m\n\u001b[1;32m   2608\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_element_type_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2609\u001b[0;31m   operand = core.Primitive.bind(convert_element_type_p, operand,\n\u001b[0m\u001b[1;32m   2610\u001b[0m                                 \u001b[0mnew_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweak_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    438\u001b[0m             all(isinstance(arg, Tracer) or valid_jaxtype(arg) for arg in args)), args\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_top_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpop_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mbatched_device_put\u001b[0;34m(aval, sharding, xs, devices, committed)\u001b[0m\n\u001b[1;32m    224\u001b[0m         aval, sharding, bufs, committed=committed, _skip_checks=True)\n\u001b[0;32m--> 225\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mxc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatched_device_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommitted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 1.73G. That was not possible. There are 143.53M free.; (0x0x0_HBM0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5b21e4402bed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mteacher_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVishwamAIModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mteacher_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mteacher_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Initialize student model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_use_named_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_derive_profiling_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VishwamAI/vishwamai/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error loading weights from {shard_path}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;31m# Bind parameters to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error loading weights from /root/.cache/huggingface/hub/models--perplexity-ai--r1-1776/snapshots/1ae3222e162fe7dd8511b1f74f27e100e7b82d6a/model-00001-of-00252.safetensors: RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 1.73G. That was not possible. There are 143.53M free.; (0x0x0_HBM0)"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "def download_partial_model(model_path: str, num_shards: int = 15):\n",
        "    \"\"\"Download only specified number of model shards\"\"\"\n",
        "\n",
        "    # Create pattern to match only first N safetensor files\n",
        "    patterns = [f\"model-{i+1:05d}-of-00252.safetensors\" for i in range(num_shards)]\n",
        "    patterns.extend([\"config.json\", \"tokenizer.model\"])  # Add other required files\n",
        "\n",
        "    try:\n",
        "        local_path = snapshot_download(\n",
        "            repo_id=model_path,\n",
        "            allow_patterns=patterns,\n",
        "            local_files_only=False,\n",
        "            resume_download=True\n",
        "        )\n",
        "        print(f\"Successfully downloaded {num_shards} model shards to {local_path}\")\n",
        "        return local_path\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error downloading model shards: {str(e)}\")\n",
        "\n",
        "# Load distillation configuration\n",
        "# Load distillation configuration\n",
        "# Use os.path.join to create the full path\n",
        "distillation_config = OmegaConf.load(os.path.join(\"configs\", \"distillation_config.yaml\"))\n",
        "# Initialize teacher model with partial weights\n",
        "teacher_path = download_partial_model(\n",
        "    distillation_config['distillation']['teacher_model']['path'],\n",
        "    num_shards=15\n",
        ")\n",
        "\n",
        "teacher_config = distillation_config['distillation']['teacher_model']['config']\n",
        "student_config = distillation_config['distillation']['student_model']['config']\n",
        "\n",
        "teacher_model = VishwamAIModel(ModelConfig(**teacher_config))\n",
        "teacher_model.load_weights(teacher_path)\n",
        "\n",
        "# Initialize student model\n",
        "student_model = VishwamAIModel(ModelConfig(**student_config))\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = VishwamAITokenizer(\n",
        "    vocab_size=teacher_config[\"vocab_size\"],\n",
        "    model_prefix=\"vishwamai\"\n",
        ")\n",
        "\n",
        "# Initialize distillation trainer\n",
        "trainer = VishwamaiShaalaTrainer(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=student_model,\n",
        "    cfg=distillation_config\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jPU9A9kN9-2"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fbjwR4KN9-2"
      },
      "outputs": [],
      "source": [
        "%pip uninstall mlflow\n",
        "%pip install mlflow\n",
        "import mlflow\n",
        "#  Initialize MLflow\n",
        "mlflow.set_experiment(\"VishwamAI-Distillation\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = create_train_dataloader(OmegaConf.create(distillation_config))\n",
        "val_loader = create_val_dataloader(OmegaConf.create(distillation_config))\n",
        "\n",
        "# Initialize training state\n",
        "rng = jax.random.PRNGKey(42)\n",
        "state = trainer.create_train_state(rng)\n",
        "\n",
        "# Initialize guru knowledge with feature matching\n",
        "guru = VishwamaiGuruKnowledge(OmegaConf.create(distillation_config))\n",
        "\n",
        "# Start MLflow Run\n",
        "with mlflow.start_run():\n",
        "    try:\n",
        "        for step in range(distillation_config['training']['max_steps']):\n",
        "            batch = next(train_loader)\n",
        "\n",
        "            # Get teacher predictions and features\n",
        "            teacher_outputs = teacher_model(\n",
        "                batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                output_hidden_states=True,\n",
        "                output_attentions=True\n",
        "            )\n",
        "\n",
        "            # Training step with knowledge distillation\n",
        "            state, metrics, rng = trainer.train_step(\n",
        "                state=state,\n",
        "                batch=batch,\n",
        "                teacher_outputs=teacher_outputs,\n",
        "                guru=guru,\n",
        "                step=step,\n",
        "                rng=rng\n",
        "            )\n",
        "\n",
        "            # Enhanced logging with distillation metrics\n",
        "            if step % distillation_config['training']['logging_steps'] == 0:\n",
        "                distill_metrics = {\n",
        "                    'kd_loss': metrics['kd_loss'],\n",
        "                    'feature_loss': metrics.get('feature_loss', 0.0),\n",
        "                    'attention_loss': metrics.get('attention_loss', 0.0),\n",
        "                    'hidden_loss': metrics.get('hidden_loss', 0.0),\n",
        "                    'total_loss': metrics['total_loss'],\n",
        "                    'temperature': guru.temperature\n",
        "                }\n",
        "\n",
        "                # Log to MLflow\n",
        "                mlflow.log_metrics(distill_metrics, step=step)\n",
        "\n",
        "                # Print current distillation progress\n",
        "                print(f\"\\nStep {step}:\")\n",
        "                print(f\"KD Loss: {distill_metrics['kd_loss']:.4f}\")\n",
        "                print(f\"Feature Loss: {distill_metrics['feature_loss']:.4f}\")\n",
        "                print(f\"Total Loss: {distill_metrics['total_loss']:.4f}\")\n",
        "\n",
        "            # Evaluation with feature matching\n",
        "            if step % distillation_config['training']['eval_steps'] == 0:\n",
        "                eval_metrics = trainer.evaluate(\n",
        "                    state=state,\n",
        "                    val_loader=val_loader,\n",
        "                    teacher_model=teacher_model,\n",
        "                    guru=guru\n",
        "                )\n",
        "\n",
        "                # Log evaluation metrics\n",
        "                mlflow.log_metrics({f\"eval_{k}\": v for k, v in eval_metrics.items()}, step=step)\n",
        "\n",
        "            # Dynamic temperature adjustment\n",
        "            if step % 1000 == 0:\n",
        "                guru.temperature = max(1.0, guru.temperature * 0.95)\n",
        "\n",
        "            # Save checkpoint\n",
        "            if step % distillation_config['training']['save_steps'] == 0:\n",
        "                ckpt_path = f\"checkpoints/step_{step}\"\n",
        "                trainer.save_checkpoint(\n",
        "                    state=state,\n",
        "                    path=ckpt_path,\n",
        "                    guru=guru,\n",
        "                    metadata={\n",
        "                        'temperature': guru.temperature,\n",
        "                        'step': step,\n",
        "                        'metrics': metrics\n",
        "                    }\n",
        "                )\n",
        "                mlflow.log_artifact(ckpt_path)\n",
        "\n",
        "        # Final quantization with teacher guidance\n",
        "        if distillation_config['distillation']['quantization']['enabled']:\n",
        "            state = trainer.quantize_model(\n",
        "                state=state,\n",
        "                val_loader=val_loader,\n",
        "                teacher_model=teacher_model,\n",
        "                guru=guru,\n",
        "                num_calibration_steps=100\n",
        "            )\n",
        "            trainer.save_checkpoint(state, \"checkpoints/quantized\")\n",
        "            mlflow.log_artifact(\"checkpoints/quantized\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed: {str(e)}\")\n",
        "        mlflow.log_param(\"error\", str(e))\n",
        "    finally:\n",
        "        mlflow.end_run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soQScC1IN9-3"
      },
      "source": [
        "## Model Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bfk-XvaN9-3"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Push distilled model to HuggingFace Hub\n",
        "api = HfApi()\n",
        "\n",
        "repo_id = \"VishwamAI/VishwamAI-small\"\n",
        "api.create_repo(repo_id, exist_ok=True)\n",
        "\n",
        "# Upload model files\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"configs/student_config.json\",\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=repo_id\n",
        ")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"checkpoints/quantized/model.safetensors\",\n",
        "    path_in_repo=\"model.safetensors\",\n",
        "    repo_id=repo_id\n",
        ")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"tokenizer/vishwamai.model\",\n",
        "    path_in_repo=\"tokenizer.model\",\n",
        "    repo_id=repo_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdwrWGndN9-3"
      },
      "source": [
        "## Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4MuAzn9N9-3"
      },
      "outputs": [],
      "source": [
        "# Compare teacher and student model performance\n",
        "def evaluate_models(teacher, student, val_loader, num_batches=10):\n",
        "    teacher_metrics = []\n",
        "    student_metrics = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch = next(val_loader)\n",
        "\n",
        "        # Teacher predictions\n",
        "        teacher_output = teacher(batch['input_ids'], deterministic=True)\n",
        "        teacher_metrics.append({\n",
        "            'loss': float(teacher_output['loss']),\n",
        "            'accuracy': float(teacher_output.get('accuracy', 0))\n",
        "        })\n",
        "\n",
        "        # Student predictions\n",
        "        student_output = student(batch['input_ids'], deterministic=True)\n",
        "        student_metrics.append({\n",
        "            'loss': float(student_output['loss']),\n",
        "            'accuracy': float(student_output.get('accuracy', 0))\n",
        "        })\n",
        "\n",
        "    # Calculate averages\n",
        "    teacher_avg = {k: sum(m[k] for m in teacher_metrics) / len(teacher_metrics)\n",
        "                  for k in teacher_metrics[0]}\n",
        "    student_avg = {k: sum(m[k] for m in student_metrics) / len(student_metrics)\n",
        "                   for k in student_metrics[0]}\n",
        "\n",
        "    return {\n",
        "        'teacher': teacher_avg,\n",
        "        'student': student_avg,\n",
        "        'compression_ratio': f\"{teacher.param_count / student.param_count:.2f}x\"\n",
        "    }\n",
        "\n",
        "results = evaluate_models(teacher_model, student_model, val_loader)\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(f\"Compression Ratio: {results['compression_ratio']}\")\n",
        "print(\"\\nTeacher Model:\")\n",
        "print(f\"Loss: {results['teacher']['loss']:.4f}\")\n",
        "print(f\"Accuracy: {results['teacher']['accuracy']:.4f}\")\n",
        "print(\"\\nStudent Model:\")\n",
        "print(f\"Loss: {results['student']['loss']:.4f}\")\n",
        "print(f\"Accuracy: {results['student']['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P85BYMmjN9-4"
      },
      "outputs": [],
      "source": [
        "# Update model paths\n",
        "TEACHER_MODEL_PATH = \"perplexity-ai/r1-1776\"\n",
        "OUTPUT_MODEL_PATH = \"VishwamAI/Perplexity_r1_disttled_experiment\"\n",
        "\n",
        "# Verify teacher model files exist\n",
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Download teacher model files\n",
        "teacher_path = snapshot_download(\n",
        "    repo_id=TEACHER_MODEL_PATH,\n",
        "    allow_patterns=[\"*.safetensors\", \"config.json\", \"tokenizer.model\"]\n",
        ")\n",
        "print(f\"Downloaded teacher model to {teacher_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwtMM3v8N9-4"
      },
      "outputs": [],
      "source": [
        "# Modified model saving logic\n",
        "def save_sharded_model(state, save_dir, num_shards=15):\n",
        "    \"\"\"Save model weights in sharded safetensor format.\"\"\"\n",
        "    import safetensors\n",
        "    import safetensors.flax as stf\n",
        "    import os\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Get model parameters\n",
        "    params = state.params\n",
        "\n",
        "    # Calculate parameters per shard\n",
        "    total_params = sum(p.size for p in jax.tree_leaves(params))\n",
        "    params_per_shard = total_params // num_shards\n",
        "\n",
        "    # Save in sharded format\n",
        "    current_shard = 0\n",
        "    current_size = 0\n",
        "    shard_dict = {}\n",
        "\n",
        "    for name, param in params.items():\n",
        "        param_size = param.size\n",
        "\n",
        "        if current_size + param_size > params_per_shard:\n",
        "            # Save current shard\n",
        "            shard_path = os.path.join(\n",
        "                save_dir,\n",
        "                f\"model-{current_shard+1:05d}-of-{num_shards:05d}.safetensors\"\n",
        "            )\n",
        "            stf.save_file(shard_dict, shard_path)  # Use stf instead of safetensors\n",
        "\n",
        "            # Start new shard\n",
        "            current_shard += 1\n",
        "            current_size = 0\n",
        "            shard_dict = {}\n",
        "\n",
        "        shard_dict[name] = param\n",
        "        current_size += param_size\n",
        "\n",
        "    # Save final shard\n",
        "    if shard_dict:\n",
        "        shard_path = os.path.join(\n",
        "            save_dir,\n",
        "            f\"model-{current_shard+1:05d}-of-{num_shards:05d}.safetensors\"\n",
        "        )\n",
        "        stf.save_file(shard_dict, shard_path)  # Use stf instead of safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63OiF9wON9-4"
      },
      "outputs": [],
      "source": [
        "# Modified model export cell\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Push distilled model to HuggingFace Hub\n",
        "api = HfApi()\n",
        "\n",
        "# Save model in sharded format\n",
        "save_dir = \"checkpoints/final\"\n",
        "save_sharded_model(state, save_dir)\n",
        "\n",
        "# Upload to HF Hub\n",
        "api.create_repo(OUTPUT_MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# Upload configuration\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"configs/student_config.json\",\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=OUTPUT_MODEL_PATH\n",
        ")\n",
        "\n",
        "# Upload all model shards\n",
        "for shard_file in sorted(os.listdir(save_dir)):\n",
        "    if shard_file.endswith(\".safetensors\"):\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=os.path.join(save_dir, shard_file),\n",
        "            path_in_repo=shard_file,\n",
        "            repo_id=OUTPUT_MODEL_PATH\n",
        "        )\n",
        "\n",
        "# Upload tokenizer\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"tokenizer/vishwamai.model\",\n",
        "    path_in_repo=\"tokenizer.model\",\n",
        "    repo_id=OUTPUT_MODEL_PATH\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8d3129297c3445d980aa92c94dc7ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13c2b0942d3441adaa4b829cc03e805c",
              "IPY_MODEL_5d47737946a84df79f21a7b9d746eaec",
              "IPY_MODEL_a0633756612f4b4a9228a72e716973eb"
            ],
            "layout": "IPY_MODEL_0ade2e254cf2491eb556d9d21295408d"
          }
        },
        "13c2b0942d3441adaa4b829cc03e805c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00bc245e3df4fb9808e9f1db0b84833",
            "placeholder": "​",
            "style": "IPY_MODEL_218c354ca59346fea20414e36a0a58ca",
            "value": "Fetching 16 files: 100%"
          }
        },
        "5d47737946a84df79f21a7b9d746eaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03eb60a70fd54772b84891ac6dfe6a83",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dcae057b013400b903561438261900b",
            "value": 16
          }
        },
        "a0633756612f4b4a9228a72e716973eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b160024fac438ea2c6fcbd23456655",
            "placeholder": "​",
            "style": "IPY_MODEL_f0666df24a274f9b900a553d40a82938",
            "value": " 16/16 [00:00&lt;00:00, 1939.67it/s]"
          }
        },
        "0ade2e254cf2491eb556d9d21295408d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00bc245e3df4fb9808e9f1db0b84833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218c354ca59346fea20414e36a0a58ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03eb60a70fd54772b84891ac6dfe6a83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dcae057b013400b903561438261900b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52b160024fac438ea2c6fcbd23456655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0666df24a274f9b900a553d40a82938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}