{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAbg5csLN9-x"
      },
      "source": [
        "# VishwamAI Distillation Training\n",
        "\n",
        "This notebook implements knowledge distillation from DeepSeek to a smaller VishwamAI model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McG6UzJpN9-0"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q --upgrade transformers datasets accelerate bitsandbytes sentencepiece \\\n",
        "    flax optax omegaconf huggingface-hub einops aim>=3.17.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax.training import train_state\n",
        "\n",
        "# Configure TPU and memory settings\n",
        "jax.config.update('jax_platform_name', 'tpu')\n",
        "jax.config.update('jax_default_matmul_precision', 'bfloat16')\n",
        "\n",
        "from vishwamai.model import VishwamAIModel, ModelConfig\n",
        "from vishwamai.tokenizer import VishwamAITokenizer\n",
        "from vishwamai.distillation import VishwamaiGuruKnowledge, VishwamaiShaalaTrainer\n",
        "from vishwamai.data_utils import create_train_dataloader, create_val_dataloader\n",
        "from huggingface_hub import snapshot_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "import gc\n",
        "import jax\n",
        "import os\n",
        "\n",
        "def download_partial_model(model_path: str, num_shards: int = 5):\n",
        "    \"\"\"Download only specified number of model shards with memory efficiency\"\"\"\n",
        "    \n",
        "    # Clear memory before starting\n",
        "    gc.collect()\n",
        "    jax.clear_backends()\n",
        "\n",
        "    # Create pattern to match only first N safetensor files\n",
        "    patterns = [f\"model-{i+1:05d}-of-00252.safetensors\" for i in range(num_shards)]\n",
        "    patterns.extend([\"config.json\", \"tokenizer.model\"])  # Add other required files\n",
        "\n",
        "    try:\n",
        "        local_path = snapshot_download(\n",
        "            repo_id=model_path,\n",
        "            allow_patterns=patterns,\n",
        "            local_files_only=False,\n",
        "            resume_download=True\n",
        "        )\n",
        "        print(f\"Successfully downloaded {num_shards} model shards to {local_path}\")\n",
        "        return local_path\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error downloading model shards: {str(e)}\")\n",
        "\n",
        "# Load distillation configuration\n",
        "distillation_config = OmegaConf.load(os.path.join(\"vishwamai\", \"configs\", \"training\", \"perplexity_r1_distillation.yaml\"))\n",
        "\n",
        "# Initialize teacher model with fewer partial weights\n",
        "teacher_path = download_partial_model(\n",
        "    distillation_config['distillation']['teacher_model']['path'],\n",
        "    num_shards=5  # Reduced from 15 to 5 for memory efficiency\n",
        ")\n",
        "\n",
        "# Get configurations\n",
        "teacher_config = distillation_config['distillation']['teacher_model']['config']\n",
        "student_config = distillation_config['distillation']['student_model']['config']\n",
        "\n",
        "# Update dtype to bfloat16 for memory efficiency\n",
        "teacher_config['dtype'] = 'bfloat16'\n",
        "student_config['dtype'] = 'bfloat16'\n",
        "\n",
        "# Initialize models with memory cleanup between steps\n",
        "teacher_model = VishwamAIModel(ModelConfig(**teacher_config))\n",
        "gc.collect()\n",
        "jax.clear_backends()\n",
        "\n",
        "print(\"Loading teacher weights...\")\n",
        "teacher_model.load_weights(teacher_path)\n",
        "gc.collect()\n",
        "jax.clear_backends()\n",
        "\n",
        "print(\"Initializing student model...\")\n",
        "student_model = VishwamAIModel(ModelConfig(**student_config))\n",
        "gc.collect()\n",
        "jax.clear_backends()\n",
        "\n",
        "# Initialize tokenizer\n",
        "print(\"Initializing tokenizer...\")\n",
        "tokenizer = VishwamAITokenizer(\n",
        "    vocab_size=teacher_config[\"vocab_size\"],\n",
        "    model_prefix=\"vishwamai\"\n",
        ")\n",
        "\n",
        "# Initialize distillation trainer with smaller batch size\n",
        "print(\"Initializing trainer...\")\n",
        "distillation_config['training']['batch_size'] = 4  # Reduced batch size\n",
        "trainer = VishwamaiShaalaTrainer(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=student_model,\n",
        "    cfg=distillation_config\n",
        ")\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import Aim for experiment tracking\n",
        "import aim\n",
        "\n",
        "# Initialize Aim\n",
        "aim_run = aim.Run(experiment=\"VishwamAI-Distillation\")\n",
        "\n",
        "# Create data loaders with reduced batch size\n",
        "train_loader = create_train_dataloader(OmegaConf.create(distillation_config))\n",
        "val_loader = create_val_dataloader(OmegaConf.create(distillation_config))\n",
        "\n",
        "# Initialize training state\n",
        "rng = jax.random.PRNGKey(42)\n",
        "state = trainer.create_train_state(rng)\n",
        "\n",
        "# Initialize guru knowledge\n",
        "guru = VishwamaiGuruKnowledge(OmegaConf.create(distillation_config))\n",
        "\n",
        "# Start training with memory management\n",
        "try:\n",
        "    for step in range(distillation_config['training']['max_steps']):\n",
        "        batch = next(train_loader)\n",
        "\n",
        "        # Clear memory before heavy operations\n",
        "        gc.collect()\n",
        "        jax.clear_backends()\n",
        "\n",
        "        # Get teacher predictions and features\n",
        "        teacher_outputs = teacher_model(\n",
        "            batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            output_hidden_states=True,\n",
        "            output_attentions=True\n",
        "        )\n",
        "\n",
        "        # Training step with knowledge distillation\n",
        "        state, metrics, rng = trainer.train_step(\n",
        "            state=state,\n",
        "            batch=batch,\n",
        "            step=step,\n",
        "            rng=rng\n",
        "        )\n",
        "\n",
        "        # Log metrics and cleanup memory\n",
        "        if step % distillation_config['training']['logging_steps'] == 0:\n",
        "            distill_metrics = {\n",
        "                'kd_loss': metrics['kd_loss'],\n",
        "                'feature_loss': metrics.get('feature_loss', 0.0),\n",
        "                'attention_loss': metrics.get('attention_loss', 0.0),\n",
        "                'hidden_loss': metrics.get('hidden_loss', 0.0),\n",
        "                'total_loss': metrics['total_loss'],\n",
        "                'temperature': guru.temperature\n",
        "            }\n",
        "\n",
        "            # Log to Aim\n",
        "            for metric_name, metric_value in distill_metrics.items():\n",
        "                aim_run.track(metric_value, name=metric_name, step=step)\n",
        "\n",
        "            print(f\"\\nStep {step}:\")\n",
        "            print(f\"KD Loss: {distill_metrics['kd_loss']:.4f}\")\n",
        "            print(f\"Feature Loss: {distill_metrics['feature_loss']:.4f}\")\n",
        "            print(f\"Total Loss: {distill_metrics['total_loss']:.4f}\")\n",
        "\n",
        "            # Clear memory after logging\n",
        "            gc.collect()\n",
        "            jax.clear_backends()\n",
        "\n",
        "        if step % distillation_config['training']['eval_steps'] == 0:\n",
        "            eval_metrics = trainer.evaluate(\n",
        "                state=state,\n",
        "                val_loader=val_loader,\n",
        "                teacher_model=teacher_model,\n",
        "                guru=guru\n",
        "            )\n",
        "\n",
        "            # Log evaluation metrics\n",
        "            for k, v in eval_metrics.items():\n",
        "                aim_run.track(v, name=f\"eval_{k}\", step=step)\n",
        "\n",
        "        # Temperature adjustment and cleanup\n",
        "        if step % 1000 == 0:\n",
        "            guru.temperature = max(1.0, guru.temperature * 0.95)\n",
        "            gc.collect()\n",
        "            jax.clear_backends()\n",
        "\n",
        "        # Save checkpoint with memory cleanup\n",
        "        if step % distillation_config['training']['save_steps'] == 0:\n",
        "            gc.collect()\n",
        "            jax.clear_backends()\n",
        "            \n",
        "            ckpt_path = f\"checkpoints/step_{step}\"\n",
        "            trainer.save_checkpoint(\n",
        "                state=state,\n",
        "                path=ckpt_path,\n",
        "                guru=guru,\n",
        "                metadata={\n",
        "                    'temperature': guru.temperature,\n",
        "                    'step': step,\n",
        "                    'metrics': metrics\n",
        "                }\n",
        "            )\n",
        "            aim_run.track_artifact(ckpt_path, name=\"checkpoints\")\n",
        "\n",
        "    # Final quantization\n",
        "    if distillation_config['distillation']['quantization']['enabled']:\n",
        "        gc.collect()\n",
        "        jax.clear_backends()\n",
        "        \n",
        "        state = trainer.quantize_model(\n",
        "            state=state,\n",
        "            val_loader=val_loader,\n",
        "            num_calibration_steps=100\n",
        "        )\n",
        "        trainer.save_checkpoint(state, \"checkpoints/quantized\")\n",
        "        aim_run.track_artifact(\"checkpoints/quantized\", name=\"quantized_model\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Training failed: {str(e)}\")\n",
        "    aim_run.set_params({\"error\": str(e)})\n",
        "finally:\n",
        "    aim_run.close()\n",
        "    gc.collect()\n",
        "    jax.clear_backends()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soQScC1IN9-3"
      },
      "source": [
        "## Model Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "# Clear memory before export\n",
        "gc.collect()\n",
        "jax.clear_backends()\n",
        "\n",
        "# Push distilled model to HuggingFace Hub\n",
        "api = HfApi()\n",
        "repo_id = \"VishwamAI/VishwamAI-small\"\n",
        "\n",
        "# Create repository\n",
        "api.create_repo(repo_id, exist_ok=True)\n",
        "\n",
        "# Upload files in chunks\n",
        "files_to_upload = [\n",
        "    (\"configs/student_config.json\", \"config.json\"),\n",
        "    (\"checkpoints/quantized/model.safetensors\", \"model.safetensors\"),\n",
        "    (\"tokenizer/vishwamai.model\", \"tokenizer.model\")\n",
        "]\n",
        "\n",
        "for local_path, repo_path in files_to_upload:\n",
        "    print(f\"Uploading {local_path}...\")\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=local_path,\n",
        "        path_in_repo=repo_path,\n",
        "        repo_id=repo_id\n",
        "    )\n",
        "    gc.collect()\n",
        "\n",
        "print(\"Export complete!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
