{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishwamAI/VishwamAI/blob/main/train_vishwamai_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAbg5csLN9-x"
      },
      "source": [
        "# VishwamAI Distillation Training\n",
        "\n",
        "This notebook implements knowledge distillation from DeepSeek to a smaller VishwamAI model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0DJ8BItN9-z",
        "outputId": "fa3a7c9d-c72b-4f7c-d75e-24dfab31e30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VishwamAI'...\n",
            "remote: Enumerating objects: 2129, done.\u001b[K\n",
            "remote: Counting objects: 100% (518/518), done.\u001b[K\n",
            "remote: Compressing objects: 100% (421/421), done.\u001b[K\n",
            "remote: Total 2129 (delta 165), reused 410 (delta 87), pack-reused 1611 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2129/2129), 35.09 MiB | 50.18 MiB/s, done.\n",
            "Resolving deltas: 100% (1003/1003), done.\n",
            "/content/VishwamAI/VishwamAI/VishwamAI\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository and change directory\n",
        "!git clone https://github.com/VishwamAI/VishwamAI\n",
        "%cd VishwamAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "McG6UzJpN9-0"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q --upgrade transformers datasets accelerate bitsandbytes sentencepiece \\\n",
        "    flax optax omegaconf huggingface-hub einops aim>=3.17.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cmuE9ixWN9-0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax.training import train_state\n",
        "import gc\n",
        "import jax\n",
        "\n",
        "from vishwamai.model import VishwamAIModel, ModelConfig\n",
        "from vishwamai.tokenizer import VishwamAITokenizer\n",
        "from vishwamai.distillation import VishwamaiGuruKnowledge, VishwamaiShaalaTrainer\n",
        "from vishwamai.data_utils import create_train_dataloader, create_val_dataloader\n",
        "from huggingface_hub import snapshot_download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXqn3fOmN9-0"
      },
      "source": [
        "## Configuration Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_dRmGenmN9-1"
      },
      "outputs": [],
      "source": [
        "# Teacher model config (DeepSeek)\n",
        "teacher_config = {\n",
        "    \"vocab_size\": 129280,\n",
        "    \"hidden_size\": 7168,\n",
        "    \"num_layers\": 61,\n",
        "    \"num_attention_heads\": 128,\n",
        "    \"intermediate_size\": 18432,\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"attention_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 163840,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_eps\": 1e-5,\n",
        "    \"use_cache\": True, # Changed from true to True\n",
        "    \"pad_token_id\": 0,\n",
        "    \"bos_token_id\": 1,\n",
        "    \"eos_token_id\": 2,\n",
        "    \"tie_word_embeddings\": True,\n",
        "    \"use_flash_attention\": True,\n",
        "    \"use_rope\": True,\n",
        "    \"use_alibi\": False, # Changed from false to False\n",
        "    \"use_gqa\": True,\n",
        "    \"num_key_value_heads\": 128,\n",
        "    \"dtype\": \"bfloat16\"\n",
        "}\n",
        "\n",
        "# Student model config (smaller VishwamAI)\n",
        "student_config = {\n",
        "    \"vocab_size\": 129280,\n",
        "    \"hidden_size\": 2048,  # Smaller hidden size\n",
        "    \"num_layers\": 24,  # Fewer layers\n",
        "    \"num_attention_heads\": 32,\n",
        "    \"intermediate_size\": 8192,\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"attention_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 163840,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_eps\": 1e-5,\n",
        "    \"use_cache\": True, # Changed from true to True\n",
        "    \"pad_token_id\": 0,\n",
        "    \"bos_token_id\": 1,\n",
        "    \"eos_token_id\": 2,\n",
        "    \"tie_word_embeddings\": True,\n",
        "    \"use_flash_attention\": True,\n",
        "    \"use_rope\": True,\n",
        "    \"use_alibi\": False, # Changed from false to False\n",
        "    \"use_gqa\": True,\n",
        "    \"num_key_value_heads\": 32,\n",
        "    \"dtype\": \"bfloat16\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIFwM6B3N9-1"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929,
          "referenced_widgets": [
            "80ae9e62755042c78c860695ec96412b",
            "41e4c211b9584377af16d392f6137280",
            "297ea395621948bb93f85239464155b7",
            "22b4f65408cf44b4994a01c74bf4de7a",
            "4eff3d72989d438bb4612608ef5c45d3",
            "0d59556c38304d97b417d3f1d0a4baf3",
            "8e5e6d434c1444dab28f682a06ba7a0f",
            "4ed51837f9c84807b4cfb8b0cc879adb",
            "a3604b78362644cf8ada0616483b5c19",
            "91eb594a841a43598afbbe78c433ec29",
            "2414aa914443443b82e9651ceba264ab"
          ]
        },
        "id": "dl2tVuXzN9-2",
        "outputId": "2b230a46-fe17-47fd-8dbf-2d9e83a7d912"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80ae9e62755042c78c860695ec96412b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded 5 model shards to /root/.cache/huggingface/hub/models--perplexity-ai--r1-1776/snapshots/1ae3222e162fe7dd8511b1f74f27e100e7b82d6a\n",
            "Loading reduced size model for memory constraints...\n",
            "Loading model-00001-of-00252.safetensors...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error loading weights from /root/.cache/huggingface/hub/models--perplexity-ai--r1-1776/snapshots/1ae3222e162fe7dd8511b1f74f27e100e7b82d6a/model-00001-of-00252.safetensors: name 'safetensors' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/VishwamAI/vishwamai/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, model_path, reduced_size)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mshard_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".safetensors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshard_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'safetensors' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2034aef6309f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mteacher_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVishwamAIModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mteacher_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mteacher_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Initialize student model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_use_named_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_derive_profiling_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VishwamAI/vishwamai/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, model_path, reduced_size)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mallow_patterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"*.safetensors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 )\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error downloading model from {model_path}: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error loading weights from /root/.cache/huggingface/hub/models--perplexity-ai--r1-1776/snapshots/1ae3222e162fe7dd8511b1f74f27e100e7b82d6a/model-00001-of-00252.safetensors: name 'safetensors' is not defined"
          ]
        }
      ],
      "source": [
        "import safetensors.flax as stf\n",
        "import safetensors\n",
        "def download_partial_model(model_path: str, num_shards: int = 15):\n",
        "    \"\"\"Download only specified number of model shards\"\"\"\n",
        "    patterns = [f\"model-{i+1:05d}-of-00252.safetensors\" for i in range(num_shards)]\n",
        "    patterns.extend([\"config.json\", \"tokenizer.model\"])  # Add other required files\n",
        "\n",
        "    try:\n",
        "        local_path = snapshot_download(\n",
        "            repo_id=model_path,\n",
        "            allow_patterns=patterns,\n",
        "            local_files_only=False,\n",
        "            resume_download=True\n",
        "        )\n",
        "        print(f\"Successfully downloaded {num_shards} model shards to {local_path}\")\n",
        "        return local_path\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error downloading model shards: {str(e)}\")\n",
        "\n",
        "# Load distillation configuration\n",
        "config_path = os.path.join(\"vishwamai\", \"configs\", \"training\", \"perplexity_r1_distillation.yaml\")\n",
        "if not os.path.exists(config_path):\n",
        "    distillation_config_path = os.path.join(\"vishwamai\", \"configs\", \"training\", \"perplexity_r1_distillation.yaml\")\n",
        "    if not os.path.exists(distillation_config_path):\n",
        "        distillation_config = OmegaConf.create({\n",
        "            'distillation': {\n",
        "                'teacher_model': {\n",
        "                    'path': \"perplexity-ai/r1-1776\",\n",
        "                    'config': {\n",
        "                        'hidden_size': 7168,\n",
        "                        'intermediate_size': 18432,\n",
        "                        'num_attention_heads': 128,\n",
        "                        'num_layers': 61,\n",
        "                        'num_key_value_heads': 128,\n",
        "                        'vocab_size': 129280,\n",
        "                        'max_position_embeddings': 163840\n",
        "                    }\n",
        "                },\n",
        "                'student_model': {\n",
        "                    'path': \"model-00001-to-00015-of-00252.safetensors\",\n",
        "                    'config': {\n",
        "                        'hidden_size': 2048,\n",
        "                        'intermediate_size': 8192,\n",
        "                        'num_attention_heads': 32,\n",
        "                        'num_layers': 24,\n",
        "                        'num_key_value_heads': 32,\n",
        "                        'vocab_size': 129280,\n",
        "                        'max_position_embeddings': 163840\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        })\n",
        "        print(f\"Warning: Config file not found at {distillation_config_path}. Using default config.\")\n",
        "    else:\n",
        "        distillation_config = OmegaConf.load(distillation_config_path)\n",
        "\n",
        "# Download partial teacher model\n",
        "teacher_path = download_partial_model(\n",
        "    distillation_config['distillation']['teacher_model']['path'],\n",
        "    num_shards=5  # Reduced for memory efficiency\n",
        ")\n",
        "\n",
        "# Initialize teacher model\n",
        "teacher_config = distillation_config['distillation']['teacher_model']['config']\n",
        "student_config = distillation_config['distillation']['student_model']['config']\n",
        "\n",
        "teacher_model = VishwamAIModel(ModelConfig(**teacher_config))\n",
        "teacher_model.load_weights(teacher_path, reduced_size=True)\n",
        "\n",
        "# Initialize student model\n",
        "student_model = VishwamAIModel(ModelConfig(**student_config))\n",
        "\n",
        "# Initialize tokenizer (placeholder)\n",
        "tokenizer = VishwamAITokenizer(\n",
        "    vocab_size=teacher_config[\"vocab_size\"],\n",
        "    model_prefix=\"vishwamai\"\n",
        ")\n",
        "\n",
        "# Initialize trainer (placeholder)\n",
        "trainer = VishwamaiShaalaTrainer(\n",
        "    teacher_model=teacher_model,\n",
        "    student_model=student_model,\n",
        "    cfg=distillation_config\n",
        ")\n",
        "\n",
        "print(\"Setup completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jPU9A9kN9-2"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2fbjwR4KN9-2",
        "outputId": "ee5a2585-c66b-4ab1-b190-f2056cfdfa0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:vishwamai.data_utils:Failed to load dataset: Config name is missing.\n",
            "Please pick one among the available configs: ['en', 'realnewslike', 'en.noblocklist', 'en.noclean']\n",
            "Example of usage:\n",
            "\t`load_dataset('c4', 'en')`\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Config name is missing.\nPlease pick one among the available configs: ['en', 'realnewslike', 'en.noblocklist', 'en.noclean']\nExample of usage:\n\t`load_dataset('c4', 'en')`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b1e5b2a4b199>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistillation_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_val_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistillation_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VishwamAI/VishwamAI/VishwamAI/vishwamai/data_utils.py\u001b[0m in \u001b[0;36mcreate_train_dataloader\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load dataset: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2130\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1884\u001b[0m     \u001b[0mbuilder_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_builder_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m     \u001b[0;31m# Instantiate the dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m     builder_instance: DatasetBuilder = builder_cls(\n\u001b[0m\u001b[1;32m   1887\u001b[0m         \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m         \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, repo_id, data_files, data_dir, storage_options, writer_batch_size, **config_kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_dir\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         self.config, self.config_id = self._create_builder_config(\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mcustom_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_create_builder_config\u001b[0;34m(self, config_name, custom_features, **config_kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m                             \u001b[0;34mf\"load_dataset('{self.repo_id or self.dataset_name}', '{self.BUILDER_CONFIGS[0].name}')\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                         )\n\u001b[0;32m--> 554\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    555\u001b[0m                             \u001b[0;34m\"Config name is missing.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                             \u001b[0;34mf\"\\nPlease pick one among the available configs: {list(self.builder_configs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Config name is missing.\nPlease pick one among the available configs: ['en', 'realnewslike', 'en.noblocklist', 'en.noclean']\nExample of usage:\n\t`load_dataset('c4', 'en')`"
          ]
        }
      ],
      "source": [
        "# Import Aim for experiment tracking\n",
        "import aim\n",
        "\n",
        "# Initialize Aim\n",
        "aim_run = aim.Run(experiment=\"VishwamAI-Distillation\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = create_train_dataloader(OmegaConf.create(distillation_config))\n",
        "val_loader = create_val_dataloader(OmegaConf.create(distillation_config))\n",
        "\n",
        "# Initialize training state\n",
        "rng = jax.random.PRNGKey(42)\n",
        "state = trainer.create_train_state(rng)\n",
        "\n",
        "# Initialize guru knowledge with feature matching\n",
        "guru = VishwamaiGuruKnowledge(OmegaConf.create(distillation_config))\n",
        "\n",
        "# Start training\n",
        "try:\n",
        "    for step in range(distillation_config['training']['max_steps']):\n",
        "        batch = next(train_loader)\n",
        "\n",
        "        # Get teacher predictions and features\n",
        "        teacher_outputs = teacher_model(\n",
        "            batch['input_ids'],\n",
        "            attention_mask=batch['attention_mask'],\n",
        "            output_hidden_states=True,\n",
        "            output_attentions=True\n",
        "        )\n",
        "\n",
        "        # Training step with knowledge distillation\n",
        "        state, metrics, rng = trainer.train_step(\n",
        "            state=state,\n",
        "            batch=batch,\n",
        "            step=step,\n",
        "            rng=rng\n",
        "        )\n",
        "\n",
        "        # Enhanced logging with distillation metrics\n",
        "        if step % distillation_config['training']['logging_steps'] == 0:\n",
        "            distill_metrics = {\n",
        "                'kd_loss': metrics['kd_loss'],\n",
        "                'feature_loss': metrics.get('feature_loss', 0.0),\n",
        "                'attention_loss': metrics.get('attention_loss', 0.0),\n",
        "                'hidden_loss': metrics.get('hidden_loss', 0.0),\n",
        "                'total_loss': metrics['total_loss'],\n",
        "                'temperature': guru.temperature\n",
        "            }\n",
        "\n",
        "            # Log to Aim\n",
        "            for metric_name, metric_value in distill_metrics.items():\n",
        "                aim_run.track(metric_value, name=metric_name, step=step)\n",
        "\n",
        "            # Print current distillation progress\n",
        "            print(f\"\\nStep {step}:\")\n",
        "            print(f\"KD Loss: {distill_metrics['kd_loss']:.4f}\")\n",
        "            print(f\"Feature Loss: {distill_metrics['feature_loss']:.4f}\")\n",
        "            print(f\"Total Loss: {distill_metrics['total_loss']:.4f}\")\n",
        "\n",
        "        # Evaluation with feature matching\n",
        "        if step % distillation_config['training']['eval_steps'] == 0:\n",
        "            eval_metrics = trainer.evaluate(\n",
        "                state=state,\n",
        "                val_loader=val_loader,\n",
        "                teacher_model=teacher_model,\n",
        "                guru=guru\n",
        "            )\n",
        "\n",
        "            # Log evaluation metrics to Aim\n",
        "            for k, v in eval_metrics.items():\n",
        "                aim_run.track(v, name=f\"eval_{k}\", step=step)\n",
        "\n",
        "        # Dynamic temperature adjustment\n",
        "        if step % 1000 == 0:\n",
        "            guru.temperature = max(1.0, guru.temperature * 0.95)\n",
        "\n",
        "        # Save checkpoint\n",
        "        if step % distillation_config['training']['save_steps'] == 0:\n",
        "            ckpt_path = f\"checkpoints/step_{step}\"\n",
        "            trainer.save_checkpoint(\n",
        "                state=state,\n",
        "                path=ckpt_path,\n",
        "                guru=guru,\n",
        "                metadata={\n",
        "                    'temperature': guru.temperature,\n",
        "                    'step': step,\n",
        "                    'metrics': metrics\n",
        "                }\n",
        "            )\n",
        "            # Track checkpoint as artifact in Aim\n",
        "            aim_run.track_artifact(ckpt_path, name=\"checkpoints\")\n",
        "\n",
        "    # Final quantization with teacher guidance\n",
        "    if distillation_config['distillation']['quantization']['enabled']:\n",
        "        state = trainer.quantize_model(\n",
        "            state=state,\n",
        "            val_loader=val_loader,\n",
        "            num_calibration_steps=100\n",
        "        )\n",
        "        trainer.save_checkpoint(state, \"checkpoints/quantized\")\n",
        "        aim_run.track_artifact(\"checkpoints/quantized\", name=\"quantized_model\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Training failed: {str(e)}\")\n",
        "    aim_run.set_params({\"error\": str(e)})\n",
        "finally:\n",
        "    aim_run.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soQScC1IN9-3"
      },
      "source": [
        "## Model Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bfk-XvaN9-3"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Push distilled model to HuggingFace Hub\n",
        "api = HfApi()\n",
        "\n",
        "repo_id = \"VishwamAI/VishwamAI-small\"\n",
        "api.create_repo(repo_id, exist_ok=True)\n",
        "\n",
        "# Upload model files\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"configs/student_config.json\",\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=repo_id\n",
        ")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"checkpoints/quantized/model.safetensors\",\n",
        "    path_in_repo=\"model.safetensors\",\n",
        "    repo_id=repo_id\n",
        ")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"tokenizer/vishwamai.model\",\n",
        "    path_in_repo=\"tokenizer.model\",\n",
        "    repo_id=repo_id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdwrWGndN9-3"
      },
      "source": [
        "## Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4MuAzn9N9-3"
      },
      "outputs": [],
      "source": [
        "# Compare teacher and student model performance\n",
        "def evaluate_models(teacher, student, val_loader, num_batches=10):\n",
        "    teacher_metrics = []\n",
        "    student_metrics = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch = next(val_loader)\n",
        "\n",
        "        # Teacher predictions\n",
        "        teacher_output = teacher(batch['input_ids'], deterministic=True)\n",
        "        teacher_metrics.append({\n",
        "            'loss': float(teacher_output['loss']),\n",
        "            'accuracy': float(teacher_output.get('accuracy', 0))\n",
        "        })\n",
        "\n",
        "        # Student predictions\n",
        "        student_output = student(batch['input_ids'], deterministic=True)\n",
        "        student_metrics.append({\n",
        "            'loss': float(student_output['loss']),\n",
        "            'accuracy': float(student_output.get('accuracy', 0))\n",
        "        })\n",
        "\n",
        "    # Calculate averages\n",
        "    teacher_avg = {k: sum(m[k] for m in teacher_metrics) / len(teacher_metrics)\n",
        "                  for k in teacher_metrics[0]}\n",
        "    student_avg = {k: sum(m[k] for m in student_metrics) / len(student_metrics)\n",
        "                   for k in student_metrics[0]}\n",
        "\n",
        "    return {\n",
        "        'teacher': teacher_avg,\n",
        "        'student': student_avg,\n",
        "        'compression_ratio': f\"{teacher.param_count / student.param_count:.2f}x\"\n",
        "    }\n",
        "\n",
        "results = evaluate_models(teacher_model, student_model, val_loader)\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(f\"Compression Ratio: {results['compression_ratio']}\")\n",
        "print(\"\\nTeacher Model:\")\n",
        "print(f\"Loss: {results['teacher']['loss']:.4f}\")\n",
        "print(f\"Accuracy: {results['teacher']['accuracy']:.4f}\")\n",
        "print(\"\\nStudent Model:\")\n",
        "print(f\"Loss: {results['student']['loss']:.4f}\")\n",
        "print(f\"Accuracy: {results['student']['accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P85BYMmjN9-4"
      },
      "outputs": [],
      "source": [
        "# Update model paths\n",
        "TEACHER_MODEL_PATH = \"perplexity-ai/r1-1776\"\n",
        "OUTPUT_MODEL_PATH = \"VishwamAI/Perplexity_r1_disttled_experiment\"\n",
        "\n",
        "# Verify teacher model files exist\n",
        "import os\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Download teacher model files\n",
        "teacher_path = snapshot_download(\n",
        "    repo_id=TEACHER_MODEL_PATH,\n",
        "    allow_patterns=[\"*.safetensors\", \"config.json\", \"tokenizer.model\"]\n",
        ")\n",
        "print(f\"Downloaded teacher model to {teacher_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwtMM3v8N9-4"
      },
      "outputs": [],
      "source": [
        "# Modified model saving logic\n",
        "def save_sharded_model(state, save_dir, num_shards=15):\n",
        "    \"\"\"Save model weights in sharded safetensor format.\"\"\"\n",
        "    import safetensors\n",
        "    import safetensors.flax as stf\n",
        "    import os\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Get model parameters\n",
        "    params = state.params\n",
        "\n",
        "    # Calculate parameters per shard\n",
        "    total_params = sum(p.size for p in jax.tree_leaves(params))\n",
        "    params_per_shard = total_params // num_shards\n",
        "\n",
        "    # Save in sharded format\n",
        "    current_shard = 0\n",
        "    current_size = 0\n",
        "    shard_dict = {}\n",
        "\n",
        "    for name, param in params.items():\n",
        "        param_size = param.size\n",
        "\n",
        "        if current_size + param_size > params_per_shard:\n",
        "            # Save current shard\n",
        "            shard_path = os.path.join(\n",
        "                save_dir,\n",
        "                f\"model-{current_shard+1:05d}-of-{num_shards:05d}.safetensors\"\n",
        "            )\n",
        "            stf.save_file(shard_dict, shard_path)  # Use stf instead of safetensors\n",
        "\n",
        "            # Start new shard\n",
        "            current_shard += 1\n",
        "            current_size = 0\n",
        "            shard_dict = {}\n",
        "\n",
        "        shard_dict[name] = param\n",
        "        current_size += param_size\n",
        "\n",
        "    # Save final shard\n",
        "    if shard_dict:\n",
        "        shard_path = os.path.join(\n",
        "            save_dir,\n",
        "            f\"model-{current_shard+1:05d}-of-{num_shards:05d}.safetensors\"\n",
        "        )\n",
        "        stf.save_file(shard_dict, shard_path)  # Use stf instead of safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63OiF9wON9-4"
      },
      "outputs": [],
      "source": [
        "# Modified model export cell\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Push distilled model to HuggingFace Hub\n",
        "api = HfApi()\n",
        "\n",
        "# Save model in sharded format\n",
        "save_dir = \"checkpoints/final\"\n",
        "save_sharded_model(state, save_dir)\n",
        "\n",
        "# Upload to HF Hub\n",
        "api.create_repo(OUTPUT_MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# Upload configuration\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"configs/student_config.json\",\n",
        "    path_in_repo=\"config.json\",\n",
        "    repo_id=OUTPUT_MODEL_PATH\n",
        ")\n",
        "\n",
        "# Upload all model shards\n",
        "for shard_file in sorted(os.listdir(save_dir)):\n",
        "    if shard_file.endswith(\".safetensors\"):\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=os.path.join(save_dir, shard_file),\n",
        "            path_in_repo=shard_file,\n",
        "            repo_id=OUTPUT_MODEL_PATH\n",
        "        )\n",
        "\n",
        "# Upload tokenizer\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"tokenizer/vishwamai.model\",\n",
        "    path_in_repo=\"tokenizer.model\",\n",
        "    repo_id=OUTPUT_MODEL_PATH\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80ae9e62755042c78c860695ec96412b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41e4c211b9584377af16d392f6137280",
              "IPY_MODEL_297ea395621948bb93f85239464155b7",
              "IPY_MODEL_22b4f65408cf44b4994a01c74bf4de7a"
            ],
            "layout": "IPY_MODEL_4eff3d72989d438bb4612608ef5c45d3"
          }
        },
        "41e4c211b9584377af16d392f6137280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d59556c38304d97b417d3f1d0a4baf3",
            "placeholder": "​",
            "style": "IPY_MODEL_8e5e6d434c1444dab28f682a06ba7a0f",
            "value": "Fetching 6 files: 100%"
          }
        },
        "297ea395621948bb93f85239464155b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed51837f9c84807b4cfb8b0cc879adb",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3604b78362644cf8ada0616483b5c19",
            "value": 6
          }
        },
        "22b4f65408cf44b4994a01c74bf4de7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91eb594a841a43598afbbe78c433ec29",
            "placeholder": "​",
            "style": "IPY_MODEL_2414aa914443443b82e9651ceba264ab",
            "value": " 6/6 [00:00&lt;00:00, 793.32it/s]"
          }
        },
        "4eff3d72989d438bb4612608ef5c45d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d59556c38304d97b417d3f1d0a4baf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5e6d434c1444dab28f682a06ba7a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ed51837f9c84807b4cfb8b0cc879adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3604b78362644cf8ada0616483b5c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91eb594a841a43598afbbe78c433ec29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2414aa914443443b82e9651ceba264ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}