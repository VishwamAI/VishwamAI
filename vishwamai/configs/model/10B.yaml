dim: 6144
depth: 44
heads: 48
vocab_size: 50304
max_seq_len: 8192
dropout_rate: 0.1
expert_count: 8
expert_capacity: 4
ffn_dim: 24576
head_dim: 128
rope_base: 10000
attention_bias: false
parallel_factor: 1

moe_config:
  num_experts: 8
  capacity_factor: 1.25
  expert_dropout: 0.1
  load_balance_weight: 0.01
  router_z_loss_weight: 0.001
  router_aux_loss_weight: 0.001

error_correction:
  enabled: true
  hidden_size: 1024
  num_heads: 4
  intermediate_size: 4096
  error_threshold: 0.1
  correction_weight: 0.5

tot_config:
  enabled: true
  max_thoughts: 5
  max_depth: 3
  beam_width: 3
  temperature: 0.7
  thought_dropout: 0.1

optimization:
  gradient_checkpointing: true
  mixed_precision: true
  dtype: "bfloat16"
  param_init_scale: 0.02
  
model_parallel:
  tensor_parallel_size: 1
  pipeline_parallel_size: 1
  sequence_parallel: false
