# Mixture of Experts configuration

# Basic MoE settings
moe:
  num_experts: 8
  experts_per_token: 2
  expert_capacity_factor: 1.25
  min_expert_capacity: 4
  jitter_noise: 0.1
  enable_overflow_tracking: true
  load_balancing_strategy: balanced
  training_mode: standard  # {standard, auxiliary, distillation}
  enable_expert_dropout: true

# Expert network architecture
expert_network:
  hidden_size: 4096
  intermediate_size: 11008
  activation: gelu
  layer_norm: true
  bias: true
  dropout: 0.1
  expert_initialization:
    method: truncated_normal
    mean: 0.0
    std: 0.02
    min_value: -0.06
    max_value: 0.06

# Router configuration
router:
  type: top_k
  capacity_factor: 1.25
  router_z_loss_coef: 0.01
  load_balancing_loss_coef: 0.01
  router_bias: true
  normalize_router_logits: true
  router_initialization:
    method: uniform
    a: -0.05
    b: 0.05
  noise:
    add_bias_noise: true
    noise_epsilon: 1e-2
    multiply_by_gates: true

# Token dispatching
dispatch:
  routing_strategy: top_k  # {top_k, sampling, threshold}
  routing_temperature: 1.0
  threshold: null
  pad_to_capacity: true
  drop_overflow_tokens: false
  route_method: token  # {token, batch, sequence}
  use_token_priority: true

# Load balancing
load_balancing:
  enabled: true
  strategy: auxiliary_loss  # {auxiliary_loss, dynamic_scaling, expert_replication}
  aux_loss:
    coefficient: 0.01
    type: importance  # {importance, load}
    normalize: true
  balance_by:
    - compute
    - memory
    - communication
  monitor_imbalance: true
  rebalance_interval: 1000

# Expert communication
communication:
  strategy: all_to_all  # {all_to_all, master_worker, hierarchical}
  quantize_weights: false
  gradient_compression: none
  overlap_communication: true
  async_communication: false
  buffer_size: 1024
  optimize_communication: true

# Expert sharding
sharding:
  enabled: true
  strategy: uniform  # {uniform, load_balanced, memory_optimized}
  replicate_experts: false
  min_experts_per_device: 1
  balance_workload: true
  recompute_experts: false
  expert_mapping:
    type: static  # {static, dynamic}
    update_frequency: never  # {never, epoch, step}

# Auxiliary losses
auxiliary_losses:
  z_loss:
    enabled: true
    coefficient: 0.01
  load_balance_loss:
    enabled: true
    coefficient: 0.01
    type: variance  # {variance, max_min, entropy}
  expert_consistency_loss:
    enabled: false
    coefficient: 0.001

# Expert streaming
streaming:
  enabled: false
  chunk_size: 1024
  overlap_computation: true
  buffer_strategy: circular
  max_stream_length: null
  adaptive_chunking: true

# Monitoring and debugging
monitoring:
  track_expert_assignment: true
  track_load_balancing: true
  track_capacity_usage: true
  track_routing_patterns: true
  track_expert_metrics:
    - utilization
    - load
    - overflow
    - computation_time
  alert_thresholds:
    load_imbalance: 0.3
    overflow_rate: 0.1
    expert_usage_min: 0.1

# Expert checkpointing
checkpointing:
  save_experts_separately: true
  checkpoint_interval: 1000
  keep_last_k: 3
  save_router_state: true
  include_expert_metrics: true
  validate_consistency: true

# Optimization
optimization:
  share_expert_weights: false
  recompute_router_logits: true
  fuse_expert_operations: true
  optimize_communication: true
  enable_expert_parallelism: true
  training_optimizations:
    gradient_checkpointing: true
    selective_activation_checkpointing: true
    expert_gradient_accumulation: true
