{
    "model_config": {
        "vocab_size": 32000,
        "num_layers": 12,
        "num_heads": 12,
        "head_dim": 64,
        "hidden_dim": 768,
        "mlp_dim": 3072,
        "max_seq_len": 2048,
        "dropout_rate": 0.1,
        "attention_dropout_rate": 0.1,
        "use_enhanced": true,
        "use_rotary": true,
        "use_flash_attn": true,
        "use_rms_norm": true,
        "dtype": "bfloat16",
        "param_dtype": "bfloat16",
        "compute_dtype": "float32",
        "max_grad_norm": 1.0
    },
    "training": {
        "batch_size": 32,
        "learning_rate": 1e-4,
        "warmup_steps": 2000,
        "decay_steps": 50000,
        "label_smoothing": 0.1,
        "weight_decay": 0.01,
        "beta1": 0.9,
        "beta2": 0.95,
        "epsilon": 1e-8,
        "gradient_checkpointing": true,
        "gradient_accumulation_steps": 4,
        "mixed_precision": true,
        "tpu_iterations_per_loop": 100
    },
    "optimization": {
        "use_pjit": true,
        "use_automatic_sharding": true,
        "attention_partition": "2d",
        "parameter_partition": "2d",
        "remat_policy": "save_nothing",
        "scan_layers": true
    },
    "inference": {
        "max_length": 2048,
        "temperature": 0.7,
        "top_p": 0.95,
        "top_k": 50,
        "repetition_penalty": 1.1,
        "length_penalty": 1.0
    }
}