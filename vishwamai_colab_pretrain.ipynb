{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Colab Training\n",
    "\n",
    "Training with custom VishwamAI Transformer architecture using advanced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment\n",
    "!nvidia-smi\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Setup directories\n",
    "import os\n",
    "DRIVE_DIR = '/content/drive/MyDrive/VishwamAI'\n",
    "CHECKPOINT_DIR = f'{DRIVE_DIR}/checkpoints'\n",
    "!mkdir -p {CHECKPOINT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies and clone repo\n",
    "!git clone https://github.com/VishwamAI/VishwamAI.git\n",
    "%cd VishwamAI\n",
    "\n",
    "%pip install -q torch transformers datasets accelerate bitsandbytes wandb\n",
    "%pip install -e .\n",
    "\n",
    "# Secure Hugging Face authentication\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "def get_huggingface_token():\n",
    "    \"\"\"Get Hugging Face token from environment or prompt\"\"\"\n",
    "    token = os.getenv('HUGGINGFACE_TOKEN')\n",
    "    if not token:\n",
    "        print(\"HUGGINGFACE_TOKEN not found in environment\")\n",
    "        token = getpass.getpass('Enter your Hugging Face token (input will be hidden): ')\n",
    "        # Store temporarily for this session\n",
    "        os.environ['HUGGINGFACE_TOKEN'] = token\n",
    "    return token\n",
    "\n",
    "try:\n",
    "    token = get_huggingface_token()\n",
    "    login(token=token)\n",
    "    print(\"Successfully logged in to Hugging Face\")\n",
    "except Exception as e:\n",
    "    print(f\"Error logging in to Hugging Face: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from vishwamai import (\n",
    "    create_model,\n",
    "    ModelArgs,\n",
    "    VishwamAITokenizer,\n",
    "    TokenizerConfig,\n",
    "    Transformer\n",
    ")\n",
    "from vishwamai.advanced_training import AdvancedTrainer\n",
    "from vishwamai.fp8_cast_bf16 import main\n",
    "from vishwamai.neural_memory import NeuralMemory\n",
    "from vishwamai.tree_of_thoughts import TreeConfig, RewardConfig\n",
    "from vishwamai.curriculum import CurriculumConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualization and analysis tools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Initialize performance tracking\n",
    "performance_history = {\n",
    "    'steps': [],\n",
    "    'loss': [],\n",
    "    'learning_rate': [],\n",
    "    'memory_usage': [],\n",
    "    'curriculum_level': [],\n",
    "    'expert_usage': [],\n",
    "    'evaluation_scores': []\n",
    "}\n",
    "\n",
    "performance_df = pd.DataFrame(performance_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_performance_tracking(stats, step):\n",
    "    \"\"\"Update performance tracking with new statistics\"\"\"\n",
    "    performance_df.loc[len(performance_df)] = {\n",
    "        'steps': step,\n",
    "        'loss': stats['loss'],\n",
    "        'learning_rate': stats['lr'],\n",
    "        'memory_usage': stats['memory_usage']['allocated'],\n",
    "        'curriculum_level': stats['curriculum_stats']['current_difficulty'],\n",
    "        'expert_usage': sum(stats.get('moe_metrics', {}).values()) / len(stats.get('moe_metrics', {})),\n",
    "        'evaluation_scores': stats.get('eval_score', 0)\n",
    "    }\n",
    "\n",
    "def plot_training_progress():\n",
    "    \"\"\"Generate training progress visualization\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Training Progress Overview', fontsize=16)\n",
    "    \n",
    "    axes[0,0].plot(performance_df['steps'], performance_df['loss'])\n",
    "    axes[0,0].set_title('Training Loss')\n",
    "    axes[0,0].set_xlabel('Steps')\n",
    "    axes[0,0].set_ylabel('Loss')\n",
    "    \n",
    "    axes[0,1].plot(performance_df['steps'], performance_df['learning_rate'])\n",
    "    axes[0,1].set_title('Learning Rate')\n",
    "    axes[0,1].set_xlabel('Steps')\n",
    "    axes[0,1].set_ylabel('Learning Rate')\n",
    "    \n",
    "    axes[1,0].plot(performance_df['steps'], performance_df['curriculum_level'])\n",
    "    axes[1,0].set_title('Curriculum Difficulty')\n",
    "    axes[1,0].set_xlabel('Steps')\n",
    "    axes[1,0].set_ylabel('Difficulty Level')\n",
    "    \n",
    "    axes[1,1].plot(performance_df['steps'], performance_df['expert_usage'])\n",
    "    axes[1,1].set_title('Expert Usage')\n",
    "    axes[1,1].set_xlabel('Steps')\n",
    "    axes[1,1].set_ylabel('Average Usage')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{DRIVE_DIR}/training_progress.png\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization and performance tracking initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "config = {\n",
    "    # Model architecture\n",
    "    \"hidden_size\": 1024,\n",
    "    \"num_hidden_layers\": 12,\n",
    "    \"num_attention_heads\": 16,\n",
    "    \"model_type\": \"moe\",\n",
    "    \"qk_nope_head_dim\": 128,\n",
    "    \"qk_rope_head_dim\": 64,\n",
    "    \"v_head_dim\": 128,\n",
    "    \"intermediate_size\": 2816,\n",
    "    \"max_position_embeddings\": 2048,\n",
    "    \n",
    "    # Training settings\n",
    "    \"batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 256,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"max_steps\": 50000,\n",
    "    \n",
    "    # Scaling parameters\n",
    "    \"rope_theta\": 10000.0,\n",
    "    \"rope_factor\": 40,\n",
    "    \"mscale\": 1.0,\n",
    "    \"rope_condense_ratio\": 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural memory and model arguments\n",
    "model_args = ModelArgs(\n",
    "    max_batch_size=4,\n",
    "    max_seq_len=2048,\n",
    "    dtype=\"fp8\",\n",
    "    vocab_size=32000,\n",
    "    dim=1024,\n",
    "    inter_dim=2816,\n",
    "    moe_inter_dim=512,\n",
    "    n_layers=12,\n",
    "    n_dense_layers=1,\n",
    "    n_heads=16,\n",
    "    n_routed_experts=8,\n",
    "    n_shared_experts=1,\n",
    "    n_activated_experts=2,\n",
    "    n_expert_groups=1,\n",
    "    n_limited_groups=1,\n",
    "    score_func=\"softmax\",\n",
    "    route_scale=1.0,\n",
    "    q_lora_rank=0,\n",
    "    kv_lora_rank=64,\n",
    "    qk_nope_head_dim=64,\n",
    "    qk_rope_head_dim=32,\n",
    "    v_head_dim=64,\n",
    "    original_seq_len=2048,\n",
    "    rope_theta=10000.0,\n",
    "    rope_factor=20,\n",
    "    beta_fast=16,\n",
    "    beta_slow=1,\n",
    "    mscale=0.5,\n",
    "    use_alibi=False,\n",
    "    use_rope_scaling=True,\n",
    "    gradient_checkpointing=True,\n",
    "    parallel_attn=True,\n",
    "    rope_condense_ratio=1.0\n",
    ")\n",
    "\n",
    "neural_memory = NeuralMemory(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training components\n",
    "tot_config = TreeConfig(\n",
    "    max_branches=4,\n",
    "    max_depth=3,\n",
    "    beam_width=2,\n",
    "    reward_gamma=0.95\n",
    ")\n",
    "\n",
    "reward_config = RewardConfig(\n",
    "    reasoning_weight=0.4,\n",
    "    accuracy_weight=0.4,\n",
    "    consistency_weight=0.2\n",
    ")\n",
    "\n",
    "curriculum_config = CurriculumConfig(\n",
    "    initial_difficulty=0.1,\n",
    "    max_difficulty=1.0,\n",
    "    difficulty_step=0.05,\n",
    "    min_samples_at_level=1000,\n",
    "    performance_threshold=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process datasets\n",
    "print(\"Loading datasets...\")\n",
    "datasets = {\n",
    "    \"gsm8k\": load_dataset(\"gsm8k\", split=\"train\"),\n",
    "    \"mmlu\": load_dataset(\"cais/mmlu\", split=\"train\"),\n",
    "    \"code\": load_dataset(\"codeparrot/github-code\", split=\"train\")\n",
    "}\n",
    "\n",
    "# Initialize updated tokenizer\n",
    "tokenizer = VishwamAITokenizer(TokenizerConfig(\n",
    "    vocab_size=32000,\n",
    "    max_sentence_length=2048\n",
    "))\n",
    "\n",
    "def process_dataset(examples, dataset_type):\n",
    "    if dataset_type in [\"gsm8k\", \"mmlu\"]:\n",
    "        text = [f\"Question: {q}\\nAnswer: {a}\" for q, a in zip(examples[\"question\"], examples[\"answer\"])]\n",
    "    else:\n",
    "        text = examples[\"content\"]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=2048,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Process datasets\n",
    "processed_datasets = {}\n",
    "for name, dataset in datasets.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    processed_datasets[name] = dataset.map(\n",
    "        lambda x: process_dataset(x, name),\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names\n",
    "    )\n",
    "    print(f\"Processed {len(processed_datasets[name])} examples from {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and trainer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, _ = create_model(config)\n",
    "model = model.to(device)\n",
    "main(model)\n",
    "\n",
    "trainer = AdvancedTrainer(\n",
    "    model=model,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    memory_size=512,\n",
    "    cache_size=256,\n",
    "    tot_config=tot_config,\n",
    "    reward_config=reward_config,\n",
    "    curriculum_config=curriculum_config\n",
    ")\n",
    "\n",
    "# Initialize wandb\n",
    "import wandb\n",
    "wandb.init(\n",
    "    project=\"vishwamai-training\",\n",
    "    config={\n",
    "        \"model\": config,\n",
    "        \"curriculum\": curriculum_config.__dict__,\n",
    "        \"tot\": tot_config.__dict__\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model initialized on {device}\")\n",
    "print(f\"Memory usage: {torch.cuda.memory_allocated(device)/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Performance Tracking\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=\"vishwamai-training\")\n",
    "\n",
    "performance_data = []\n",
    "\n",
    "try:\n",
    "    for step in tqdm(range(config[\"max_steps\"])):\n",
    "        stats = trainer.train_step()\n",
    "        update_performance_tracking(stats, step)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"loss\": stats[\"loss\"],\n",
    "            \"learning_rate\": stats[\"lr\"],\n",
    "            \"batch_size\": stats[\"batch_size\"],\n",
    "            \"curriculum_level\": stats[\"curriculum_stats\"][\"current_difficulty\"],\n",
    "            \"memory_usage\": stats[\"memory_usage\"][\"allocated\"],\n",
    "            \"moe_loss\": stats.get(\"moe_loss\", 0),\n",
    "            \"gradient_norm\": stats[\"gradient_norm\"],\n",
    "            \"expert_usage\": stats.get(\"moe_metrics\", {})\n",
    "        })\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            plot_training_progress()\n",
    "            checkpoint_path = f\"{CHECKPOINT_DIR}/step_{step}.pt\"\n",
    "            trainer.save_checkpoint(checkpoint_path)\n",
    "            \n",
    "            trainer.push_to_hub(\n",
    "                \"VishwamAI/VishwamAI\",\n",
    "                commit_message=f\"Training checkpoint at step {step}\"\n",
    "            )\n",
    "            \n",
    "        if step % 5000 == 0:\n",
    "            print(f\"\\nEvaluating at step {step}...\")\n",
    "            eval_metrics = trainer.evaluate()\n",
    "            wandb.log({\"eval\": eval_metrics})\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nTraining interrupted. Saving final visualization...\")\n",
    "    plot_training_progress()\n",
    "    trainer.save_checkpoint(f\"{CHECKPOINT_DIR}/interrupted.pt\")\n",
    "\n",
    "plot_training_progress()\n",
    "performance_df.to_csv(f\"{DRIVE_DIR}/training_metrics.csv\", index=False)\n",
    "print(\"Training complete with performance tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Performance Graphs\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(performance_df[\"step\"], performance_df[\"loss\"], label=\"Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{DRIVE_DIR}/training_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(performance_df[\"step\"], performance_df[\"memory_usage\"], label=\"Memory Usage (GB)\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Memory Usage (GB)\")\n",
    "plt.title(\"Memory Usage Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{DRIVE_DIR}/memory_usage.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Evaluation\n",
    "print(\"Running final evaluation...\")\n",
    "\n",
    "eval_datasets = [\n",
    "    \"gsm8k\",\n",
    "    \"TIGER-Lab/MMLU-Pro\",\n",
    "    \"MMMU/MMMU\",\n",
    "    \"microsoft/SCBench\",\n",
    "    \"camel-ai/math\",\n",
    "    \"camel-ai/code\"\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for dataset in eval_datasets:\n",
    "    print(f\"\\nEvaluating on {dataset}...\")\n",
    "    try:\n",
    "        eval_data = load_dataset(dataset, split=\"test\")\n",
    "        metrics = trainer.evaluate(eval_data)\n",
    "        results[dataset] = metrics\n",
    "        print(f\"{dataset}: {metrics}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {dataset}: {str(e)}\")\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open(f\"{DRIVE_DIR}/final_evaluation.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
