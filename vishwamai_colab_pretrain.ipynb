{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Advanced Pre-training on A100 GPUs\n",
    "\n",
    "This notebook implements advanced pre-training for VishwamAI using:\n",
    "\n",
    "- Mixed precision FP8/FP16 training\n",
    "- Fully Sharded Data Parallel (FSDP)\n",
    "- Gradient checkpointing\n",
    "- Efficient memory management\n",
    "- Multi-dataset curriculum learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"Setting up VishwamAI in Google Colab...\")\n",
    "    # Clone repository if not exists\n",
    "    ![ ! -d \"VishwamAI\" ] && git clone https://github.com/VishwamAI/VishwamAI.git\n",
    "    %cd VishwamAI\n",
    "    \n",
    "    # Install core dependencies first\n",
    "    !pip install --quiet torch accelerate datasets transformers\n",
    "    !pip install --quiet matplotlib seaborn pandas\n",
    "    \n",
    "    # Install git-lfs and initialize\n",
    "    !apt-get -qq update && apt-get -qq install git-lfs\n",
    "    !git lfs install\n",
    "    \n",
    "    # Install VishwamAI\n",
    "    !pip install -e .\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # Create directories\n",
    "    !mkdir -p checkpoints logs training_visualizations\n",
    "    \n",
    "    print(\"Setup complete!\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab\")\n",
    "\n",
    "# Core imports\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataset handling\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Distributed training\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Import VishwamAI classes directly to avoid circular imports\n",
    "from vishwamai.model import VishwamAI\n",
    "from vishwamai.utils.config import ModelConfig, TrainingConfig\n",
    "from vishwamai.training.advanced_training import AdvancedTrainer\n",
    "from vishwamai.data.dataset import create_combined_dataset\n",
    "from vishwamai.utils.logging import PretrainingLogger\n",
    "from vishwamai.utils.checkpoint import CheckpointManager\n",
    "from vishwamai.utils.hub_utils import HuggingFaceUploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# Configure model and training parameters\n",
    "model_config = ModelConfig(\n",
    "    vocab_size=64000,\n",
    "    hidden_size=8192,\n",
    "    num_layers=120,\n",
    "    num_heads=64,\n",
    "    intermediate_size=32768,\n",
    "    max_position_embeddings=32768,\n",
    "    use_moe=True,\n",
    "    num_experts=8,\n",
    "    use_memory=True,\n",
    "    memory_size=4096,\n",
    "    enable_emergent=True,\n",
    "    tree_search_depth=3\n",
    ")\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=2000,\n",
    "    max_grad_norm=1.0,\n",
    "    fp8_training=True,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging and load config\n",
    "logger = PretrainingLogger('configs/pretrain_config.yaml')\n",
    "\n",
    "# Monitor GPU stats\n",
    "def log_gpu_stats():\n",
    "    stats = {\n",
    "        'gpu_memory_used': torch.cuda.memory_allocated() / 1e9,  # GB\n",
    "        'gpu_memory_cached': torch.cuda.memory_reserved() / 1e9,  # GB\n",
    "        'gpu_utilization': torch.cuda.utilization()\n",
    "    }\n",
    "    logger.log_hardware_stats(stats)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distributed training\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision='fp8',\n",
    "    gradient_accumulation_steps=training_config.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "datasets = [\n",
    "    ('openai/gsm8k', 'main'),\n",
    "    ('cais/mmlu', 'all'),\n",
    "    ('TIGER-Lab/MMLU-Pro', 'main'),\n",
    "    ('deepmind/math_dataset', 'algebra'),\n",
    "    ('wikimedia/wikipedia', '20231101.en'),\n",
    "    ('HuggingFace/c4', 'en'),\n",
    "    ('sentence-transformers/codesearchnet', 'all')\n",
    "]\n",
    "\n",
    "train_dataset = create_combined_dataset(datasets)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = VishwamAI(model_config)\n",
    "\n",
    "# Wrap model in FSDP\n",
    "model = FSDP(\n",
    "    model,\n",
    "    auto_wrap_policy=transformer_auto_wrap_policy,\n",
    "    mixed_precision=True,\n",
    "    device_id=torch.cuda.current_device()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = AdvancedTrainer(\n",
    "    model=model,\n",
    "    config=model_config,\n",
    "    training_config=training_config,\n",
    "    use_tree_search=True\n",
    ")\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    compression=True,\n",
    "    shard_size=1024*1024*1024  # 1GB shards\n",
    ")\n",
    "\n",
    "# Initialize HuggingFace uploader\n",
    "hub_uploader = HuggingFaceUploader(\n",
    "    repo_id=\"VishwamAI/VishwamAI\",  # Updated organization/repo path\n",
    "    token=os.environ.get(\"HF_TOKEN\"),\n",
    "    private=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Log GPU stats before training\n",
    "        log_gpu_stats()\n",
    "        \n",
    "        # Train epoch\n",
    "        metrics = trainer.train_epoch(\n",
    "            dataloader=train_loader,\n",
    "            epoch=epoch,\n",
    "            use_curriculum=True,\n",
    "            checkpoint_dir='checkpoints'\n",
    "        )\n",
    "        \n",
    "        # Log metrics\n",
    "        logger.log_metrics(metrics, step=epoch)\n",
    "        \n",
    "        # Save checkpoint and upload to Hub\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint_path = f\"checkpoints/model_epoch_{epoch+1}\"\n",
    "            \n",
    "            # Save local checkpoint\n",
    "            checkpoint_manager.save_checkpoint(\n",
    "                model=model,\n",
    "                optimizer=trainer.optimizer,\n",
    "                filepath=checkpoint_path,\n",
    "                extra_data={\n",
    "                    'epoch': epoch,\n",
    "                    'metrics': metrics\n",
    "                },\n",
    "                quantize=True\n",
    "            )\n",
    "            \n",
    "            # Upload to HuggingFace Hub\n",
    "            hub_uploader.upload_checkpoint(\n",
    "                checkpoint_path=checkpoint_path,\n",
    "                commit_message=f\"Upload model checkpoint for epoch {epoch+1}\",\n",
    "                epoch=epoch+1,\n",
    "                metrics=metrics\n",
    "            )\n",
    "            \n",
    "            # Upload metrics separately\n",
    "            hub_uploader.upload_metrics(metrics, epoch+1)\n",
    "            \n",
    "            # Log checkpoint\n",
    "            logger.log_checkpoint(checkpoint_path, epoch)\n",
    "            \n",
    "            # Clean up local checkpoint to save space\n",
    "            if epoch > 2:  # Keep only last 2 checkpoints locally\n",
    "                old_checkpoint = f\"checkpoints/model_epoch_{epoch-1}\"\n",
    "                if os.path.exists(old_checkpoint):\n",
    "                    os.remove(old_checkpoint)\n",
    "                    \n",
    "except Exception as e:\n",
    "    logger.log_error(e)\n",
    "    raise e\n",
    "finally:\n",
    "    logger.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "A100",
   "name": "VishwamAI Advanced Pre-training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
