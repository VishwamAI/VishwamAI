{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Math Integration Tutorial\n",
    "\n",
    "This notebook demonstrates how to integrate mathematical reasoning capabilities with VishwamAI using the GSM8K dataset. We'll cover:\n",
    "\n",
    "1. Dataset preparation and loading\n",
    "2. Model and tokenizer configuration\n",
    "3. Training pipeline setup\n",
    "4. Evaluation and visualization\n",
    "5. Example inference\n",
    "\n",
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from vishwamai.model import VishwamaiModel, VishwamaiConfig\n",
    "from vishwamai.conceptual_tokenizer import ConceptualTokenizer, ConceptualTokenizerConfig\n",
    "from vishwamai.training import VishwamaiTrainer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "We'll use the GSM8K (Grade School Math 8K) dataset, which contains math word problems with step-by-step solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 7473\n",
      "Test examples: 1319\n",
      "\n",
      "Sample problem:\n",
      "Question: Bob is tilling a plot of his garden. The plot is 110 feet wide by 120 feet long. His tiller digs a swath two feet wide, and he can till 1 foot of ground in about 2 seconds. How long will it take him to till this plot of land, in minutes?\n",
      "Answer: If Bob goes along the side that's 120 feet long, he will till 110 / 2 = 55 rows.\n",
      "Each of these rows are 120 feet long, so he will push the tiller a total of 120 * 55 = <<120*55=6600>>6,600 feet.\n",
      "He tills 1 linear foot of ground every 2 seconds, so it will take him 2 * 6,600 = 13,200 seconds to till this plot\n",
      "13,200 seconds is 13,2000 / 60 = <<13200/60=220>>220 minutes\n",
      "#### 220\n"
     ]
    }
   ],
   "source": [
    "# Load GSM8K dataset\n",
    "train_df = pd.read_parquet('math/gsm8k/train-00000-of-00001.parquet')\n",
    "test_df = pd.read_parquet('math/gsm8k/test-00000-of-00001.parquet')\n",
    "\n",
    "print(f\"Training examples: {len(train_df)}\")\n",
    "print(f\"Test examples: {len(test_df)}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample problem:\")\n",
    "sample_idx = np.random.randint(len(train_df))\n",
    "print(f\"Question: {train_df.iloc[sample_idx]['question']}\")\n",
    "print(f\"Answer: {train_df.iloc[sample_idx]['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        inputs = self.tokenizer.encode(question)\n",
    "        labels = self.tokenizer.encode(answer)\n",
    "        \n",
    "        # Truncate if necessary\n",
    "        if len(inputs) > self.max_length:\n",
    "            inputs = inputs[:self.max_length]\n",
    "        if len(labels) > self.max_length:\n",
    "            labels = labels[:self.max_length]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long),\n",
    "            'attention_mask': torch.ones(len(inputs), dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Configure the model and tokenizer with appropriate parameters for math reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "model_config = VishwamaiConfig(\n",
    "    hidden_size=3072,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    vocab_size=32000,\n",
    "    layer_norm_eps=1e-12,\n",
    "    pad_token_id=0,\n",
    "    num_key_value_heads=12,  # Setting this equal to num_attention_heads\n",
    "    rope_theta=10000  # Using default value\n",
    ")\n",
    "\n",
    "# Tokenizer configuration\n",
    "tokenizer_config = ConceptualTokenizerConfig(\n",
    "    vocab_size=32000,\n",
    "    max_length=512,\n",
    "    concept_tokens=[\"math\", \"algebra\", \"arithmetic\", \"geometry\"],\n",
    "    reasoning_tokens=[\"equals\", \"therefore\", \"because\", \"solve\", \"calculate\"],\n",
    "    pad_token=\"[PAD]\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    bos_token=\"[BOS]\",\n",
    "    eos_token=\"[EOS]\"\n",
    ")\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model = VishwamaiModel(model_config)\n",
    "tokenizer = ConceptualTokenizer(tokenizer_config)\n",
    "\n",
    "print(\"Model and tokenizer initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup\n",
    "\n",
    "Configure the training pipeline with appropriate hyperparameters and optimization settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = MathDataset(train_df, tokenizer)\n",
    "val_dataset = MathDataset(test_df, tokenizer)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "device = \"cpu\"  # Use CPU for training\n",
    "model = model.to(device)\n",
    "\n",
    "trainer = VishwamaiTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_loader,\n",
    "    eval_dataset=val_loader,\n",
    "    device=device,\n",
    "    optimizer_class=torch.optim.AdamW,\n",
    "    scheduler_class=torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "    use_wandb=False  # Disable wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training metrics collector\n",
    "metrics_history = []\n",
    "\n",
    "def metric_callback(metrics):\n",
    "    metrics_history.append(metrics)\n",
    "    \n",
    "# Train the model\n",
    "trainer.train(\n",
    "    num_epochs=10,\n",
    "    save_dir=\"./checkpoints\",\n",
    "    evaluation_steps=100,\n",
    "    save_steps=1000,\n",
    "    logging_steps=10,\n",
    "    fp16=False  # Disable mixed precision training\n",
    ")\n",
    "\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare metrics for visualization\n",
    "metrics_df = pd.DataFrame(metrics_history)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot training and validation loss\n",
    "ax1.plot(metrics_df['step'], metrics_df['train_loss'], label='Training Loss')\n",
    "if 'eval_loss' in metrics_df.columns:\n",
    "    ax1.plot(metrics_df['step'], metrics_df['eval_loss'], label='Validation Loss')\n",
    "ax1.set_xlabel('Training Steps')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "if 'accuracy' in metrics_df.columns:\n",
    "    ax2.plot(metrics_df['step'], metrics_df['accuracy'], label='Accuracy', color='green')\n",
    "    ax2.set_xlabel('Training Steps')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Model Accuracy over Training')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Inference\n",
    "\n",
    "Test the model on some example math problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_math_problem(problem, max_length=100):\n",
    "    # Prepare input\n",
    "    inputs = tokenizer.encode(problem)\n",
    "    inputs = torch.tensor(inputs, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Generate output\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode output\n",
    "    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return solution\n",
    "\n",
    "# Test examples\n",
    "test_problems = [\n",
    "    \"If John has 5 apples and gives 2 to Mary, how many apples does he have left?\",\n",
    "    \"A train travels at 60 miles per hour. How far will it travel in 2.5 hours?\",\n",
    "    \"What is 15% of 200?\"\n",
    "]\n",
    "\n",
    "for problem in test_problems:\n",
    "    print(f\"\\nProblem: {problem}\")\n",
    "    solution = solve_math_problem(problem)\n",
    "    print(f\"Solution: {solution}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
