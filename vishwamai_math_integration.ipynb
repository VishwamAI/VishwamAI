{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from vishwamai.model import VishwamaiModel, VishwamaiConfig\n",
    "from vishwamai.training import VishwamaiTrainer\n",
    "from vishwamai.conceptual_tokenizer import ConceptualTokenizer, ConceptualTokenizerConfig\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test tokenizer initialization first\n",
    "def test_tokenizer_setup():\n",
    "    config = ConceptualTokenizerConfig(\n",
    "        vocab_size=256,  # Increased from 64 to accommodate all characters\n",
    "        max_length=512,\n",
    "        model_prefix=\"test_tokenizer\",\n",
    "        character_coverage=0.9995  # Reduced coverage\n",
    "    )\n",
    "    tokenizer = ConceptualTokenizer(config)\n",
    "    \n",
    "    # Test basic tokenization\n",
    "    text = \"Test equation: 2 + 2 = 4\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    decoded = tokenizer.decode(tokens)\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Decoded: {decoded}\")\n",
    "    return tokenizer\n",
    "\n",
    "# Run test\n",
    "test_tokenizer = test_tokenizer_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class GSM8KDataset(Dataset):\n",
    "    def __init__(self, data, max_length=512):\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        return {'question': item['question'], 'answer': item['answer']}\n",
    "\n",
    "def collate_fn(batch, tokenizer, max_length=512):\n",
    "    questions = [f\"Question: {item['question']}\\nLet's solve this step by step:\" for item in batch]\n",
    "    answers = [item['answer'] for item in batch]\n",
    "    \n",
    "    try:\n",
    "        # Basic tokenization first\n",
    "        inputs = tokenizer.encode(questions)\n",
    "        input_ids = torch.tensor(inputs)\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "        \n",
    "        # Encode targets/labels\n",
    "        labels = torch.tensor(tokenizer.encode(answers))\n",
    "        \n",
    "        # Ensure all tensors have same sequence length\n",
    "        max_len = max(input_ids.size(1), labels.size(1))\n",
    "        if max_len > max_length:\n",
    "            max_len = max_length\n",
    "            \n",
    "        # Pad or truncate\n",
    "        input_ids = input_ids[:, :max_len]\n",
    "        attention_mask = attention_mask[:, :max_len]\n",
    "        labels = labels[:, :max_len]\n",
    "        \n",
    "        # Add padding\n",
    "        if max_len < max_length:\n",
    "            pad_length = max_length - max_len\n",
    "            input_ids = torch.nn.functional.pad(input_ids, (0, pad_length), value=tokenizer.pad_token_id)\n",
    "            attention_mask = torch.nn.functional.pad(attention_mask, (0, pad_length), value=0)\n",
    "            labels = torch.nn.functional.pad(labels, (0, pad_length), value=-100)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {str(e)}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "try:\n",
    "    train_data = pd.read_parquet('gsm8k/train-00000-of-00001.parquet')\n",
    "    test_data = pd.read_parquet('gsm8k/test-00000-of-00001.parquet')\n",
    "    \n",
    "    print(\"Loading data successful\")\n",
    "    print(f\"Training examples: {len(train_data)}\")\n",
    "    print(f\"Test examples: {len(test_data)}\")\n",
    "    \n",
    "    train_dataset = GSM8KDataset(train_data)\n",
    "    test_dataset = GSM8KDataset(test_data)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model & Tokenizer setup\n",
    "try:\n",
    "    # Model configuration\n",
    "    model_config = VishwamaiConfig(\n",
    "        vocab_size=256,  # Increased to match tokenizer\n",
    "        hidden_size=256,\n",
    "        num_hidden_layers=4,\n",
    "        num_attention_heads=8,\n",
    "        intermediate_size=512,\n",
    "        max_position_embeddings=512\n",
    "    )\n",
    "\n",
    "    # Tokenizer configuration\n",
    "    tokenizer_config = ConceptualTokenizerConfig(\n",
    "        vocab_size=256,  # Increased to handle all characters\n",
    "        max_length=512,\n",
    "        model_prefix=\"gsm8k_tokenizer\",\n",
    "        concept_tokens=[\"math\", \"equation\", \"solve\"],\n",
    "        reasoning_tokens=[\"therefore\", \"because\", \"result\"],\n",
    "        character_coverage=0.9995,  # Reduced coverage\n",
    "        control_symbols=[\"[\", \"]\", \"=\", \"+\", \"-\", \"*\", \"/\"],\n",
    "        user_defined_symbols=[\"$\", \"%\"]\n",
    "    )\n",
    "\n",
    "    print(\"Creating tokenizer...\")\n",
    "    tokenizer = ConceptualTokenizer(tokenizer_config)\n",
    "    print(\"Creating model...\")\n",
    "    model = VishwamaiModel(model_config)\n",
    "\n",
    "    # Train tokenizer if needed\n",
    "    if not os.path.exists(f\"{tokenizer_config.model_prefix}.model\"):\n",
    "        print(\"Training tokenizer...\")\n",
    "        all_texts = list(train_data['question'][:100]) + list(train_data['answer'][:100])  # Start with subset\n",
    "        tokenizer.train_tokenizer(all_texts)\n",
    "        print(\"Tokenizer training completed\")\n",
    "    else:\n",
    "        print(\"Loading existing tokenizer model\")\n",
    "    \n",
    "    print(\"Setup completed successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in setup: {str(e)}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "try:\n",
    "    batch_size = 4\n",
    "    print(\"Creating data loaders...\")\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: collate_fn(x, tokenizer)\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: collate_fn(x, tokenizer)\n",
    "    )\n",
    "\n",
    "    print(\"Data loaders created successfully\")\n",
    "    \n",
    "    # Test batch generation\n",
    "    print(\"\\nTesting batch generation...\")\n",
    "    test_batch = next(iter(train_loader))\n",
    "    print(f\"Batch keys: {test_batch.keys()}\")\n",
    "    print(f\"Input shape: {test_batch['input_ids'].shape}\")\n",
    "    \n",
    "    # Initialize trainer\n",
    "    print(\"\\nInitializing trainer...\")\n",
    "    trainer = VishwamaiTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_loader,\n",
    "        eval_dataset=test_loader,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        optimizer_class=torch.optim.AdamW,\n",
    "        use_wandb=False\n",
    "    )\n",
    "    \n",
    "    print(\"Trainer initialized successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "try:\n",
    "    save_dir = \"math_model_checkpoints\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    trainer.train(\n",
    "        num_epochs=1,  # Start with 1 epoch for testing\n",
    "        save_dir=save_dir,\n",
    "        evaluation_steps=10,\n",
    "        save_steps=50,\n",
    "        logging_steps=5,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_grad_norm=1.0,\n",
    "        fp16=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training error: {str(e)}\")\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
