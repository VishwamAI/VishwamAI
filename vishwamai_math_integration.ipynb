{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Math Integration - GSM8k Testing\n",
    "\n",
    "Initial testing notebook for mathematical reasoning with minimal configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from typing import Dict, List\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from vishwamai.model import VishwamaiConfig, VishwamaiModel\n",
    "from vishwamai.training import VishwamaiTrainer\n",
    "from vishwamai.conceptual_tokenizer import ConceptualTokenizer, ConceptualTokenizerConfig\n",
    "from vishwamai.generate import VishwamaiGenerator, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clear any existing PyTorch memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Force using CPU for initial testing\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load small subset of data for testing\n",
    "def load_test_data(num_samples=100):\n",
    "    train_full = load_dataset('parquet', data_files='gsm8k/train-00000-of-00001.parquet', split='train')\n",
    "    test_full = load_dataset('parquet', data_files='gsm8k/test-00000-of-00001.parquet', split='train')\n",
    "    \n",
    "    # Take small subsets\n",
    "    train_subset = Subset(train_full, range(min(num_samples, len(train_full))))\n",
    "    test_subset = Subset(test_full, range(min(num_samples//10, len(test_full))))\n",
    "    \n",
    "    return train_subset, test_subset, train_full\n",
    "\n",
    "train_dataset, test_dataset, full_dataset = load_test_data()\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize and train tokenizer\n",
    "tokenizer_config = ConceptualTokenizerConfig(\n",
    "    vocab_size=32000,\n",
    "    max_length=128  # Reduced for testing\n",
    ")\n",
    "tokenizer = ConceptualTokenizer(tokenizer_config)\n",
    "\n",
    "# Get sample texts for tokenizer training\n",
    "train_texts = []\n",
    "for i in range(min(1000, len(full_dataset))):\n",
    "    item = full_dataset[i]\n",
    "    train_texts.append(f\"Question: {item['question']}\\nAnswer: {item['answer']}\")\n",
    "\n",
    "print(\"Training tokenizer...\")\n",
    "tokenizer.train_tokenizer(train_texts)\n",
    "print(\"Tokenizer trained\")\n",
    "\n",
    "# Initialize tiny model\n",
    "model_config = VishwamaiConfig(\n",
    "    vocab_size=32000,\n",
    "    hidden_size=128,  # Tiny size for testing\n",
    "    num_hidden_layers=2,  # Minimum layers\n",
    "    num_attention_heads=4,  # Reduced heads\n",
    "    max_seq_len=128,  # Reduced sequence length\n",
    "    intermediate_size=256  # Small FFN size\n",
    ")\n",
    "\n",
    "model = VishwamaiModel(model_config).to(device)\n",
    "print(\"Model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class QuietVishwamaiTrainer(VishwamaiTrainer):\n",
    "    def compute_loss(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Compute loss without debug prints\"\"\"\n",
    "        labels = batch['labels']\n",
    "        model_inputs = {\n",
    "            'input_ids': batch['input_ids'],\n",
    "            'attention_mask': batch['attention_mask']\n",
    "        }\n",
    "        \n",
    "        if 'concept_ids' in batch:\n",
    "            model_inputs['concept_ids'] = batch['concept_ids']\n",
    "        \n",
    "        outputs = self.model(**model_inputs)\n",
    "        \n",
    "        # Get sequence lengths and use minimum\n",
    "        batch_size, seq_length_output, vocab_size = outputs.size()\n",
    "        batch_size_labels, seq_length_labels = labels.size()\n",
    "        min_seq_length = min(seq_length_output, seq_length_labels)\n",
    "        \n",
    "        # Truncate and reshape\n",
    "        outputs = outputs[:, :min_seq_length, :].reshape(-1, vocab_size)\n",
    "        labels = labels[:, :min_seq_length].reshape(-1)\n",
    "        \n",
    "        return torch.nn.functional.cross_entropy(outputs, labels)\n",
    "\n",
    "def math_collate_fn(batch, tokenizer):\n",
    "    questions = [b['question'] for b in batch]\n",
    "    answers = [b['answer'] for b in batch]\n",
    "    \n",
    "    inputs = [f\"Question: {q}\\nAnswer: {a}\" for q, a in zip(questions, answers)]\n",
    "    encoded_inputs = [tokenizer.encode(text) for text in inputs]\n",
    "    \n",
    "    max_len = max(len(x) for x in encoded_inputs)\n",
    "    padded_inputs = [x + [tokenizer.pad_token_id] * (max_len - len(x)) for x in encoded_inputs]\n",
    "    attention_masks = [[1] * len(x) + [0] * (max_len - len(x)) for x in encoded_inputs]\n",
    "    \n",
    "    return {\n",
    "        'input_ids': torch.tensor(padded_inputs),\n",
    "        'attention_mask': torch.tensor(attention_masks),\n",
    "        'labels': torch.tensor(padded_inputs).clone()\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    collate_fn=partial(math_collate_fn, tokenizer=tokenizer),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    collate_fn=partial(math_collate_fn, tokenizer=tokenizer)\n",
    ")\n",
    "\n",
    "print(\"Data loaders prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize trainer with quiet version\n",
    "trainer = QuietVishwamaiTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_loader,\n",
    "    eval_dataset=test_loader,\n",
    "    device=device,\n",
    "    optimizer_class=lambda params: torch.optim.AdamW(params, lr=1e-4),\n",
    "    use_wandb=False\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup save directory\n",
    "save_dir = Path(\"gsm8k_test_model\")\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Train for few steps\n",
    "try:\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train(\n",
    "        num_epochs=2,\n",
    "        save_dir=save_dir,\n",
    "        evaluation_steps=10,\n",
    "        save_steps=50,\n",
    "        logging_steps=5,\n",
    "        fp16=False  # Disable mixed precision since we're on CPU\n",
    "    )\n",
    "    print(\"Training completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Training error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test generation\n",
    "try:\n",
    "    generator = VishwamaiGenerator(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        config=GenerationConfig(\n",
    "            max_length=128,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9\n",
    "        )\n",
    "    )\n",
    "\n",
    "    test_question = \"If John has 5 apples and gives 2 to Mary, how many apples does John have left?\"\n",
    "    print(\"Generating answer...\")\n",
    "    generated = generator.generate(test_question)\n",
    "    print(f\"\\nQuestion: {test_question}\")\n",
    "    print(f\"Answer: {generated[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Generation error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
