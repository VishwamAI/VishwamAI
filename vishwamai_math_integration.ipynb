{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VishwamAI Math Integration Tutorial\n",
    "\n",
    "This notebook demonstrates how to integrate mathematical reasoning capabilities with VishwamAI using the GSM8K dataset. We'll cover:\n",
    "\n",
    "1. Dataset preparation and loading\n",
    "2. Model and tokenizer configuration\n",
    "3. Training pipeline setup\n",
    "4. Evaluation and visualization\n",
    "5. Example inference\n",
    "\n",
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from vishwamai.model import VishwamaiModel, VishwamaiConfig\n",
    "from vishwamai.conceptual_tokenizer import ConceptualTokenizer, ConceptualTokenizerConfig\n",
    "from vishwamai.training import VishwamaiTrainer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "We'll use the GSM8K (Grade School Math 8K) dataset, which contains math word problems with step-by-step solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 7473\n",
      "Test examples: 1319\n",
      "\n",
      "Sample problem:\n",
      "Question: Bob is tilling a plot of his garden. The plot is 110 feet wide by 120 feet long. His tiller digs a swath two feet wide, and he can till 1 foot of ground in about 2 seconds. How long will it take him to till this plot of land, in minutes?\n",
      "Answer: If Bob goes along the side that's 120 feet long, he will till 110 / 2 = 55 rows.\n",
      "Each of these rows are 120 feet long, so he will push the tiller a total of 120 * 55 = <<120*55=6600>>6,600 feet.\n",
      "He tills 1 linear foot of ground every 2 seconds, so it will take him 2 * 6,600 = 13,200 seconds to till this plot\n",
      "13,200 seconds is 13,2000 / 60 = <<13200/60=220>>220 minutes\n",
      "#### 220\n"
     ]
    }
   ],
   "source": [
    "# Load GSM8K dataset\n",
    "train_df = pd.read_parquet('gsm8k/train-00000-of-00001.parquet')\n",
    "test_df = pd.read_parquet('gsm8k/test-00000-of-00001.parquet')\n",
    "\n",
    "print(f\"Training examples: {len(train_df)}\")\n",
    "print(f\"Test examples: {len(test_df)}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample problem:\")\n",
    "sample_idx = np.random.randint(len(train_df))\n",
    "print(f\"Question: {train_df.iloc[sample_idx]['question']}\")\n",
    "print(f\"Answer: {train_df.iloc[sample_idx]['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        \n",
    "        # Tokenize inputs with padding and truncation\n",
    "        inputs = self.tokenizer.encode(\n",
    "            question,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        labels = self.tokenizer.encode(\n",
    "            answer,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long),\n",
    "            'attention_mask': torch.ones(len(inputs), dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Configure the model and tokenizer with appropriate parameters for math reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VishwamaiConfig.__init__() got an unexpected keyword argument 'hidden_dropout_prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Model configuration\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_config \u001b[38;5;241m=\u001b[39m \u001b[43mVishwamaiConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3072\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_attention_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3072\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_dropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_vocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_norm_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Tokenizer configuration\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m ConceptualTokenizerConfig(\n\u001b[1;32m     21\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32000\u001b[39m,\n\u001b[1;32m     22\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     }\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: VishwamaiConfig.__init__() got an unexpected keyword argument 'hidden_dropout_prob'"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "model_config = VishwamaiConfig(\n",
    "    hidden_size=3072,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    vocab_size=32000,\n",
    "    type_vocab_size=2,\n",
    "    initializer_range=0.02,\n",
    "    layer_norm_eps=1e-12,\n",
    "    pad_token_id=0,\n",
    "    use_cache=True,\n",
    "    num_decoder_layers=12\n",
    ")\n",
    "\n",
    "# Tokenizer configuration\n",
    "tokenizer_config = ConceptualTokenizerConfig(\n",
    "    vocab_size=32000,\n",
    "    max_length=512,\n",
    "    concept_tokens=[\"math\", \"algebra\", \"arithmetic\", \"geometry\"],\n",
    "    reasoning_tokens=[\"equals\", \"therefore\", \"because\", \"solve\", \"calculate\"],\n",
    "    special_tokens={\n",
    "        \"pad_token\": \"[PAD]\",\n",
    "        \"unk_token\": \"[UNK]\",\n",
    "        \"bos_token\": \"[BOS]\",\n",
    "        \"eos_token\": \"[EOS]\",\n",
    "        \"sep_token\": \"[SEP]\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model = VishwamaiModel(model_config)\n",
    "tokenizer = ConceptualTokenizer(tokenizer_config)\n",
    "\n",
    "print(\"Model and tokenizer initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup\n",
    "\n",
    "Configure the training pipeline with appropriate hyperparameters and optimization settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = MathDataset(train_df, tokenizer)\n",
    "val_dataset = MathDataset(test_df, tokenizer)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "trainer = VishwamaiTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_loader,\n",
    "    eval_dataset=val_loader,\n",
    "    device=device,\n",
    "    optimizer_kwargs={\n",
    "        'lr': 5e-5,\n",
    "        'weight_decay': 0.01,\n",
    "        'beta1': 0.9,\n",
    "        'beta2': 0.999\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training metrics collector\n",
    "metrics_history = []\n",
    "\n",
    "def metric_callback(metrics):\n",
    "    metrics_history.append(metrics)\n",
    "    \n",
    "# Train the model\n",
    "trainer.train(\n",
    "    num_epochs=10,\n",
    "    save_dir=\"./checkpoints\",\n",
    "    evaluation_steps=100,\n",
    "    save_steps=1000,\n",
    "    logging_steps=10,\n",
    "    callback=metric_callback,\n",
    "    fp16=True  # Enable mixed precision training\n",
    ")\n",
    "\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare metrics for visualization\n",
    "metrics_df = pd.DataFrame(metrics_history)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot training and validation loss\n",
    "ax1.plot(metrics_df['step'], metrics_df['train_loss'], label='Training Loss')\n",
    "if 'eval_loss' in metrics_df.columns:\n",
    "    ax1.plot(metrics_df['step'], metrics_df['eval_loss'], label='Validation Loss')\n",
    "ax1.set_xlabel('Training Steps')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "if 'accuracy' in metrics_df.columns:\n",
    "    ax2.plot(metrics_df['step'], metrics_df['accuracy'], label='Accuracy', color='green')\n",
    "    ax2.set_xlabel('Training Steps')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Model Accuracy over Training')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Inference\n",
    "\n",
    "Test the model on some example math problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_math_problem(problem, max_length=100):\n",
    "    # Prepare input\n",
    "    inputs = tokenizer.encode(\n",
    "        problem,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate output\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode output\n",
    "    solution = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return solution\n",
    "\n",
    "# Test examples\n",
    "test_problems = [\n",
    "    \"If John has 5 apples and gives 2 to Mary, how many apples does he have left?\",\n",
    "    \"A train travels at 60 miles per hour. How far will it travel in 2.5 hours?\",\n",
    "    \"What is 15% of 200?\"\n",
    "]\n",
    "\n",
    "for problem in test_problems:\n",
    "    print(f\"\\nProblem: {problem}\")\n",
    "    solution = solve_math_problem(problem)\n",
    "    print(f\"Solution: {solution}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
